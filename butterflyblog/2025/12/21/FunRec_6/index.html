<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>赛题项目：阿里天池新闻推荐 | isSeymour</title><meta name="author" content="isSeymour"><meta name="copyright" content="isSeymour"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考  赛题项目：阿里天池新闻推荐  在掌握推荐系统的核心方法后，本章将通过一个完整的项目实践，展示如何将理论知识应用于实践。我们将从需求理解与数据分析入手，建立评测指标与基线；然后逐步构建多路召回与冷启动策略，开展特征工程，并训练排序模型；最后对结果进行验证与融合。本章旨在将前述章节的算法与技术串联起来，覆盖从数据处理、模型构建到离线评测的完整流程，帮助读者建立系统化的实战能力。  一、赛题理">
<meta property="og:type" content="article">
<meta property="og:title" content="赛题项目：阿里天池新闻推荐">
<meta property="og:url" content="https://isseymour.github.io/butterflyblog/2025/12/21/FunRec_6/index.html">
<meta property="og:site_name" content="isSeymour">
<meta property="og:description" content="参考  赛题项目：阿里天池新闻推荐  在掌握推荐系统的核心方法后，本章将通过一个完整的项目实践，展示如何将理论知识应用于实践。我们将从需求理解与数据分析入手，建立评测指标与基线；然后逐步构建多路召回与冷启动策略，开展特征工程，并训练排序模型；最后对结果进行验证与融合。本章旨在将前述章节的算法与技术串联起来，覆盖从数据处理、模型构建到离线评测的完整流程，帮助读者建立系统化的实战能力。  一、赛题理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png">
<meta property="article:published_time" content="2025-12-21T06:00:00.000Z">
<meta property="article:modified_time" content="2025-12-21T06:00:00.000Z">
<meta property="article:author" content="isSeymour">
<meta property="article:tag" content="项目">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/IC1011.ico"><link rel="canonical" href="https://isseymour.github.io/butterflyblog/2025/12/21/FunRec_6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/butterflyblog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/butterflyblog/',
  algolia: undefined,
  localSearch: {"path":"/butterflyblog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '赛题项目：阿里天池新闻推荐',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-12-21 14:00:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyblog/code/style.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">89</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">43</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/luogu/"><i class="fa-fw fa-solid fa-magnet"></i><span> 洛谷</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/Diary/"><i class="fa-fw fa-solid fa-book"></i><span> 日记本</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/BAOYAN/"><i class="fa-fw fa-solid fa-hashtag"></i><span> BAOYAN</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png')"><nav id="nav"><span id="blog-info"><a href="/butterflyblog/" title="isSeymour"><span class="site-name">isSeymour</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/luogu/"><i class="fa-fw fa-solid fa-magnet"></i><span> 洛谷</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/Diary/"><i class="fa-fw fa-solid fa-book"></i><span> 日记本</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/BAOYAN/"><i class="fa-fw fa-solid fa-hashtag"></i><span> BAOYAN</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">赛题项目：阿里天池新闻推荐</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-21T06:00:00.000Z" title="发表于 2025-12-21 14:00:00">2025-12-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-12-21T06:00:00.000Z" title="更新于 2025-12-21 14:00:00">2025-12-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/butterflyblog/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">24.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>110分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="赛题项目：阿里天池新闻推荐"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/fun-rec/chapter_5_projects/index.html">参考</a></p>
</blockquote>
<h1>赛题项目：阿里天池新闻推荐</h1>
<blockquote>
<p>在掌握推荐系统的核心方法后，本章将通过一个完整的项目实践，展示如何将理论知识应用于实践。我们将从需求理解与数据分析入手，建立评测指标与基线；然后逐步构建多路召回与冷启动策略，开展特征工程，并训练排序模型；最后对结果进行验证与融合。本章旨在将前述章节的算法与技术串联起来，覆盖从数据处理、模型构建到离线评测的完整流程，帮助读者建立系统化的实战能力。</p>
</blockquote>
<h2 id="一、赛题理解">一、赛题理解</h2>
<p>赛题理解是切入一道赛题的基础，会影响后续特征工程和模型构建等各种工作，也影响着后续发展工作的方向，正确了解赛题背后的思想以及赛题业务逻辑的清晰，有利于花费更少时间构建更为有效的特征模型， 在各种比赛中， 赛题理解都是极其重要且必须走好的第一步， 今天我们就从赛题的理解出发， 首先了解一下这次赛题的概况和数据，从中分析赛题以及大致的处理方式， 其次我们了解模型评测的指标，最后对赛题的理解整理一些经验。</p>
<p>此次比赛是<a target="_blank" rel="noopener" href="https://tianchi.aliyun.com/competition/entrance/531842">新闻推荐场景下的用户行为预测挑战赛</a>， 该赛题是以新闻APP中的新闻推荐为背景， 目的是<strong>要求我们根据用户历史浏览点击新闻文章的数据信息预测用户未来的点击行为， 即用户的最后一次点击的新闻文章</strong>， 这道赛题的设计初衷是引导大家了解推荐系统中的一些业务背景， 解决实际问题。</p>
<h3 id="1、数据概况">1、数据概况</h3>
<p>该数据来自某新闻APP平台的用户交互数据，包括30万用户，近300万次点击，共36万多篇不同的新闻文章，同时每篇新闻文章有对应的embedding向量表示。为了保证比赛的公平性，从中抽取20万用户的点击日志数据作为训练集，5万用户的点击日志数据作为测试集A，5万用户的点击日志数据作为测试集B。具体数据表和参数， 大家可以参考赛题说明。下面说一下拿到这样的数据如何进行理解， 来有效的开展下一步的工作。</p>
<h3 id="2、评价方式理解">2、评价方式理解</h3>
<p>理解评价方式， 我们需要结合着最后的提交文件来看， 根据sample.submit.csv， 我们最后提交的格式是针对每个用户， 我们都会给出五篇文章的推荐结果，按照点击概率从前往后排序。 而真实的每个用户最后一次点击的文章只会有一篇的真实答案， 所以我们就看我们推荐的这五篇里面是否有命中真实答案的。比如对于user1来说， 我们的提交会是：user1, article1, article2, article3, article4, article5$。</p>
<p>评价指标的公式如下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mtext>user</mtext><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mn>5</mn></munderover><mfrac><mrow><mi>s</mi><mo stretchy="false">(</mo><mtext>user</mtext><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><mi>k</mi></mfrac></mrow><annotation encoding="application/x-tex">score(\text{user}) = \sum_{k=1}^5 \frac{s(\text{user}, k)}{k}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord text"><span class="mord">user</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1032em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord text"><span class="mord">user</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>假如article1就是真实的用户点击文章，也就是article1命中， 则<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mtext>user1</mtext><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">(</mo><mtext>user1</mtext><mo separator="true">,</mo><mn>2</mn><mo>−</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s(\text{user1},1)=1, s(\text{user1},2-4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord text"><span class="mord">user1</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord text"><span class="mord">user1</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span>都是0， 如果article2是用户点击的文章， 则<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mtext>user</mtext><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">(</mo><mtext>user</mtext><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>5</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s(\text{user},2)=1/2,s(\text{user},1,3,4,5)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord text"><span class="mord">user</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord text"><span class="mord">user</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span>都是0。也就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mtext>user</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">score(\text{user})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord text"><span class="mord">user</span></span><span class="mclose">)</span></span></span></span>命中第几条的倒数。如果都没中， 则<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mtext>user1</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">score(\text{user1})=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord text"><span class="mord">user1</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>。 这个是合理的， 因为我们希望的就是命中的结果尽量靠前， 而此时分数正好比较高。</p>
<h3 id="3、问题分析">3、问题分析</h3>
<p>根据赛题简介，我们首先要明确我们此次比赛的目标： 根据用户历史浏览点击新闻的数据信息预测用户最后一次点击的新闻文章。从这个目标上看， 会发现此次比赛和我们之前遇到的普通的结构化比赛不太一样， 主要有两点：</p>
<ul>
<li>首先是目标上， 要预测最后一次点击的新闻文章，也就是我们给用户推荐的是新闻文章， 并不是像之前那种预测一个数或者预测数据哪一类那样的问题</li>
<li>数据上， 通过给出的数据我们会发现， 这种数据也不是我们之前遇到的那种特征+标签的数据，而是基于了真实的业务场景， 拿到的用户的点击日志</li>
</ul>
<p>所以拿到这个题目，我们的思考方向就是结合我们的目标，<strong>把该预测问题转成一个监督学习的问题(特征+标签)，然后我们才能进行ML，DL等建模预测</strong>。那么我们自然而然的就应该在心里会有这么几个问题：如何转成一个监督学习问题呢？ 转成一个什么样的监督学习问题呢？ 我们能利用的特征又有哪些呢？ 又有哪些模型可以尝试呢？ 此次面对数万级别的文章推荐，我们又有哪些策略呢？</p>
<p>当然这些问题不会在我们刚看到赛题之后就一下出来答案， 但是只要有了问题之后， 我们就能想办法解决问题了， 比如上面的第二个问题，转成一个什么样的监督学习问题？  由于我们是预测用户最后一次点击的新闻文章，从36万篇文章中预测某一篇的话我们首先可能会想到这可能是一个多分类的问题(36万类里面选1)， 但是如此庞大的分类问题， 我们做起来可能比较困难， 那么能不能转化一下？ 既然是要预测最后一次点击的文章， 那么如果我们能预测出某个用户最后一次对于某一篇文章会进行点击的概率， 是不是就间接性的解决了这个问题呢？概率最大的那篇文章不就是用户最后一次可能点击的新闻文章吗？ 这样就把原问题变成了一个点击率预测的问题(用户, 文章) --&gt; 点击的概率(软分类)， 而这个问题， 就是我们所熟悉的监督学习领域分类问题了， 这样我们后面建模的时候， 对于模型的选择就基本上有大致方向了，比如最简单的逻辑回归模型。</p>
<p>这样， 我们对于该赛题的解决方案应该有了一个大致的解决思路，要先转成一个分类问题来做， 而分类的标签就是用户是否会点击某篇文章，分类问题的特征中会有用户和文章，我们要训练一个分类模型， 对某用户最后一次点击某篇文章的概率进行预测。 那么又会有几个问题：如何转成监督学习问题？ 训练集和测试集怎么制作？ 我们又能利用哪些特征？ 我们又可以尝试哪些模型？ 面对36万篇文章， 20多万用户的推荐， 我们又有哪些策略来缩减问题的规模？如何进行最后的预测？</p>
<h2 id="二、Baseline">二、Baseline</h2>
<p>本baseline将重点实现ItemCF（基于物品的协同过滤）算法作为召回策略，这是工业界广泛使用的经典方法，具有可解释性强、效果稳定的特点。</p>
<h3 id="代码">代码</h3>
<h4 id="requirements-txt">requirements.txt</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tensorflow==2.13.0</span><br><span class="line">pandas==2.0.3</span><br><span class="line">scikit-learn&gt;=1.3.2</span><br><span class="line">python-dotenv==1.0.1</span><br><span class="line">pyyaml==6.0.2</span><br><span class="line">gensim==4.3.3</span><br><span class="line">tabulate==0.9.0</span><br><span class="line">tqdm==4.67.1</span><br><span class="line">networkx==3.1</span><br><span class="line"># 新闻推荐需要</span><br><span class="line">seaborn==0.13.2</span><br><span class="line">faiss-cpu==1.7.4</span><br><span class="line">lightgbm==4.6.0</span><br></pre></td></tr></table></figure>
<h4 id="Baseline-py"><a target="_blank" rel="noopener" href="http://Baseline.py">Baseline.py</a></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_env_with_fallback, reduce_mem, get_all_click_df, get_user_item_time,\</span><br><span class="line">                    get_item_topk_click, submit</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model_itemcf <span class="keyword">import</span> itemcf_sim, item_based_recommend</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">load_env_with_fallback()</span><br><span class="line">RAW_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>))</span><br><span class="line">PROCESSED_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>))</span><br><span class="line"></span><br><span class="line">data_path = RAW_DATA_PATH / <span class="string">&quot;news_recommendation&quot;</span></span><br><span class="line">save_path = PROCESSED_DATA_PATH / <span class="string">&quot;projects/news_recommendation&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_path):</span><br><span class="line">    os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">all_click_df = get_all_click_df(data_path, offline=<span class="literal">False</span>)</span><br><span class="line">all_click_df = reduce_mem(all_click_df)</span><br><span class="line"><span class="built_in">print</span>(all_click_df.head())</span><br><span class="line"><span class="comment"># print(all_click_df[all_click_df[&#x27;click_article_id&#x27;] == 87100])</span></span><br><span class="line"><span class="comment"># print(all_click_df[all_click_df[&#x27;user_id&#x27;] == 249971])</span></span><br><span class="line"></span><br><span class="line">i2i_sim = itemcf_sim(all_click_df, save_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># itemcf 召回</span></span><br><span class="line">user_recall_item_dict = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line"><span class="comment"># 准备参数</span></span><br><span class="line">user_item_time_dict = get_user_item_time(all_click_df)</span><br><span class="line">sim_item_topk = <span class="number">10</span></span><br><span class="line">recall_item_num = <span class="number">10</span></span><br><span class="line">item_topk_click = get_item_topk_click(all_click_df, k=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只需要 testA 的用户情况</span></span><br><span class="line">tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># tst_click = pd.read_csv(data_path / &#x27;testA_click_log.csv&#x27;)[:10000]</span></span><br><span class="line">tst_users = tst_click[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line"><span class="keyword">for</span> user <span class="keyword">in</span> tqdm(tst_users, desc=<span class="string">&#x27;recall&#x27;</span>):</span><br><span class="line">    user_recall_item_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim,</span><br><span class="line">                                                       sim_item_topk=sim_item_topk,</span><br><span class="line">                                                       recall_item_num=recall_item_num,</span><br><span class="line">                                                       item_topk_click=item_topk_click)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转df</span></span><br><span class="line">recall_list = []</span><br><span class="line"><span class="keyword">for</span> user, items <span class="keyword">in</span> tqdm(user_recall_item_dict.items(), desc=<span class="string">&#x27;to_df&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> i, s <span class="keyword">in</span> items:</span><br><span class="line">        recall_list.append([user, i, s])</span><br><span class="line">recall_df = pd.DataFrame(recall_list, columns=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(recall_df.head())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只需要 testA 的用户情况</span></span><br><span class="line">tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># tst_click = pd.read_csv(data_path / &#x27;testA_click_log.csv&#x27;)[:10000]</span></span><br><span class="line">tst_users = tst_click[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line">tst_recall = recall_df[recall_df[<span class="string">&#x27;user_id&#x27;</span>].isin(tst_users)]</span><br><span class="line"><span class="built_in">print</span>(tst_recall.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成提交文件</span></span><br><span class="line">submit(tst_recall, save_path, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;itemcf&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="utils-py"><a target="_blank" rel="noopener" href="http://utils.py">utils.py</a></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> find_dotenv, load_dotenv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">submit</span>(<span class="params">recall_df, save_path, topk=<span class="number">5</span>, model_name=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 生成排名</span></span><br><span class="line">    recall_df = recall_df.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    recall_df[<span class="string">&#x27;rank&#x27;</span>] = recall_df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    <span class="comment"># 保证都有5篇以上</span></span><br><span class="line">    tmp = recall_df.groupby(<span class="string">&#x27;user_id&#x27;</span>).apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;rank&#x27;</span>].<span class="built_in">max</span>())</span><br><span class="line">    <span class="keyword">assert</span> tmp.<span class="built_in">min</span>() &gt; topk</span><br><span class="line">    <span class="comment"># 把排名改为按要求的1-5横向摆放</span></span><br><span class="line">    <span class="keyword">del</span> recall_df[<span class="string">&#x27;pred_score&#x27;</span>]</span><br><span class="line">    submit = recall_df[recall_df[<span class="string">&#x27;rank&#x27;</span>]&lt;=topk].set_index([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>]).unstack(-<span class="number">1</span>).reset_index()</span><br><span class="line">    submit.columns = [<span class="built_in">int</span>(col) <span class="keyword">if</span> <span class="built_in">isinstance</span>(col, <span class="built_in">int</span>) <span class="keyword">else</span> col <span class="keyword">for</span> col <span class="keyword">in</span> submit.columns.droplevel(<span class="number">0</span>)]</span><br><span class="line">    submit = submit.rename(columns = &#123;<span class="string">&#x27;&#x27;</span>:<span class="string">&#x27;user_id&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;article_1&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;article_2&#x27;</span>, <span class="number">3</span>:<span class="string">&#x27;article_3&#x27;</span>, </span><br><span class="line">                                      <span class="number">4</span>:<span class="string">&#x27;article_4&#x27;</span>, <span class="number">5</span>:<span class="string">&#x27;article_5&#x27;</span>&#125;)</span><br><span class="line">    save_name = save_path / <span class="string">f&quot;<span class="subst">&#123;model_name&#125;</span>_<span class="subst">&#123;datetime.now().strftime(<span class="string">&#x27;%m-%d %H:%M&#x27;</span>)&#125;</span>.csv&quot;</span></span><br><span class="line">    submit.to_csv(save_name, index=<span class="literal">False</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载环境函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_env_with_fallback</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    envpath = find_dotenv(usecwd=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> envpath:</span><br><span class="line">        load_dotenv(envpath)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已加载 .env 文件：&quot;</span>, envpath)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未找到 .env 文件&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.getenv(<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>):</span><br><span class="line">            os.environ[<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>] = <span class="built_in">str</span>(Path.cwd()) / <span class="string">&quot;dataset&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>):</span><br><span class="line">            os.environ[<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>] = <span class="built_in">str</span>(Path.cwd()) / <span class="string">&quot;dataset_processed&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># df 节省内存</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reduce_mem</span>(<span class="params">df</span>):</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    start_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span>**<span class="number">2</span></span><br><span class="line">    numerics = [<span class="string">&#x27;int16&#x27;</span>, <span class="string">&#x27;int32&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>, <span class="string">&#x27;float16&#x27;</span>, <span class="string">&#x27;float32&#x27;</span>, <span class="string">&#x27;float64&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        col_type = df[col].dtypes</span><br><span class="line">        <span class="keyword">if</span> col_type <span class="keyword">in</span> numerics:</span><br><span class="line">            dmin = df[col].<span class="built_in">min</span>()</span><br><span class="line">            dmax = df[col].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> pd.isnull(dmin) <span class="keyword">or</span> pd.isnull(dmax):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(col_type)[:<span class="number">3</span>] == <span class="string">&#x27;int&#x27;</span>:</span><br><span class="line">                    <span class="keyword">if</span> dmin &gt; np.iinfo(np.int8).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int8).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int8)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.int16).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int16).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int16)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.int32).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int32).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int32)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int64)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> dmin &gt; np.iinfo(np.float16).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.float16).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float16)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.float32).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.float32).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float32)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float64)</span><br><span class="line">    end_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span>**<span class="number">2</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Memory usage decreased to &#123;:5.2f&#125;Mb(&#123;:.2f&#125;% redcution), time spend &#123;:.2f&#125; min&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        end_mem, <span class="number">100</span>*(start_mem-end_mem)/start_mem, (start_time-end_time)/<span class="number">60</span>))</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样部分数据进行 调试、线下开发、线上提交</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_click_sample</span>(<span class="params">data_path, sample_num=<span class="number">20000</span></span>):</span><br><span class="line">    all_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)</span><br><span class="line">    all_user_ids = all_click[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">    sample_user_ids = np.random.choice(all_user_ids ,size=sample_num, replace=<span class="literal">False</span>)</span><br><span class="line">    all_click = all_click[all_click[<span class="string">&#x27;user_id&#x27;</span>].isin(sample_user_ids)]</span><br><span class="line"></span><br><span class="line">    all_click = all_click.drop_duplicates([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> all_click</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_click_df</span>(<span class="params">data_path, offline=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">if</span> offline:</span><br><span class="line">        all_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)[:<span class="number">20000</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br><span class="line">        trn_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)</span><br><span class="line">        <span class="comment"># trn_click = pd.read_csv(data_path / &quot;train_click_log.csv&quot;)[:10000]</span></span><br><span class="line">        <span class="comment"># tst_click = pd.read_csv(data_path / &#x27;testA_click_log.csv&#x27;)[:10000]</span></span><br><span class="line">        all_click = pd.concat([trn_click, tst_click])</span><br><span class="line">    </span><br><span class="line">    all_click = all_click.drop_duplicates([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> all_click</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户 - 文章，点击</span></span><br><span class="line"><span class="comment"># &#123;user1:[(item,time),(item,time)], ..., user2:[...]&#125;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user_item_time</span>(<span class="params">click_df</span>):</span><br><span class="line">    click_df = click_df.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_item_time_list</span>(<span class="params">df</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(df[<span class="string">&#x27;click_article_id&#x27;</span>], df[<span class="string">&#x27;click_timestamp&#x27;</span>]))</span><br><span class="line">    click_df = click_df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[[<span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]] \</span><br><span class="line">                        .apply(make_item_time_list) \</span><br><span class="line">                        .reset_index() \</span><br><span class="line">                        .rename(columns=&#123;<span class="number">0</span>:<span class="string">&#x27;item_time_list&#x27;</span>&#125;)</span><br><span class="line">    user_item_time_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(click_df[<span class="string">&#x27;user_id&#x27;</span>], click_df[<span class="string">&#x27;item_time_list&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> user_item_time_dict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最热门的K个新闻(返回新闻id)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_topk_click</span>(<span class="params">click_df, k</span>):</span><br><span class="line">    <span class="keyword">return</span> click_df[<span class="string">&#x27;click_article_id&#x27;</span>].value_counts().index[:k]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="model-itemcf-py">model_itemcf.py</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_user_item_time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># itemcf 相似度矩阵计算</span></span><br><span class="line"><span class="comment"># Sim = 共现权重W(i,j) / sqrt(Ni用户数, Nj用户数)</span></span><br><span class="line"><span class="comment"># 其中共现权重不是直接次数，而是这个用户是否活跃 1/log(活跃数+1)是权值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">itemcf_sim</span>(<span class="params">df, save_path</span>):</span><br><span class="line">    user_item_time_dict = get_user_item_time(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算共现权重W、每个物品的用户数Ni</span></span><br><span class="line">    Wij = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    Ni = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> user, item_list <span class="keyword">in</span> tqdm(user_item_time_dict.items()):</span><br><span class="line">        w = <span class="number">1</span> / math.log(<span class="built_in">len</span>(item_list)+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i, i_time <span class="keyword">in</span> item_list:</span><br><span class="line">            Ni[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> j, j_time <span class="keyword">in</span> item_list:</span><br><span class="line">                <span class="keyword">if</span> i == j:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                Wij[i][j] += w</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 Sim</span></span><br><span class="line">    Sim = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    <span class="keyword">for</span> i, wj <span class="keyword">in</span> Wij.items():</span><br><span class="line">        <span class="keyword">for</span> j, w <span class="keyword">in</span> wj.items():</span><br><span class="line">            Sim[i][j] = w / math.sqrt(Ni[i] * Ni[j])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转为普通字典</span></span><br><span class="line">    i2i_Sim = <span class="built_in">dict</span>(Sim)</span><br><span class="line">    <span class="comment"># 存储相似度矩阵</span></span><br><span class="line">    pickle.dump(i2i_Sim, <span class="built_in">open</span>(save_path / <span class="string">&#x27;itemcf_i2i_sim.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;itemcf相似度矩阵保存文件到本地&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> i2i_Sim</span><br><span class="line"></span><br><span class="line"><span class="comment"># itemcf 召回</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">item_based_recommend</span>(<span class="params">user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click</span>):</span><br><span class="line">    user_history = user_item_time_dict[user_id]</span><br><span class="line">    user_history = [item <span class="keyword">for</span> item, _ <span class="keyword">in</span> user_history]</span><br><span class="line"></span><br><span class="line">    item_rank = defaultdict(<span class="built_in">float</span>)</span><br><span class="line">    <span class="comment"># 每个历史物品都找到 k 个相似物品（此处k不是最终数量）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> user_history:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> i2i_sim: <span class="comment"># 没有相似的物品，不在相似度矩阵中</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        items = <span class="built_in">sorted</span>(i2i_sim[i].items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:sim_item_topk]</span><br><span class="line">        <span class="keyword">for</span> j, w <span class="keyword">in</span> items:</span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">in</span> user_history:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            item_rank[j] += w</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数量应该很多了，不足则用热门补全</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(item_rank) &lt; recall_item_num:</span><br><span class="line">        <span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(item_topk_click):</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> item_rank:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            item_rank[i] = -idx-<span class="number">100</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(item_rank) == recall_item_num:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 排序输出最终所需的K个（这里是最终的召回K）</span></span><br><span class="line">    res = <span class="built_in">sorted</span>(item_rank.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:recall_item_num]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="三、数据分析">三、数据分析</h2>
<p>数据分析的价值主要在于熟悉了解整个数据集的基本情况包括每个文件里有哪些数据，具体的文件中的每个字段表示什么实际含义，以及数据集中特征之间的相关性，在推荐场景下主要就是分析用户本身的基本属性，文章基本属性，以及用户和文章交互的一些分布，这些都有利于后面的召回策略的选择，以及特征工程。</p>
<p><strong>建议：当特征工程和模型调参已经很难继续上分了，可以回来在重新从新的角度去分析这些数据，或许可以找到上分的灵感</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_env_with_fallback</span><br><span class="line"></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">13</span>)</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">load_env_with_fallback()</span><br><span class="line">RAW_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>))</span><br><span class="line">PROCESSED_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data_path = RAW_DATA_PATH / <span class="string">&#x27;news_recommendation/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">trn_click = pd.read_csv(data_path / <span class="string">&#x27;train_click_log.csv&#x27;</span>)</span><br><span class="line">item_df = pd.read_csv(data_path / <span class="string">&#x27;articles.csv&#x27;</span>)</span><br><span class="line">item_df = item_df.rename(columns=&#123;<span class="string">&#x27;article_id&#x27;</span>:<span class="string">&#x27;click_article_id&#x27;</span>&#125;)</span><br><span class="line">item_emb_df = pd.read_csv(data_path / <span class="string">&#x27;articles_emb.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="1、数据查看分析">1、数据查看分析</h3>
<p><strong>用户</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对每个用户的点击时间戳进行排序</span></span><br><span class="line">trn_click[<span class="string">&#x27;rank&#x27;</span>] = trn_click.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].rank(ascending=<span class="literal">False</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">tst_click[<span class="string">&#x27;rank&#x27;</span>] = tst_click.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].rank(ascending=<span class="literal">False</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算用户点击文章的次数，并添加新的一列count</span></span><br><span class="line">trn_click[<span class="string">&#x27;click_cnts&#x27;</span>] = trn_click.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">tst_click[<span class="string">&#x27;click_cnts&#x27;</span>] = tst_click.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line">trn_click = trn_click.merge(item_df, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;click_article_id&#x27;</span>])</span><br><span class="line">trn_click.describe()</span><br><span class="line">trn_click.head()</span><br><span class="line"></span><br><span class="line"><span class="comment">#用户点击日志信息</span></span><br><span class="line">trn_click.info()</span><br></pre></td></tr></table></figure>
<p><code>train_click_log.csv</code>文件数据中每个字段的含义:</p>
<ol>
<li>user_id: 用户的唯一标识</li>
<li>click_article_id: 用户点击的文章唯一标识</li>
<li>click_timestamp: 用户点击文章时的时间戳</li>
<li>click_environment: 用户点击文章的环境</li>
<li>click_deviceGroup: 用户点击文章的设备组</li>
<li>click_os: 用户点击文章时的操作系统</li>
<li>click_country: 用户点击文章时的所在的国家</li>
<li>click_region: 用户点击文章时所在的区域</li>
<li>click_referrer_type: 用户点击文章时，文章的来源</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span><br><span class="line">RangeIndex: 1112623 entries, 0 to 1112622</span><br><span class="line">Data columns (total 14 columns):</span><br><span class="line"> #   Column               Non-Null Count    Dtype</span><br><span class="line">---  ------               --------------    -----</span><br><span class="line"> 0   user_id              1112623 non-null  int64</span><br><span class="line"> 1   click_article_id     1112623 non-null  int64</span><br><span class="line"> 2   click_timestamp      1112623 non-null  int64</span><br><span class="line"> 3   click_environment    1112623 non-null  int64</span><br><span class="line"> 4   click_deviceGroup    1112623 non-null  int64</span><br><span class="line"> 5   click_os             1112623 non-null  int64</span><br><span class="line"> 6   click_country        1112623 non-null  int64</span><br><span class="line"> 7   click_region         1112623 non-null  int64</span><br><span class="line"> 8   click_referrer_type  1112623 non-null  int64</span><br><span class="line"> 9   rank                 1112623 non-null  int64</span><br><span class="line"> 10  click_cnts           1112623 non-null  int64</span><br><span class="line"> 11  category_id          1112623 non-null  int64</span><br><span class="line"> 12  created_at_ts        1112623 non-null  int64</span><br><span class="line"> 13  words_count          1112623 non-null  int64</span><br><span class="line">dtypes: int64(14)</span><br><span class="line">memory usage: 118.8 MB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练集中的用户数量为20w</span></span><br><span class="line">trn_click.user_id.nunique()  <span class="comment"># 200000</span></span><br><span class="line">trn_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;click_article_id&#x27;</span>].count().<span class="built_in">min</span>()  <span class="comment"># 训练集里面每个用户至少点击了2篇文章</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">20</span>))</span><br><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>, <span class="string">&#x27;click_environment&#x27;</span>, <span class="string">&#x27;click_deviceGroup&#x27;</span>, <span class="string">&#x27;click_os&#x27;</span>, <span class="string">&#x27;click_country&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;click_region&#x27;</span>, <span class="string">&#x27;click_referrer_type&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>, <span class="string">&#x27;click_cnts&#x27;</span>]:</span><br><span class="line">    plot_envs = plt.subplot(<span class="number">5</span>, <span class="number">2</span>, i)</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    v = trn_click[col].value_counts().reset_index()[:<span class="number">10</span>]</span><br><span class="line">    <span class="comment"># Use iloc to access columns by position to avoid column name issues</span></span><br><span class="line">    fig = sns.barplot(x=v.iloc[:, <span class="number">0</span>], y=v.iloc[:, <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> fig.get_xticklabels():</span><br><span class="line">        item.set_rotation(<span class="number">90</span>)</span><br><span class="line">    plt.title(col)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://datawhalechina.github.io/fun-rec/_images/output_3.analysis_183fda_15_0.png" alt="直方图查看10个用户情况"></p>
<p><strong>测试集用户点击日志</strong></p>
<p>类似，此处不赘述。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tst_click = tst_click.merge(item_df, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;click_article_id&#x27;</span>])</span><br><span class="line">tst_click.head()</span><br><span class="line">tst_click.describe()</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试集中的用户数量为5w</span></span><br><span class="line">tst_click.user_id.nunique()</span><br><span class="line">tst_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;click_article_id&#x27;</span>].count().<span class="built_in">min</span>() <span class="comment"># 注意测试集里面有只点击过一次文章的用户</span></span><br><span class="line"><span class="comment">#新闻文章数据集浏览</span></span><br><span class="line">item_df.head()</span><br><span class="line">item_df[<span class="string">&#x27;words_count&#x27;</span>].value_counts()</span><br><span class="line"><span class="built_in">print</span>(item_df[<span class="string">&#x27;category_id&#x27;</span>].nunique())     <span class="comment"># 461个文章主题</span></span><br><span class="line">item_df[<span class="string">&#x27;category_id&#x27;</span>].hist(figsize=(<span class="number">5</span>, <span class="number">4</span>), grid=<span class="literal">False</span>)</span><br><span class="line">item_df.shape       <span class="comment"># 364047篇文章</span></span><br><span class="line">item_emb_df.head()</span><br><span class="line">item_emb_df.shape</span><br></pre></td></tr></table></figure>
<p><strong>用户分析</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">user_click_merge = pd.concat([trn_click, tst_click])</span><br><span class="line"><span class="comment">#用户重复点击</span></span><br><span class="line">user_click_count = user_click_merge.groupby([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].agg(&#123;<span class="string">&#x27;count&#x27;</span>&#125;).reset_index()</span><br><span class="line">user_click_count[:<span class="number">5</span>]</span><br><span class="line">user_click_count[user_click_count[<span class="string">&#x27;count&#x27;</span>]&gt;<span class="number">7</span>]</span><br><span class="line">user_click_count[<span class="string">&#x27;count&#x27;</span>].unique()</span><br><span class="line"><span class="comment">#用户点击新闻次数</span></span><br><span class="line">user_click_count[<span class="string">&#x27;count&#x27;</span>].value_counts()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户点击环境变化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_envs</span>(<span class="params">df, cols, r, c, figsize=(<span class="params"><span class="number">8</span>, <span class="number">4</span></span>)</span>):</span><br><span class="line">    plt.figure(figsize=figsize)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">        plt.subplot(r, c, i)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        v = df[col].value_counts().reset_index()</span><br><span class="line">        fig = sns.barplot(x=v.iloc[:, <span class="number">0</span>], y=v.iloc[:, <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> fig.get_xticklabels():</span><br><span class="line">            item.set_rotation(<span class="number">90</span>)</span><br><span class="line">        plt.title(col)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分析用户点击环境变化是否明显，这里随机采样10个用户分析这些用户的点击环境分布</span></span><br><span class="line">sample_user_ids = np.random.choice(tst_click[<span class="string">&#x27;user_id&#x27;</span>].unique(), size=<span class="number">5</span>, replace=<span class="literal">False</span>)</span><br><span class="line">sample_users = user_click_merge[user_click_merge[<span class="string">&#x27;user_id&#x27;</span>].isin(sample_user_ids)]</span><br><span class="line">cols = [<span class="string">&#x27;click_environment&#x27;</span>,<span class="string">&#x27;click_deviceGroup&#x27;</span>, <span class="string">&#x27;click_os&#x27;</span>, <span class="string">&#x27;click_country&#x27;</span>, <span class="string">&#x27;click_region&#x27;</span>,<span class="string">&#x27;click_referrer_type&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> _, user_df <span class="keyword">in</span> sample_users.groupby(<span class="string">&#x27;user_id&#x27;</span>):</span><br><span class="line">    plot_envs(user_df, cols, <span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>新闻分析</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户点击新闻数量分布</span></span><br><span class="line">user_click_item_count = <span class="built_in">sorted</span>(user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;click_article_id&#x27;</span>].count().values, reverse=<span class="literal">True</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(user_click_item_count)</span><br><span class="line"></span><br><span class="line"><span class="comment">#点击次数在前50的用户</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(user_click_item_count[:<span class="number">50</span>])</span><br><span class="line">_ii = pd.DataFrame(user_click_item_count)</span><br><span class="line">_ii.value_counts()</span><br><span class="line"><span class="comment">#点击次数排名在[25000:50000]之间</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(user_click_item_count[<span class="number">25000</span>:<span class="number">50000</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新闻点击次数分析</span></span><br><span class="line">item_click_count = <span class="built_in">sorted</span>(user_click_merge.groupby(<span class="string">&#x27;click_article_id&#x27;</span>)[<span class="string">&#x27;user_id&#x27;</span>].count(), reverse=<span class="literal">True</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(item_click_count)</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(item_click_count[:<span class="number">100</span>])</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(item_click_count[:<span class="number">20</span>])</span><br><span class="line"><span class="built_in">print</span>(item_click_count[:<span class="number">20</span>])</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(item_click_count[<span class="number">3500</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新闻共现频次：两篇新闻连续出现的次数</span></span><br><span class="line">tmp = user_click_merge.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">tmp[<span class="string">&#x27;next_item&#x27;</span>] = tmp.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;click_article_id&#x27;</span>].transform(<span class="keyword">lambda</span> x:x.shift(-<span class="number">1</span>))</span><br><span class="line">union_item = tmp.groupby([<span class="string">&#x27;click_article_id&#x27;</span>,<span class="string">&#x27;next_item&#x27;</span>])[<span class="string">&#x27;click_timestamp&#x27;</span>].agg(&#123;<span class="string">&#x27;count&#x27;</span>&#125;).reset_index().sort_values(<span class="string">&#x27;count&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">union_item[[<span class="string">&#x27;count&#x27;</span>]].describe()</span><br><span class="line"></span><br><span class="line"><span class="comment">#画个图直观地看一看</span></span><br><span class="line">x = union_item[<span class="string">&#x27;click_article_id&#x27;</span>]</span><br><span class="line">y = union_item[<span class="string">&#x27;count&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.scatter(x, y)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(union_item[<span class="string">&#x27;count&#x27;</span>].values[<span class="number">40000</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文章信息</span></span><br><span class="line"><span class="comment">#不同类型的新闻出现的次数</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(user_click_merge[<span class="string">&#x27;category_id&#x27;</span>].value_counts().values)</span><br><span class="line"><span class="comment">#出现次数比较少的新闻类型, 有些新闻类型，基本上就出现过几次</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(user_click_merge[<span class="string">&#x27;category_id&#x27;</span>].value_counts().values[<span class="number">150</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment">#新闻字数的描述性统计</span></span><br><span class="line">user_click_merge[<span class="string">&#x27;words_count&#x27;</span>].describe()</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(user_click_merge[<span class="string">&#x27;words_count&#x27;</span>].values)</span><br></pre></td></tr></table></figure>
<p><strong>用户新闻交互分析</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户点击新闻类型偏好</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(<span class="built_in">sorted</span>(user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;category_id&#x27;</span>].nunique(), reverse=<span class="literal">True</span>))</span><br><span class="line">user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;category_id&#x27;</span>].nunique().reset_index().describe()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户查看文章长度分布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ =plt.plot(<span class="built_in">sorted</span>(user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;words_count&#x27;</span>].mean(), reverse=<span class="literal">True</span>))</span><br><span class="line"><span class="comment">#挑出大多数人的区间仔细看看</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(<span class="built_in">sorted</span>(user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;words_count&#x27;</span>].mean(), reverse=<span class="literal">True</span>)[<span class="number">1000</span>:<span class="number">45000</span>])</span><br><span class="line"><span class="comment">#更加详细的参数</span></span><br><span class="line">user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;words_count&#x27;</span>].mean().reset_index().describe()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户点击新闻的时间分析</span></span><br><span class="line"><span class="comment">#为了更好的可视化，这里把时间进行归一化操作</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">mm = MinMaxScaler()</span><br><span class="line">user_click_merge[<span class="string">&#x27;click_timestamp&#x27;</span>] = mm.fit_transform(user_click_merge[[<span class="string">&#x27;click_timestamp&#x27;</span>]])</span><br><span class="line">user_click_merge[<span class="string">&#x27;created_at_ts&#x27;</span>] = mm.fit_transform(user_click_merge[[<span class="string">&#x27;created_at_ts&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">user_click_merge = user_click_merge.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">user_click_merge.head()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_diff_time_func</span>(<span class="params">df, col</span>):</span><br><span class="line">    df = pd.DataFrame(df, columns=[col])</span><br><span class="line">    df[<span class="string">&#x27;time_shift1&#x27;</span>] = df[col].shift(<span class="number">1</span>).fillna(<span class="number">0</span>)</span><br><span class="line">    df[<span class="string">&#x27;diff_time&#x27;</span>] = <span class="built_in">abs</span>(df[col] - df[<span class="string">&#x27;time_shift1&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> df[<span class="string">&#x27;diff_time&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 点击时间差的平均值</span></span><br><span class="line">mean_diff_click_time = user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[[<span class="string">&#x27;click_timestamp&#x27;</span>, <span class="string">&#x27;created_at_ts&#x27;</span>]].apply(<span class="keyword">lambda</span> x: mean_diff_time_func(x, <span class="string">&#x27;click_timestamp&#x27;</span>))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(<span class="built_in">sorted</span>(mean_diff_click_time.values, reverse=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前后点击文章的创建时间差的平均值</span></span><br><span class="line">mean_diff_created_time = user_click_merge.groupby(<span class="string">&#x27;user_id&#x27;</span>)[[<span class="string">&#x27;click_timestamp&#x27;</span>, <span class="string">&#x27;created_at_ts&#x27;</span>]].apply(<span class="keyword">lambda</span> x: mean_diff_time_func(x, <span class="string">&#x27;created_at_ts&#x27;</span>))</span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line">_ = plt.plot(<span class="built_in">sorted</span>(mean_diff_created_time.values, reverse=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户前后点击文章的相似性分布</span></span><br><span class="line">item_idx_2_rawid_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_emb_df[<span class="string">&#x27;article_id&#x27;</span>], item_emb_df.index))</span><br><span class="line"><span class="keyword">del</span> item_emb_df[<span class="string">&#x27;article_id&#x27;</span>]</span><br><span class="line">item_emb_np = np.ascontiguousarray(item_emb_df.values, dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机选择5个用户，查看这些用户前后查看文章的相似性</span></span><br><span class="line">sub_user_ids = np.random.choice(user_click_merge.user_id.unique(), size=<span class="number">15</span>, replace=<span class="literal">False</span>)</span><br><span class="line">sub_user_info = user_click_merge[user_click_merge[<span class="string">&#x27;user_id&#x27;</span>].isin(sub_user_ids)]</span><br><span class="line"></span><br><span class="line">sub_user_info.head()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_sim_list</span>(<span class="params">df</span>):</span><br><span class="line">    sim_list = []</span><br><span class="line">    item_list = df[<span class="string">&#x27;click_article_id&#x27;</span>].values</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(item_list)-<span class="number">1</span>):</span><br><span class="line">        emb1 = item_emb_np[item_idx_2_rawid_dict[item_list[i]]]</span><br><span class="line">        emb2 = item_emb_np[item_idx_2_rawid_dict[item_list[i+<span class="number">1</span>]]]</span><br><span class="line">        sim_list.append(np.dot(emb1,emb2)/(np.linalg.norm(emb1)*(np.linalg.norm(emb2))))</span><br><span class="line">    sim_list.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> sim_list</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> _, user_df <span class="keyword">in</span> sub_user_info.groupby(<span class="string">&#x27;user_id&#x27;</span>):</span><br><span class="line">    item_sim_list = get_item_sim_list(user_df)</span><br><span class="line">    plt.plot(item_sim_list)</span><br></pre></td></tr></table></figure>
<p><img src="https://datawhalechina.github.io/fun-rec/_images/output_3.analysis_183fda_85_0.png" alt="用户前后点击新闻相似度变化"></p>
<p>从图中可以看出有些用户前后看的商品的相似度波动比较大，有些波动比较小，也是有一定的区分度的。</p>
<h3 id="2、数据总结">2、数据总结</h3>
<p>通过数据分析的过程， 我们目前可以得到以下几点重要的信息， 这个对于我们进行后面的特征制作和分析非常有帮助：</p>
<ol>
<li>训练集和测试集的用户id没有重复，也就是测试集里面的用户没有模型是没有见过的</li>
<li>训练集中用户最少的点击文章数是2， 而测试集里面用户最少的点击文章数是1</li>
<li>用户对于文章存在重复点击的情况， 但这个都存在于训练集里面</li>
<li>同一用户的点击环境存在不唯一的情况，后面做这部分特征的时候可以采用统计特征</li>
<li>用户点击文章的次数有很大的区分度，后面可以根据这个制作衡量用户活跃度的特征</li>
<li>文章被用户点击的次数也有很大的区分度，后面可以根据这个制作衡量文章热度的特征</li>
<li>用户看的新闻，相关性是比较强的，所以往往我们判断用户是否对某篇文章感兴趣的时候， 在很大程度上会和他历史点击过的文章有关</li>
<li>用户点击的文章字数有比较大的区别， 这个可以反映用户对于文章字数的区别</li>
<li>用户点击过的文章主题也有很大的区别， 这个可以反映用户的主题偏好</li>
<li>不同用户点击文章的时间差也会有所区别， 这个可以反映用户对于文章时效性的偏好</li>
</ol>
<p>所以根据上面的一些分析，可以更好的帮助我们后面做好特征工程， 充分挖掘数据的隐含信息。</p>
<h2 id="四、多路召回">四、多路召回</h2>
<p>所谓的“多路召回”策略，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用，可以明显的看出，“多路召回策略”是在“计算速度”和“召回率”之间进行权衡的结果。其中，各种简单策略保证候选集的快速召回，从不同角度设计的策略保证召回率接近理想的状态，不至于损伤排序效果。如下图是多路召回的一个示意图，在多路召回中，每个策略之间毫不相关，所以一般可以写并发多线程同时进行，这样可以更加高效。</p>
<p><img src="https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png" alt="多路召回"></p>
<p>上图只是一个多路召回的例子，也就是说可以使用多种不同的策略来获取用户排序的候选商品集合，而具体使用哪些召回策略其实是与业务强相关的 ，针对不同的任务就会有对于该业务真实场景下需要考虑的召回规则。例如新闻推荐，召回规则可以是“热门视频”、“导演召回”、“演员召回”、“最近上映“、”流行趋势“、”类型召回“等等。</p>
<p><strong>三种模式</strong>， 不同的模式对应的不同的数据集：</p>
<ol>
<li>Debug模式： 从海量数据的训练集中随机抽取一部分样本来进行调试(<code>train_click_log_sample</code>)， 先跑通一个baseline。</li>
<li>线下验证模式： 加载整个训练集(<code>train_click_log</code>)， 然后把整个训练集再分成训练集和验证集。训练集是模型的训练数据， 验证集部分帮助我们调整模型的参数和其他的一些超参数。</li>
<li>线上模式： 使用的训练数据集是全量的数据集(<code>train_click_log</code>+<code>test_click_log</code>)</li>
</ol>
<h3 id="1、相似度矩阵">1、相似度矩阵</h3>
<ol>
<li><code>i2i_sim</code>: 借鉴KDD2020的去偏商品推荐，在计算item2item相似性矩阵时，使用关联规则，使得计算的文章的相似性还考虑到了: 1. 用户点击的时间权重 2. 用户点击的顺序权重 3. 文章创建的时间权重</li>
<li><code>u2u_sim</code>: 在计算用户之间的相似度的时候，也可以使用一些简单的关联规则，比如用户活跃度权重，这里将用户的点击次数作为用户活跃度的指标。</li>
<li><code>item_emb_sim</code>: 使用Embedding计算item之间的相似度是为了后续冷启动的时候可以获取未出现在点击数据中的文章。</li>
</ol>
<blockquote>
<p>faiss是Facebook的AI团队开源的一套用于做聚类或者相似性搜索的软件库，底层是用C++实现。Faiss因为超级优越的性能，被广泛应用于推荐相关的业务当中.</p>
<p>faiss工具包一般使用在推荐系统中的向量召回部分。在做向量召回的时候要么是u2u,u2i或者i2i，这里的u和i指的是user和item.我们知道在实际的场景中user和item的数量都是海量的，我们最容易想到的基于向量相似度的召回就是使用两层循环遍历user列表或者item列表计算两个向量的相似度，但是这样做在面对海量数据是不切实际的，faiss就是用来加速计算某个查询向量最相似的topk个索引向量。</p>
<p><strong>faiss查询的原理：</strong></p>
<p>faiss使用了PCA和PQ(Product quantization乘积量化)两种技术进行向量压缩和编码，当然还使用了其他的技术进行优化，但是PCA和PQ是其中最核心部分。</p>
<ol>
<li>PCA降维算法细节参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6239403.html">主成分分析（PCA）原理总结</a></li>
<li>PQ编码的细节参考：<a target="_blank" rel="noopener" href="http://www.fabwrite.com/productquantization">实例理解product quantization算法</a></li>
</ol>
<p><strong>faiss使用</strong>：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/faiss/wiki/Getting-started">faiss官方教程</a></p>
</blockquote>
<h3 id="2、召回">2、召回</h3>
<p>召回常用的策略：</p>
<ul>
<li>Youtube DNN 召回</li>
<li>基于文章的召回
<ul>
<li>文章的协同过滤</li>
<li>基于文章embedding的召回</li>
</ul>
</li>
<li>基于用户的召回
<ul>
<li>用户的协同过滤</li>
<li>用户embedding</li>
</ul>
</li>
</ul>
<p>上面的各种召回方式一部分在基于用户已经看得文章的基础上去召回与这些文章相似的一些文章，而这个相似性的计算方式不同，就得到了不同的召回方式，比如文章的协同过滤，文章内容的embedding等。还有一部分是根据用户的相似性进行推荐，对于某用户推荐与其相似的其他用户看过的文章，比如用户的协同过滤和用户embedding。 还有一种思路是类似矩阵分解的思路，先计算出用户和文章的embedding之后，就可以直接算用户和文章的相似度，根据这个相似度进行推荐，比如YouTube DNN。我们下面详细来看一下每一个召回方法：</p>
<h4 id="YoutubeDNN召回">YoutubeDNN召回</h4>
<p><strong>(这一步是直接获取用户召回的候选文章列表)</strong></p>
<p><a target="_blank" rel="noopener" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf">论文下载地址</a></p>
<p><strong>Youtubednn召回架构</strong></p>
<p><img src="https://datawhalechina.github.io/fun-rec/_images/youtubednn_candidate.png" alt="YoutubeDNN召回架构"></p>
<p>关于YoutubeDNN原理和应用推荐看王喆的两篇博客：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52169807">重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52504407">YouTube深度学习推荐系统的十大工程问题</a></li>
</ol>
<p><strong>参考文献:</strong></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52169807">YouTubeDNN原理</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26306795">word2vec放到排序中的w2v的介绍部分</a></li>
</ol>
<h4 id="ItemCF召回">ItemCF召回</h4>
<p>已经通过协同过滤，Embedding检索的方式得到了文章的相似度矩阵，下面使用协同过滤的思想，给用户召回与其历史文章相似的文章。 这里在召回的时候，也是用了关联规则的方式：</p>
<ol>
<li>考虑相似文章与历史点击文章顺序的权重</li>
<li>考虑文章创建时间的权重，也就是考虑相似文章与历史点击文章创建时间差的权重</li>
<li>考虑文章内容相似度权重(使用Embedding计算相似文章相似度，但是这里需要注意，在Embedding的时候并没有计算所有商品两两之间的相似度，所以相似的文章与历史点击文章不存在相似度，需要做特殊处理)</li>
</ol>
<h4 id="UserCF召回">UserCF召回</h4>
<p>基于用户协同过滤，核心思想是给用户推荐与其相似的用户历史点击文章，因为这里涉及到了相似用户的历史文章，这里仍然可以加上一些关联规则来给用户可能点击的文章进行加权，这里使用的关联规则主要是考虑相似用户的历史点击文章与被推荐用户历史点击商品的关系权重，而这里的关系就可以直接借鉴基于物品的协同过滤相似的做法，只不过这里是对被推荐物品关系的一个累加的过程。</p>
<p>（1）<code>UserCF(emb)</code>：使用usercf的u2u用户相似度和emb的物品相似度，进行u2u2i召回。</p>
<p>（2）<code>UserCF(emb+youtubednnuser)</code> ：使用youtubednn的u2u用户相似度和emb的物品相似度，进行u2u2i召回。</p>
<h4 id="运行效果">运行效果</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">已加载 .env 文件： /Users/seymour/GitHub/LLM4Rec/FunRec/.env</span><br><span class="line">[INFO] 11:31:02 Start...</span><br><span class="line"></span><br><span class="line">[1] 采样数据...</span><br><span class="line">[1] 新闻数据...</span><br><span class="line">[2] 相似矩阵...</span><br><span class="line">ItemCF_sim: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 2290467.45it/s]</span><br><span class="line">itemcf相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/itemcf_i2i_sim.pkl</span><br><span class="line">UserCF_sim: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 9513/9513 [00:05&lt;00:00, 1703.22it/s]</span><br><span class="line">usercf相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/usercf_u2u_sim.pkl</span><br><span class="line">faiss 正在处理(等待时间较长)...</span><br><span class="line">faiss 处理完毕.</span><br><span class="line">embedding_sim: 364047it [00:03, 102177.76it/s]</span><br><span class="line">content-based相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/emb_i2i_sim.pkl</span><br><span class="line"></span><br><span class="line">[INFO] 1. YoutubeDNN recall ==============</span><br><span class="line">gen_data_set: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 48303.33it/s]</span><br><span class="line">YoutubeDNN训练后分离user向量矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/user_youtube_emb.pkl</span><br><span class="line">YoutubeDNN训练后分离item向量矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/item_youtube_emb.pkl</span><br><span class="line">FAISS开始处理...</span><br><span class="line">FAISS处理完毕.</span><br><span class="line">YoutubeDNN_相似度矩阵: 20000it [00:00, 67522.37it/s]</span><br><span class="line">YoutubeDNN_u2i矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/youtube_u2i_dict.pkl</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/YoutubeDNN_recall_12-21 11:33.pkl</span><br><span class="line">Hit@5     2.79% (557/20000)</span><br><span class="line">Hit@10    4.82% (964/20000)</span><br><span class="line">Hit@15    6.69% (1338/20000)</span><br><span class="line">Hit@20    8.04% (1608/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 2. ItemCF(itemcf) recall ===============</span><br><span class="line">ItemCF i2i recall: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 75085.73it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/ItemCF(itemcf)_recall_12-21 11:33.pkl</span><br><span class="line">Hit@5     6.46% (1291/20000)</span><br><span class="line">Hit@10   10.36% (2072/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 3. ItemCF(emb) recall ===============</span><br><span class="line">ItemCF i2i recall: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 64512.62it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/ItemCF(emb)_recall_12-21 11:33.pkl</span><br><span class="line">Hit@5     1.37% (274/20000)</span><br><span class="line">Hit@10    1.59% (318/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 4. UserCF(emb+usercf) recall ===============</span><br><span class="line">UserCF u2u2i recall: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:02&lt;00:00, 6786.53it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/UserCF(emb+usercf)_recall_12-21 11:33.pkl</span><br><span class="line">Hit@5    12.98% (2597/20000)</span><br><span class="line">Hit@10   18.14% (3628/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 5. UserCF(emb+youtubeuser) recall ===============</span><br><span class="line">UserCF u2u_sim: 20000it [00:00, 122271.86it/s]</span><br><span class="line">UserCF(YoutubeUser) recall: 100%|█████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 65092.71it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/UserCF(emb+youtubeuser)_recall_12-21 11:33.pkl</span><br><span class="line">Hit@5     1.25% (249/20000)</span><br><span class="line">Hit@10    4.65% (930/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 11:33:16 Finished. (2.22 mins)</span><br></pre></td></tr></table></figure>
<h3 id="3、冷启动问题">3、冷启动问题</h3>
<p><strong>冷启动问题可以分成三类：文章冷启动，用户冷启动，系统冷启动</strong>。</p>
<ol>
<li><strong>文章冷启动</strong>：对于一个平台系统新加入的文章，该文章没有任何的交互记录，如何推荐给用户的问题。
<blockquote>
<p>对于我们场景可以认为是，日志数据中没有出现过的文章都可以认为是冷启动的文章。</p>
</blockquote>
</li>
<li><strong>用户冷启动</strong>：对于一个平台系统新来的用户，该用户还没有文章的交互信息，如何给该用户进行推荐。
<blockquote>
<p>对于我们场景就是，测试集中的用户是否在测试集对应的log数据中出现过，如果没有出现过，那么可以认为该用户是冷启动用户。但是有时候并没有这么严格，我们也可以自己设定某些指标来判别哪些用户是冷启动用户，比如通过使用时长，点击率，留存率等等。</p>
</blockquote>
</li>
<li><strong>系统冷启动</strong>：就是对于一个平台刚上线，还没有任何的相关历史数据，此时就是系统冷启动，其实也就是前面两种的一个综合。</li>
</ol>
<p><strong>当前场景下冷启动问题的分析</strong>：</p>
<p>对当前的数据进行分析会发现，日志中所有出现过的点击文章只有3w多个，而整个文章库中却有30多万，那么测试集中的用户最后一次点击是否会点击没有出现在日志中的文章呢？如果存在这种情况，说明用户点击的文章之前没有任何的交互信息，这也就是我们所说的文章冷启动。通过数据分析还可以发现，测试集用户只有一次点击的数据占得比例还不少，其实仅仅通过用户的一次点击就给用户推荐文章使用模型的方式也是比较难的，这里其实也可以考虑用户冷启动的问题，但是这里只给出物品冷启动的一些解决方案及代码，关于用户冷启动的话提一些可行性的做法。</p>
<ol>
<li><strong>文章冷启动</strong>(没有冷启动的探索问题)：其实我们这里不是为了做文章的冷启动而做冷启动，而是猜测用户可能会点击一些没有在log数据中出现的文章，我们要做的就是如何从将近27万的文章中选择一些文章作为用户冷启动的文章，这里其实也可以看成是一种召回策略，我们这里就采用简单的比较好理解的基于规则的召回策略来获取用户可能点击的未出现在log数据中的文章。 现在的问题变成了：如何给每个用户考虑从27万个商品中获取一小部分商品？随机选一些可能是一种方案。下面给出一些参考的方案。
<ul>
<li>首先基于Embedding召回一部分与用户历史相似的文章</li>
<li>从基于Embedding召回的文章中通过一些规则过滤掉一些文章，使得留下的文章用户更可能点击。我们这里的规则，可以是，留下那些与用户历史点击文章主题相同的文章，或者字数相差不大的文章。并且留下的文章尽量是与测试集用户最后一次点击时间更接近的文章，或者是当天的文章也行。</li>
</ul>
</li>
<li><strong>用户冷启动</strong>：这里对测试集中的用户点击数据进行分析会发现，测试集中有百分之20的用户只有一次点击，那么这些点击特别少的用户的召回是不是可以单独做一些策略上的补充呢？或者是在排序后直接基于规则加上一些文章呢？这些都可以去尝试，这里没有提供具体的做法。</li>
</ol>
<p><strong>注意</strong>：这里看似和基于embedding计算的item之间相似度然后做itemcf是一致的，但是现在我们的目的不一样，我们这里的目的是找到相似的向量，并且还没有出现在log日志中的商品，再加上一些其他的冷启动的策略，这里需要找回的数量会偏多一点，不然被筛选完之后可能都没有文章了</p>
<h3 id="4、多路召回合并">4、多路召回合并</h3>
<p>多路召回合并就是将前面所有的召回策略得到的用户文章列表合并起来，下面是对前面所有召回结果的汇总</p>
<ol>
<li>基于itemcf计算的item之间的相似度sim进行的召回</li>
<li>基于embedding搜索得到的item之间的相似度进行的召回</li>
<li>基于usercf计算的用户相似度u2u2i召回</li>
<li>YoutubeDNN召回</li>
<li>YoutubeDNN得到的user之间的相似度进行的u2u2i召回</li>
<li>基于冷启动策略的召回</li>
</ol>
<p>注意：<br>
在做召回评估的时候就会发现有些召回的效果不错有些召回的效果很差，所以对每一路召回的结果，我们可以认为的定义一些权重，来做最终的相似度融合</p>
<p>对于上述实现的召回策略其实都不是最优的结果，我们只是做了个简单的尝试，其中还有很多地方可以优化，包括已经实现的这些召回策略的参数或者新加一些，修改一些关联规则都可以。当然还可以尝试更多的召回策略，比如对新闻进行热度召回等等。</p>
<h2 id="五、特征工程">五、特征工程</h2>
<p>特征工程和数据清洗转换是比赛中至关重要的一块， 因为<strong>数据和特征决定了机器学习的上限，而算法和模型只是逼近这个上限而已</strong>，所以特征工程的好坏往往决定着最后的结果，特征工程可以一步增强数据的表达能力，通过构造新特征，我们可以挖掘出数据的更多信息，使得数据的表达能力进一步放大。 在本节内容中，我们主要是先通过制作特征和标签把预测问题转成了监督学习问题，然后围绕着用户画像和文章画像进行一系列特征的制作， 此外，为了保证正负样本的数据均衡，我们还学习了负采样就技术等。当然本节内容只是对构造特征提供了一些思路，也请学习者们在学习过程中开启头脑风暴，尝试更多的构造特征的方法，也欢迎我们一块探讨和交流。</p>
<blockquote>
<p>不多赘述，可以查看原文：<a target="_blank" rel="noopener" href="https://datawhalechina.github.io/fun-rec/chapter_5_projects/5.feature_engineering.html">6.5特征工程</a></p>
</blockquote>
<h2 id="六、排序模型">六、排序模型</h2>
<p>通过召回的操作， 我们已经进行了问题规模的缩减， 对于每个用户，选择出了N篇文章作为了候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性特征，文章本省的属性特征，以及用户与文章之间的特征，下面就是使用机器学习模型来对构造好的特征进行学习，然后对测试集进行预测，得到测试集中的每个候选集用户点击的概率，返回点击概率最大的topk个文章，作为最终的结果。</p>
<p>排序阶段选择了三个比较有代表性的排序模型，它们分别是：</p>
<ol>
<li>LGB的排序模型</li>
<li>LGB的分类模型</li>
<li>深度学习的分类模型DIN</li>
</ol>
<p>得到了最终的排序模型输出的结果之后，还选择了两种比较经典的模型集成的方法：</p>
<ol>
<li>输出结果加权融合</li>
<li>Staking（将模型的输出结果再使用一个简单模型进行预测）</li>
</ol>
<h3 id="1、排序">1、排序</h3>
<h4 id="LGB排序">LGB排序</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">lgb_ranker = lgb.LGBMRanker(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                        max_depth=-<span class="number">1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                        learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lgb_ranker.fit(train_idx[lgb_cols], train_idx[<span class="string">&#x27;label&#x27;</span>], group=g_train,</span><br><span class="line">                eval_set=[(valid_idx[lgb_cols], valid_idx[<span class="string">&#x27;label&#x27;</span>])], eval_group= [g_val],</span><br><span class="line">                eval_at=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], eval_metric=[<span class="string">&#x27;ndcg&#x27;</span>, ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测验证集结果</span></span><br><span class="line">valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)</span><br></pre></td></tr></table></figure>
<h4 id="LGB分类">LGB分类</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型及参数的定义</span></span><br><span class="line">lgb_Classfication = lgb.LGBMClassifier(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                        max_depth=-<span class="number">1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                        learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>, verbose=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lgb_Classfication.fit(train_idx[lgb_cols], train_idx[<span class="string">&#x27;label&#x27;</span>],eval_set=[(valid_idx[lgb_cols], valid_idx[<span class="string">&#x27;label&#x27;</span>])],</span><br><span class="line">                    eval_metric=[<span class="string">&#x27;auc&#x27;</span>, ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测验证集结果</span></span><br><span class="line">valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_Classfication.predict_proba(valid_idx[lgb_cols],</span><br><span class="line">                                                        num_iteration=lgb_Classfication.best_iteration_)[:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p><strong>DIN模型简介</strong></p>
<p>我们下面尝试使用DIN模型， DIN的全称是Deep Interest Network， 这是阿里2018年基于前面的深度学习模型无法表达用户多样化的兴趣而提出的一个模型， 它可以通过考虑【给定的候选广告】和【用户的历史行为】的相关性，来计算用户兴趣的表示向量。具体来说就是通过引入局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和来获得有关候选广告的用户兴趣的表示。与候选广告相关性较高的行为会获得较高的激活权重，并支配着用户兴趣。该表示向量在不同广告上有所不同，大大提高了模型的表达能力。所以该模型对于此次新闻推荐的任务也比较适合， 我们在这里通过当前的候选文章与用户历史点击文章的相关性来计算用户对于文章的兴趣。 该模型的结构如下：</p>
<h4 id="DIN">DIN</h4>
<p><img src="https://datawhalechina.github.io/fun-rec/_images/din_architecture.png" alt="DIN模型"></p>
<p>我们这里直接调包来使用这个模型， 关于这个模型的详细细节部分我们会在下一期的推荐系统组队学习中给出。下面说一下该模型如何具体使用：deepctr的函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">DIN</span>(<span class="params">dnn_feature_columns, history_feature_list, dnn_use_bn=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">       dnn_hidden_units=(<span class="params"><span class="number">200</span>, <span class="number">80</span></span>), dnn_activation=<span class="string">&#x27;relu&#x27;</span>, att_hidden_size=(<span class="params"><span class="number">80</span>, <span class="number">40</span></span>), att_activation=<span class="string">&quot;dice&quot;</span>,</span></span><br><span class="line"><span class="params">      att_weight_normalization=<span class="literal">False</span>, l2_reg_dnn=<span class="number">0</span>, l2_reg_embedding=<span class="number">1e-6</span>, dnn_dropout=<span class="number">0</span>, seed=<span class="number">1024</span>,</span></span><br><span class="line"><span class="params">       task=<span class="string">&#x27;binary&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># * dnn_feature_columns: 特征列， 包含数据所有特征的列表</span></span><br><span class="line">    <span class="comment"># * history_feature_list: 用户历史行为列， 反应用户历史行为的特征的列表</span></span><br><span class="line">    <span class="comment"># * dnn_use_bn: 是否使用BatchNormalization</span></span><br><span class="line">    <span class="comment"># * dnn_hidden_units: 全连接层网络的层数和每一层神经元的个数， 一个列表或者元组</span></span><br><span class="line">    <span class="comment"># * dnn_activation_relu: 全连接网络的激活单元类型</span></span><br><span class="line">    <span class="comment"># * att_hidden_size: 注意力层的全连接网络的层数和每一层神经元的个数</span></span><br><span class="line">    <span class="comment"># * att_activation: 注意力层的激活单元类型</span></span><br><span class="line">    <span class="comment"># * att_weight_normalization: 是否归一化注意力得分</span></span><br><span class="line">    <span class="comment"># * l2_reg_dnn: 全连接网络的正则化系数</span></span><br><span class="line">    <span class="comment"># * l2_reg_embedding: embedding向量的正则化稀疏</span></span><br><span class="line">    <span class="comment"># * dnn_dropout: 全连接网络的神经元的失活概率</span></span><br><span class="line">    <span class="comment"># * task: 任务， 可以是分类， 也可是是回归</span></span><br></pre></td></tr></table></figure>
<p>在具体使用的时候， 我们必须要传入特征列和历史行为列， 但是再传入之前， 我们需要进行一下特征列的预处理。具体如下：</p>
<ol>
<li>首先，我们要处理数据集， 得到数据， 由于我们是基于用户过去的行为去预测用户是否点击当前文章， 所以我们需要把数据的特征列划分成<strong>数值型特征， 离散型特征和历史行为特征</strong>列三部分， 对于每一部分， DIN模型的处理会有不同：
<ol>
<li>对于离散型特征， 在我们的数据集中就是那些类别型的特征， 比如user_id这种， 这种类别型特征， 我们首先要经过embedding处理得到每个特征的低维稠密型表示， 既然要经过embedding， 那么我们就需要为每一列的类别特征的取值建立一个字典，并指明embedding维度， 所以在使用deepctr的DIN模型准备数据的时候， 我们需要通过<code>SparseFeat</code>函数指明这些类别型特征, 这个函数的传入参数就是列名， 列的唯一取值(建立字典用)和embedding维度。</li>
<li>对于用户历史行为特征列， 比如文章id， 文章的类别等这种， 同样的我们需要先经过embedding处理， 只不过和上面不一样的地方是，对于这种特征， 我们在得到每个特征的embedding表示之后， 还需要通过一个<code>Attention_layer</code>计算用户的历史行为和当前候选文章的相关性以此得到当前用户的embedding向量， 这个向量就可以基于当前的候选文章与用户过去点击过得历史文章的相似性的程度来反应用户的兴趣， 并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。这类特征对于每个用户都是一个历史行为序列， 对于每个用户， 历史行为序列长度会不一样， 可能有的用户点击的历史文章多，有的点击的历史文章少， 所以我们还需要把这个长度统一起来， 在为DIN模型准备数据的时候， 我们首先要通过<code>SparseFeat</code>函数指明这些类别型特征， 然后还需要通过<code>VarLenSparseFeat</code>函数再进行序列填充， 使得每个用户的历史序列一样长， 所以这个函数参数中会有个maxlen，来指明序列的最大长度是多少。</li>
<li>对于连续型特征列， 我们只需要用<code>DenseFeat</code>函数来指明列名和维度即可。</li>
</ol>
</li>
<li>处理完特征列之后， 我们把相应的数据与列进行对应，就得到了最后的数据。</li>
</ol>
<h3 id="2、排序融合">2、排序融合</h3>
<h4 id="加权融合">加权融合</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取多个模型的排序结果文件</span></span><br><span class="line">lgb_ranker = pd.read_csv(save_path / <span class="string">&#x27;lgb_ranker_score.csv&#x27;</span>)</span><br><span class="line">lgb_cls = pd.read_csv(save_path / <span class="string">&#x27;lgb_cls_score.csv&#x27;</span>)</span><br><span class="line">din_ranker = pd.read_csv(save_path / <span class="string">&#x27;din_rank_score.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rank_model = &#123;<span class="string">&#x27;lgb_ranker&#x27;</span>: lgb_ranker,</span><br><span class="line">              <span class="string">&#x27;lgb_cls&#x27;</span>: lgb_cls,</span><br><span class="line">              <span class="string">&#x27;din_ranker&#x27;</span>: din_ranker&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_ensumble_predict_topk</span>(<span class="params">rank_model, topk=<span class="number">5</span></span>):</span><br><span class="line">    <span class="comment"># final_recall = rank_model[&#x27;lgb_cls&#x27;].append(rank_model[&#x27;din_ranker&#x27;])</span></span><br><span class="line">    final_recall = pd.concat([rank_model[<span class="string">&#x27;lgb_cls&#x27;</span>], rank_model[<span class="string">&#x27;din_ranker&#x27;</span>]]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>][<span class="string">&#x27;pred_score&#x27;</span>] = rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>][<span class="string">&#x27;pred_score&#x27;</span>].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># final_recall = final_recall.append(rank_model[&#x27;lgb_ranker&#x27;])</span></span><br><span class="line">    final_recall = pd.concat([final_recall, rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>]]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    final_recall = final_recall.groupby([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line">    submit(final_recall, topk=topk, model_name=<span class="string">&#x27;ensemble_fuse&#x27;</span>)</span><br><span class="line"></span><br><span class="line">get_ensumble_predict_topk(rank_model)</span><br></pre></td></tr></table></figure>
<h4 id="Staking">Staking</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取多个模型的交叉验证生成的结果文件</span></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">trn_lgb_ranker_feats = pd.read_csv(save_path / <span class="string">&#x27;trn_lgb_ranker_feats.csv&#x27;</span>)</span><br><span class="line">trn_lgb_cls_feats = pd.read_csv(save_path / <span class="string">&#x27;trn_lgb_cls_feats.csv&#x27;</span>)</span><br><span class="line">trn_din_cls_feats = pd.read_csv(save_path / <span class="string">&#x27;trn_din_cls_feats.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">tst_lgb_ranker_feats = pd.read_csv(save_path / <span class="string">&#x27;tst_lgb_ranker_feats.csv&#x27;</span>)</span><br><span class="line">tst_lgb_cls_feats = pd.read_csv(save_path / <span class="string">&#x27;tst_lgb_cls_feats.csv&#x27;</span>)</span><br><span class="line">tst_din_cls_feats = pd.read_csv(save_path / <span class="string">&#x27;tst_din_cls_feats.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将多个模型输出的特征进行拼接</span></span><br><span class="line">finall_trn_ranker_feats = trn_lgb_ranker_feats[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]]</span><br><span class="line">finall_tst_ranker_feats = tst_lgb_ranker_feats[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, trn_model <span class="keyword">in</span> <span class="built_in">enumerate</span>([trn_lgb_ranker_feats, trn_lgb_cls_feats, trn_din_cls_feats]):</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [ <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]:</span><br><span class="line">        col_name = feat + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(idx)</span><br><span class="line">        finall_trn_ranker_feats[col_name] = trn_model[feat]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, tst_model <span class="keyword">in</span> <span class="built_in">enumerate</span>([tst_lgb_ranker_feats, tst_lgb_cls_feats, tst_din_cls_feats]):</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [ <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]:</span><br><span class="line">        col_name = feat + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(idx)</span><br><span class="line">        finall_tst_ranker_feats[col_name] = tst_model[feat]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测</span></span><br><span class="line"><span class="comment"># 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">feat_cols = [<span class="string">&#x27;pred_score_0&#x27;</span>, <span class="string">&#x27;pred_rank_0&#x27;</span>, <span class="string">&#x27;pred_score_1&#x27;</span>, <span class="string">&#x27;pred_rank_1&#x27;</span>, <span class="string">&#x27;pred_score_2&#x27;</span>, <span class="string">&#x27;pred_rank_2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">trn_x = finall_trn_ranker_feats[feat_cols]</span><br><span class="line">trn_y = finall_trn_ranker_feats[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line">tst_x = finall_tst_ranker_feats[feat_cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样50000行数据 因为全量数据太大了</span></span><br><span class="line">sample_indices = trn_x.sample(n=<span class="number">50000</span>, random_state=<span class="number">42</span>).index</span><br><span class="line">trn_x_sample = trn_x.loc[sample_indices]</span><br><span class="line">trn_y_sample = trn_y.loc[sample_indices]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original training data shape: <span class="subst">&#123;trn_x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Sampled training data shape: <span class="subst">&#123;trn_x_sample.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(trn_x_sample, trn_y_sample)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">test_score = []</span><br><span class="line">test_batch_size = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(tst_x), test_batch_size), total=<span class="built_in">len</span>(tst_x)//test_batch_size, desc=<span class="string">&quot;Predicting test score&quot;</span>):</span><br><span class="line">    test_score.append(lr.predict_proba(tst_x.iloc[i:i+test_batch_size])[:, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">finall_tst_ranker_feats[<span class="string">&#x27;pred_score&#x27;</span>] = np.concatenate(test_score)</span><br></pre></td></tr></table></figure>
<h2 id="附：代码">附：代码</h2>
<h4 id="recall-py"><code>recall.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, warnings, pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> model_itemcf <span class="keyword">import</span> itemcf_sim, itemcf_recall, cold_start_prepare, cold_start_recall</span><br><span class="line"><span class="keyword">from</span> model_usercf <span class="keyword">import</span> usercf_sim, u2u_embdding_sim, usercf_recall, usercf_recall_YoutubeUser</span><br><span class="line"><span class="keyword">from</span> model_youtubednn <span class="keyword">import</span> YoutubeDNN_u2i_dict</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_dotenv, get_all_click_sample, get_all_click_df, get_item_info_df, get_item_emb_dict \</span><br><span class="line">                    ,get_item_info_dict, get_hist_last_click, get_user_active_degree_dict, get_item_emb_df\</span><br><span class="line">                    ,embedding_sim, metrics_recall, get_user_item_time, get_item_topk_click, save_recall,\</span><br><span class="line">                    get_user_hist_item_info_dict, combine_recall_results, submit</span><br><span class="line"></span><br><span class="line">START_TIME = datetime.now()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;[INFO] <span class="subst">&#123;START_TIME.strftime(<span class="string">&quot;%H:%M:%S&quot;</span>)&#125;</span> Start...\n&#x27;</span>)</span><br><span class="line">os.environ[<span class="string">&#x27;OMP_NUM_THREADS&#x27;</span>] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line">RAW_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>))</span><br><span class="line">PROCESSED_DATA_PATH = Path(os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>))</span><br><span class="line">data_path = RAW_DATA_PATH / <span class="string">&#x27;news_recommendation&#x27;</span></span><br><span class="line">save_path = PROCESSED_DATA_PATH / <span class="string">&#x27;projects/news_recommendation&#x27;</span></span><br><span class="line">metric_recall = <span class="literal">True</span>  <span class="comment"># 做召回评估的一个标志, 如果不进行评估就是直接使用全量数据进行召回</span></span><br><span class="line"></span><br><span class="line">max_min_scaler = <span class="keyword">lambda</span> x: (x-np.<span class="built_in">min</span>(x)) / (np.<span class="built_in">max</span>(x)-np.<span class="built_in">min</span>(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[1] 采样数据...&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> metric_recall:</span><br><span class="line">    all_click_df = get_all_click_sample(data_path)</span><br><span class="line">    <span class="comment"># all_click_df = get_all_click_df(data_path, offline=True)</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    all_click_df = get_all_click_df(data_path, offline=<span class="literal">False</span>)</span><br><span class="line">    tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># all_click_df = get_all_click_df(data_path, offline=False)</span></span><br><span class="line"><span class="comment"># 时间戳归一化，用于规则权重(注意后面必须是两个[]，否则apply的使用会不对)</span></span><br><span class="line">all_click_df[<span class="string">&#x27;click_timestamp&#x27;</span>] = all_click_df[[<span class="string">&#x27;click_timestamp&#x27;</span>]].apply(max_min_scaler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新闻</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[1] 新闻数据...&#x27;</span>)</span><br><span class="line">item_info_df = get_item_info_df(data_path)</span><br><span class="line">item_emb_df = get_item_emb_df(data_path)</span><br><span class="line">item_emb_dict = get_item_emb_dict(data_path, save_path)</span><br><span class="line"><span class="comment"># 获取文章的属性信息，保存成字典的形式方便查询</span></span><br><span class="line">item_creat_dict, item_category_dict, item_words_dict = get_item_info_dict(item_info_df)</span><br><span class="line"><span class="comment"># 用户活跃度</span></span><br><span class="line">user_active_dict = get_user_active_degree_dict(all_click_df)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多路召回字典</span></span><br><span class="line">user_multi_recall_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;YoutubeDNN_recall&#x27;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&#x27;Coldstart_recall&#x27;</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 多路召回的权重</span></span><br><span class="line">weight_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;YoutubeDNN_recall&#x27;</span>:<span class="number">5.0</span>,</span><br><span class="line">    <span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>: <span class="number">10.0</span>,</span><br><span class="line">    <span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>: <span class="number">2.0</span>,</span><br><span class="line">    <span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>: <span class="number">20.0</span>,</span><br><span class="line">    <span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>: <span class="number">5.0</span>,</span><br><span class="line">    <span class="string">&#x27;Coldstart_recall&#x27;</span>: <span class="number">1.0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[2] 相似矩阵...&#x27;</span>)</span><br><span class="line">trn_hist_click_df, trn_last_click_df = get_hist_last_click(all_click_df)</span><br><span class="line">i2i_sim = itemcf_sim(trn_hist_click_df, save_path, item_creat_dict)</span><br><span class="line">u2u_sim = usercf_sim(all_click_df, save_path, user_active_dict)     <span class="comment"># 太耗时了</span></span><br><span class="line">emb_i2i_sim = embedding_sim(all_click_df, item_emb_df, save_path, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 线下测试：召回+评估</span></span><br><span class="line"><span class="keyword">if</span> metric_recall:</span><br><span class="line">    item_topk_click = get_item_topk_click(trn_hist_click_df, k=<span class="number">50</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 1. YoutubeDNN recall ==============&quot;</span>)</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;YoutubeDNN_recall&#x27;</span>] = YoutubeDNN_u2i_dict(trn_hist_click_df, save_path, topk=<span class="number">20</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;YoutubeDNN_recall&#x27;</span>], save_path, <span class="string">&quot;YoutubeDNN&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;YoutubeDNN_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 2. ItemCF(itemcf) recall ===============&quot;</span>)</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>] = itemcf_recall(trn_hist_click_df, item_topk_click, \</span><br><span class="line">                                                        i2i_sim, save_path, \</span><br><span class="line">                                                        sim_item_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>, \</span><br><span class="line">                                                        emb_i2i_sim=emb_i2i_sim, item_creat_dict=item_creat_dict)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>], save_path, <span class="string">&quot;ItemCF(itemcf)&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 3. ItemCF(emb) recall ===============&quot;</span>)</span><br><span class="line">    i2i_sim_3 = emb_i2i_sim</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>] = itemcf_recall(trn_hist_click_df, item_topk_click, \</span><br><span class="line">                                                        i2i_sim_3, save_path, \</span><br><span class="line">                                                        sim_item_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>, \</span><br><span class="line">                                                        emb_i2i_sim=emb_i2i_sim, item_creat_dict=item_creat_dict)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>], save_path, <span class="string">&quot;ItemCF(emb)&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 4. UserCF(emb+usercf) recall ===============&quot;</span>)</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>] = usercf_recall(trn_hist_click_df, item_topk_click, \</span><br><span class="line">                                                                       u2u_sim, item_creat_dict, emb_i2i_sim,\</span><br><span class="line">                                                                       sim_user_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>], save_path, <span class="string">&quot;UserCF(emb+usercf)&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 5. UserCF(emb+youtubeuser) recall ===============&quot;</span>)</span><br><span class="line">    user_emb_dict = pickle.load(<span class="built_in">open</span>(save_path / <span class="string">&#x27;user_youtube_emb.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    u2u_sim_dict = u2u_embdding_sim(trn_hist_click_df, user_emb_dict, save_path, topk=<span class="number">10</span>)</span><br><span class="line">    u2u_sim_5 = pickle.load(<span class="built_in">open</span>(save_path / <span class="string">&#x27;youtube_u2u_sim.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>] = usercf_recall_YoutubeUser(trn_hist_click_df, item_topk_click,\</span><br><span class="line">                                                                                         u2u_sim_5, item_creat_dict,\</span><br><span class="line">                                                                                        emb_i2i_sim, save_path,\</span><br><span class="line">                                                                                        sim_user_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>], save_path, <span class="string">&quot;UserCF(emb+youtubeuser)&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n[INFO] 6. Coldstart recall ===============&quot;</span>)</span><br><span class="line">    cold_click_df_ = trn_hist_click_df.copy()</span><br><span class="line">    cold_click_df_ = cold_click_df_.merge(item_info_df, how=<span class="string">&#x27;left&#x27;</span>, on=<span class="string">&#x27;click_article_id&#x27;</span>)</span><br><span class="line">    user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict = get_user_hist_item_info_dict(cold_click_df_)</span><br><span class="line">    click_article_ids_set = <span class="built_in">set</span>(cold_click_df_[<span class="string">&#x27;click_article_id&#x27;</span>].values)</span><br><span class="line">    <span class="comment"># 注意：这里使用了很多规则来筛选冷启动的文章，所以前面再召回的阶段就应该尽可能的多召回一些文章，否则很容易被删掉</span></span><br><span class="line">    user_recall_items_dict = cold_start_prepare(cold_click_df_, i2i_sim, item_topk_click, \</span><br><span class="line">                                                save_path, item_creat_dict, emb_i2i_sim)</span><br><span class="line">    cold_start_user_items_dict = cold_start_recall(user_recall_items_dict, user_hist_item_typs_dict, \</span><br><span class="line">                                                   user_hist_item_words_dict, user_last_item_created_time_dict, \</span><br><span class="line">                                                    item_category_dict, item_words_dict, item_creat_dict, \</span><br><span class="line">                                                    click_article_ids_set, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;Coldstart_recall&#x27;</span>] = cold_start_user_items_dict</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;Coldstart_recall&#x27;</span>], save_path, <span class="string">&quot;Coldstart&quot;</span>)</span><br><span class="line">    metrics_recall(user_multi_recall_dict[<span class="string">&#x27;Coldstart_recall&#x27;</span>], trn_last_click_df, topk=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 线上提交：只召回</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    item_topk_click = get_item_topk_click(all_click_df, k=<span class="number">50</span>)</span><br><span class="line">    <span class="comment"># 1</span></span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;YoutubeDNN_recall&#x27;</span>] = YoutubeDNN_u2i_dict(all_click_df, save_path, topk=<span class="number">20</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;YoutubeDNN_recall&#x27;</span>], save_path, <span class="string">&quot;YoutubeDNN&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2</span></span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>] = itemcf_recall(all_click_df, item_topk_click, \</span><br><span class="line">                                        i2i_sim, save_path, \</span><br><span class="line">                                        sim_item_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>, \</span><br><span class="line">                                        emb_i2i_sim=<span class="literal">None</span>, item_creat_dict=<span class="literal">None</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(itemcf)_recall&#x27;</span>], save_path, <span class="string">&quot;ItemCF(itemcf)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3</span></span><br><span class="line">    i2i_sim_3 = emb_i2i_sim</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>] = itemcf_recall(all_click_df, item_topk_click, \</span><br><span class="line">                                        i2i_sim_3, save_path, \</span><br><span class="line">                                        sim_item_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>, \</span><br><span class="line">                                        emb_i2i_sim=<span class="literal">None</span>, item_creat_dict=<span class="literal">None</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;ItemCF(emb)_recall&#x27;</span>], save_path, <span class="string">&quot;ItemCF(emb)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4</span></span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>] = usercf_recall(all_click_df, item_topk_click, \</span><br><span class="line">                                                                       u2u_sim, item_creat_dict, emb_i2i_sim,\</span><br><span class="line">                                                                       sim_user_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+usercf)_recall&#x27;</span>], save_path, <span class="string">&quot;UserCF(emb+usercf)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5</span></span><br><span class="line">    user_emb_dict = pickle.load(<span class="built_in">open</span>(save_path / <span class="string">&#x27;user_youtube_emb.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    u2u_sim_dict = u2u_embdding_sim(all_click_df, user_emb_dict, save_path, topk=<span class="number">10</span>)</span><br><span class="line">    u2u_sim_5 = pickle.load(<span class="built_in">open</span>(save_path / <span class="string">&#x27;youtube_u2u_sim.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>] = usercf_recall_YoutubeUser(all_click_df, item_topk_click,\</span><br><span class="line">                                                                                         u2u_sim_5, item_creat_dict,\</span><br><span class="line">                                                                                        emb_i2i_sim, save_path,\</span><br><span class="line">                                                                                        sim_user_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;UserCF(emb+youtubeuser)_recall&#x27;</span>], save_path, <span class="string">&quot;UserCF(emb+youtubeuser)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6</span></span><br><span class="line">    cold_click_df_ = all_click_df.copy()</span><br><span class="line">    cold_click_df_ = cold_click_df_.merge(item_info_df, how=<span class="string">&#x27;left&#x27;</span>, on=<span class="string">&#x27;click_article_id&#x27;</span>)</span><br><span class="line">    user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict = get_user_hist_item_info_dict(cold_click_df_)</span><br><span class="line">    click_article_ids_set = <span class="built_in">set</span>(cold_click_df_[<span class="string">&#x27;click_article_id&#x27;</span>].values)</span><br><span class="line">    user_recall_items_dict = cold_start_prepare(cold_click_df_, i2i_sim, item_topk_click, \</span><br><span class="line">                                                save_path, item_creat_dict, emb_i2i_sim)</span><br><span class="line">    cold_start_user_items_dict = cold_start_recall(user_recall_items_dict, user_hist_item_typs_dict, \</span><br><span class="line">                                                   user_hist_item_words_dict, user_last_item_created_time_dict, \</span><br><span class="line">                                                    item_category_dict, item_words_dict, item_creat_dict, \</span><br><span class="line">                                                    click_article_ids_set, recall_item_num=<span class="number">10</span>)</span><br><span class="line">    user_multi_recall_dict[<span class="string">&#x27;Coldstart_recall&#x27;</span>] = cold_start_user_items_dict</span><br><span class="line">    save_recall(user_multi_recall_dict[<span class="string">&#x27;Coldstart_recall&#x27;</span>], save_path, <span class="string">&quot;Coldstart&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终合并之后每个用户召回150个商品进行排序</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n[INFO] Combine recall results ===============&quot;</span>)</span><br><span class="line">final_recall_items_dict_rank = combine_recall_results(user_multi_recall_dict, weight_dict, topk=<span class="number">30</span>)</span><br><span class="line">save_recall(final_recall_items_dict_rank, save_path, <span class="string">&quot;Final&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> metric_recall:</span><br><span class="line">    metrics_recall(final_recall_items_dict_rank, trn_last_click_df, topk=<span class="number">30</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    tst_user = tst_click[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line">    final_recall_items_dict_rank = final_recall_items_dict_rank[final_recall_items_dict_rank[<span class="string">&#x27;user_id&#x27;</span>].isin(tst_user)]</span><br><span class="line">    submit(final_recall_items_dict_rank, save_path, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;multi-recall&#x27;</span>)</span><br><span class="line"></span><br><span class="line">END_TIME = datetime.now()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;\n[INFO] <span class="subst">&#123;END_TIME.strftime(<span class="string">&quot;%H:%M:%S&quot;</span>)&#125;</span> Finished. (<span class="subst">&#123;(END_TIME-START_TIME).total_seconds()/<span class="number">60</span>:<span class="number">.2</span>f&#125;</span> mins)&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="utils-py-2"><code>utils.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, time, pickle, faiss</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> find_dotenv, load_dotenv</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">submit</span>(<span class="params">recall_df, save_path, topk=<span class="number">5</span>, model_name=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 生成排名</span></span><br><span class="line">    recall_df = recall_df.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    recall_df[<span class="string">&#x27;rank&#x27;</span>] = recall_df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    <span class="comment"># 保证都有5篇以上</span></span><br><span class="line">    tmp = recall_df.groupby(<span class="string">&#x27;user_id&#x27;</span>).apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;rank&#x27;</span>].<span class="built_in">max</span>())</span><br><span class="line">    <span class="keyword">assert</span> tmp.<span class="built_in">min</span>() &gt; topk</span><br><span class="line">    <span class="comment"># 把排名改为按要求的1-5横向摆放</span></span><br><span class="line">    <span class="keyword">del</span> recall_df[<span class="string">&#x27;pred_score&#x27;</span>]</span><br><span class="line">    submit = recall_df[recall_df[<span class="string">&#x27;rank&#x27;</span>]&lt;=topk].set_index([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>]).unstack(-<span class="number">1</span>).reset_index()</span><br><span class="line">    submit.columns = [<span class="built_in">int</span>(col) <span class="keyword">if</span> <span class="built_in">isinstance</span>(col, <span class="built_in">int</span>) <span class="keyword">else</span> col <span class="keyword">for</span> col <span class="keyword">in</span> submit.columns.droplevel(<span class="number">0</span>)]</span><br><span class="line">    submit = submit.rename(columns = &#123;<span class="string">&#x27;&#x27;</span>:<span class="string">&#x27;user_id&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;article_1&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;article_2&#x27;</span>, <span class="number">3</span>:<span class="string">&#x27;article_3&#x27;</span>, </span><br><span class="line">                                      <span class="number">4</span>:<span class="string">&#x27;article_4&#x27;</span>, <span class="number">5</span>:<span class="string">&#x27;article_5&#x27;</span>&#125;)</span><br><span class="line">    save_name = save_path / <span class="string">f&quot;<span class="subst">&#123;model_name&#125;</span>_<span class="subst">&#123;datetime.now().strftime(<span class="string">&#x27;%m-%d %H:%M&#x27;</span>)&#125;</span>.csv&quot;</span></span><br><span class="line">    submit.to_csv(save_name, index=<span class="literal">False</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_recall</span>(<span class="params">user_recall_items_dict, save_path, recall_name</span>):</span><br><span class="line">    tt = datetime.now().strftime(<span class="string">&quot;%m-%d %H:%M&quot;</span>)</span><br><span class="line">    save_name = save_path / <span class="string">f&#x27;<span class="subst">&#123;recall_name&#125;</span>_recall_<span class="subst">&#123;tt&#125;</span>.pkl&#x27;</span></span><br><span class="line">    pickle.dump(user_recall_items_dict, <span class="built_in">open</span>(save_name, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;itemcf recall结果保存:<span class="subst">&#123;save_name&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估函数 (Hit@5、10/15/20/25/30...)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">metrics_recall</span>(<span class="params">user_recall_item_dict, trn_last_item_df, topk=<span class="number">30</span></span>):</span><br><span class="line">    last_item_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(trn_last_item_df[<span class="string">&#x27;user_id&#x27;</span>], trn_last_item_df[<span class="string">&#x27;click_article_id&#x27;</span>]))</span><br><span class="line">    total_num = <span class="built_in">len</span>(last_item_dict)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>, topk+<span class="number">1</span>, <span class="number">5</span>):</span><br><span class="line">        hit_num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> user, items <span class="keyword">in</span> user_recall_item_dict.items():</span><br><span class="line">            items_set = <span class="built_in">set</span>([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> items[:k]])</span><br><span class="line">            <span class="keyword">if</span> last_item_dict[user] <span class="keyword">in</span> items_set:</span><br><span class="line">                hit_num += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Hit@<span class="subst">&#123;k&#125;</span> \t <span class="subst">&#123;<span class="number">100</span>*hit_num/total_num :<span class="number">5.2</span>f&#125;</span>% (<span class="subst">&#123;hit_num&#125;</span>/<span class="subst">&#123;total_num&#125;</span>)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载环境函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_env_with_fallback</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    envpath = find_dotenv(usecwd=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> envpath:</span><br><span class="line">        load_dotenv(envpath)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已加载 .env 文件：&quot;</span>, envpath)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未找到 .env 文件&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.getenv(<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>):</span><br><span class="line">            os.environ[<span class="string">&#x27;FUNREC_RAW_DATA_PATH&#x27;</span>] = <span class="built_in">str</span>(Path.cwd()) / <span class="string">&quot;dataset&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>):</span><br><span class="line">            os.environ[<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>] = <span class="built_in">str</span>(Path.cwd()) / <span class="string">&quot;dataset_processed&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># df 节省内存</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reduce_mem</span>(<span class="params">df</span>):</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    start_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span>**<span class="number">2</span></span><br><span class="line">    numerics = [<span class="string">&#x27;int16&#x27;</span>, <span class="string">&#x27;int32&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>, <span class="string">&#x27;float16&#x27;</span>, <span class="string">&#x27;float32&#x27;</span>, <span class="string">&#x27;float64&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        col_type = df[col].dtypes</span><br><span class="line">        <span class="keyword">if</span> col_type <span class="keyword">in</span> numerics:</span><br><span class="line">            dmin = df[col].<span class="built_in">min</span>()</span><br><span class="line">            dmax = df[col].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> pd.isnull(dmin) <span class="keyword">or</span> pd.isnull(dmax):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(col_type)[:<span class="number">3</span>] == <span class="string">&#x27;int&#x27;</span>:</span><br><span class="line">                    <span class="keyword">if</span> dmin &gt; np.iinfo(np.int8).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int8).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int8)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.int16).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int16).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int16)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.int32).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.int32).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int32)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.int64)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> dmin &gt; np.iinfo(np.float16).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.float16).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float16)</span><br><span class="line">                    <span class="keyword">elif</span> dmin &gt; np.iinfo(np.float32).<span class="built_in">min</span> <span class="keyword">and</span> dmax &lt; np.iinfo(np.float32).<span class="built_in">max</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float32)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        df[col] = df[col].astype(np.float64)</span><br><span class="line">    end_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span>**<span class="number">2</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Memory usage decreased to &#123;:5.2f&#125;Mb(&#123;:.2f&#125;% redcution), time spend &#123;:.2f&#125; min&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        end_mem, <span class="number">100</span>*(start_mem-end_mem)/start_mem, (start_time-end_time)/<span class="number">60</span>))</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样部分数据进行 调试、线下开发、线上提交</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_click_sample</span>(<span class="params">data_path, sample_num=<span class="number">20000</span></span>):</span><br><span class="line">    all_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)</span><br><span class="line">    all_user_ids = all_click[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">    sample_user_ids = np.random.choice(all_user_ids ,size=sample_num, replace=<span class="literal">False</span>)</span><br><span class="line">    all_click = all_click[all_click[<span class="string">&#x27;user_id&#x27;</span>].isin(sample_user_ids)]</span><br><span class="line"></span><br><span class="line">    all_click = all_click.drop_duplicates([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> all_click</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_click_df</span>(<span class="params">data_path, offline=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">if</span> offline:</span><br><span class="line">        all_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)[:<span class="number">20000</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        tst_click = pd.read_csv(data_path / <span class="string">&#x27;testA_click_log.csv&#x27;</span>)</span><br><span class="line">        trn_click = pd.read_csv(data_path / <span class="string">&quot;train_click_log.csv&quot;</span>)</span><br><span class="line">        <span class="comment"># trn_click = pd.read_csv(data_path / &quot;train_click_log.csv&quot;)[:10000]</span></span><br><span class="line">        <span class="comment"># tst_click = pd.read_csv(data_path / &#x27;testA_click_log.csv&#x27;)[:10000]</span></span><br><span class="line">        all_click = pd.concat([trn_click, tst_click])</span><br><span class="line">    </span><br><span class="line">    all_click = all_click.drop_duplicates([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> all_click</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取历史和最后一次点击</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_hist_last_click</span>(<span class="params">all_click</span>):</span><br><span class="line">    all_click = all_click.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>])</span><br><span class="line">    last_click_df = all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>).tail(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hist_func</span>(<span class="params">df</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(df) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> df</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> df[:-<span class="number">1</span>]</span><br><span class="line">    hist_click_df = all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>).apply(hist_func).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> last_click_df, hist_click_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户 - 文章，点击</span></span><br><span class="line"><span class="comment"># &#123;user1:[(item,time),(item,time)], ..., user2:[...]&#125;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user_item_time</span>(<span class="params">click_df</span>):</span><br><span class="line">    click_df = click_df.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_item_time_list</span>(<span class="params">df</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(df[<span class="string">&#x27;click_article_id&#x27;</span>], df[<span class="string">&#x27;click_timestamp&#x27;</span>]))</span><br><span class="line">    click_df = click_df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[[<span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;click_timestamp&#x27;</span>]] \</span><br><span class="line">                        .apply(make_item_time_list) \</span><br><span class="line">                        .reset_index() \</span><br><span class="line">                        .rename(columns=&#123;<span class="number">0</span>:<span class="string">&#x27;item_time_list&#x27;</span>&#125;)</span><br><span class="line">    user_item_time_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(click_df[<span class="string">&#x27;user_id&#x27;</span>], click_df[<span class="string">&#x27;item_time_list&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> user_item_time_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文章 - 用户，点击</span></span><br><span class="line"><span class="comment"># &#123;item1: [(user1, time), (user2, time)], ... , item2:[...]&#125;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_user_time</span>(<span class="params">click_df</span>):</span><br><span class="line">    click_df = click_df.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_user_time_list</span>(<span class="params">df</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(df[<span class="string">&#x27;user_id&#x27;</span>], df[<span class="string">&#x27;click_timestamp&#x27;</span>]))</span><br><span class="line">    item_user_df = click_df.groupby(<span class="string">&#x27;click_article_id&#x27;</span>)[[<span class="string">&#x27;user_id&#x27;</span>,<span class="string">&#x27;click_timestamp&#x27;</span>]] \</span><br><span class="line">                        .apply(make_user_time_list) \</span><br><span class="line">                        .reset_index() \</span><br><span class="line">                        .rename(columns=&#123;<span class="number">0</span>:<span class="string">&#x27;user_time_list&#x27;</span>&#125;)</span><br><span class="line">    item_user_time_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_user_df[<span class="string">&#x27;click_article_id&#x27;</span>], item_user_df[<span class="string">&#x27;user_time_list&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> item_user_time_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最热门的K个新闻(返回新闻id)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_topk_click</span>(<span class="params">click_df, k</span>):</span><br><span class="line">    <span class="keyword">return</span> click_df[<span class="string">&#x27;click_article_id&#x27;</span>].value_counts().index[:k]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文章信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_info_df</span>(<span class="params">data_path</span>):</span><br><span class="line">    item_info_df = pd.read_csv(data_path / <span class="string">&#x27;articles.csv&#x27;</span>)</span><br><span class="line">    item_info_df = item_info_df.rename(columns=&#123;<span class="string">&#x27;article_id&#x27;</span>: <span class="string">&#x27;click_article_id&#x27;</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> item_info_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文章属性字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_info_dict</span>(<span class="params">item_info_df</span>):</span><br><span class="line">    max_min_scaler = <span class="keyword">lambda</span> x: (x-np.<span class="built_in">min</span>(x)) / (np.<span class="built_in">max</span>(x)-np.<span class="built_in">min</span>(x))</span><br><span class="line">    item_info_df[<span class="string">&#x27;created_at_ts&#x27;</span>] = item_info_df[[<span class="string">&#x27;created_at_ts&#x27;</span>]].apply(max_min_scaler)</span><br><span class="line"></span><br><span class="line">    item_creat_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_info_df[<span class="string">&#x27;click_article_id&#x27;</span>], item_info_df[<span class="string">&#x27;created_at_ts&#x27;</span>]))</span><br><span class="line">    item_category_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_info_df[<span class="string">&#x27;click_article_id&#x27;</span>], item_info_df[<span class="string">&#x27;category_id&#x27;</span>]))</span><br><span class="line">    item_words_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_info_df[<span class="string">&#x27;click_article_id&#x27;</span>], item_info_df[<span class="string">&#x27;words_count&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item_creat_dict, item_category_dict, item_words_dict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文章embedding_df</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_emb_df</span>(<span class="params">data_path</span>):</span><br><span class="line">    item_emb_df = pd.read_csv(data_path / <span class="string">&#x27;articles_emb.csv&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> item_emb_df</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文章的 embedding 字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_item_emb_dict</span>(<span class="params">data_path, save_path</span>):</span><br><span class="line">    item_emb_df = pd.read_csv(data_path / <span class="string">&#x27;articles_emb.csv&#x27;</span>)</span><br><span class="line">    cols = [x <span class="keyword">for</span> x <span class="keyword">in</span> item_emb_df.columns <span class="keyword">if</span> <span class="string">&#x27;emb&#x27;</span> <span class="keyword">in</span> x]</span><br><span class="line">    emb_np = np.ascontiguousarray(item_emb_df[cols])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># L2归一化：每个 item 的 embedding 向量做 L2 归一化，使其模长为 1</span></span><br><span class="line">    <span class="comment"># 从而在后续计算中可以用点积直接表示余弦相似度，常用于向量召回和内容推荐。</span></span><br><span class="line">    emb_np = emb_np / np.linalg.norm(emb_np, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    emb_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_emb_df[<span class="string">&#x27;article_id&#x27;</span>], emb_np))</span><br><span class="line">    pickle.dump(emb_dict, <span class="built_in">open</span>(save_path / <span class="string">&quot;item_content_emb.pkl&quot;</span>, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> emb_dict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户-历史文章信息 字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user_hist_item_info_dict</span>(<span class="params">all_click</span>):</span><br><span class="line">    <span class="comment"># 历史文章id </span></span><br><span class="line">    item_ids = all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;click_article_id&#x27;</span>].agg(<span class="built_in">set</span>).reset_index()</span><br><span class="line">    item_ids_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_ids[<span class="string">&#x27;user_id&#x27;</span>], item_ids[<span class="string">&#x27;click_article_id&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 历史文章类型</span></span><br><span class="line">    item_cats = all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;category_id&#x27;</span>].agg(<span class="built_in">set</span>).reset_index()</span><br><span class="line">    item_cats_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_cats[<span class="string">&#x27;user_id&#x27;</span>], item_cats[<span class="string">&#x27;category_id&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 历史文章平均字数</span></span><br><span class="line">    item_words = all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;words_count&#x27;</span>].agg(<span class="string">&#x27;mean&#x27;</span>).reset_index()</span><br><span class="line">    item_words_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_words[<span class="string">&#x27;user_id&#x27;</span>], item_words[<span class="string">&#x27;words_count&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 历史文章最近相对新鲜度</span></span><br><span class="line">    all_click = all_click.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">    item_last_time = (</span><br><span class="line">        all_click.groupby(<span class="string">&#x27;user_id&#x27;</span>)</span><br><span class="line">                .tail(<span class="number">1</span>)[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;created_at_ts&#x27;</span>]]</span><br><span class="line">                .reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">    max_min_scaler = <span class="keyword">lambda</span> x: (x-np.<span class="built_in">min</span>(x)) / (np.<span class="built_in">max</span>(x)-np.<span class="built_in">min</span>(x))</span><br><span class="line">    item_last_time[<span class="string">&#x27;created_at_ts&#x27;</span>] = item_last_time[[<span class="string">&#x27;created_at_ts&#x27;</span>]].apply(max_min_scaler)</span><br><span class="line">    item_last_time_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_last_time[<span class="string">&#x27;user_id&#x27;</span>], item_last_time[<span class="string">&#x27;created_at_ts&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item_ids_dict, item_cats_dict, item_words_dict, item_last_time_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户相对活跃度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user_active_degree_dict</span>(<span class="params">all_click_df</span>):</span><br><span class="line">    all_click_df = all_click_df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;click_article_id&#x27;</span>].count().reset_index()</span><br><span class="line">    mm = MinMaxScaler()</span><br><span class="line">    all_click_df[<span class="string">&#x27;active_degree&#x27;</span>] = mm.fit_transform(all_click_df[[<span class="string">&#x27;click_article_id&#x27;</span>]])</span><br><span class="line">    active_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(all_click_df[<span class="string">&#x27;user_id&#x27;</span>], all_click_df[<span class="string">&#x27;active_degree&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> active_dict</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 向量检索相似度计算</span></span><br><span class="line"><span class="comment"># 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章， 只不过由于文章数量太多，这里用了faiss进行加速</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embedding_sim</span>(<span class="params">click_df, item_emb_df, save_path, topk</span>):</span><br><span class="line">    <span class="comment"># 保存原始索引</span></span><br><span class="line">    item_idx2rawid_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_emb_df.index, item_emb_df[<span class="string">&#x27;article_id&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备纯数值，并单位化</span></span><br><span class="line">    cols = [x <span class="keyword">for</span> x <span class="keyword">in</span> item_emb_df.columns <span class="keyword">if</span> <span class="string">&#x27;emb&#x27;</span> <span class="keyword">in</span> x]</span><br><span class="line">    item_emb_np = np.ascontiguousarray(</span><br><span class="line">        item_emb_df[cols],</span><br><span class="line">        dtype=np.float32   <span class="comment"># faiss必须是float32</span></span><br><span class="line">    )</span><br><span class="line">    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># faiss索引：建立标准、添加数据、搜索topk个</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;faiss 正在处理(等待时间较长)...&#x27;</span>)</span><br><span class="line">    item_index = faiss.IndexFlatIP(item_emb_np.shape[<span class="number">1</span>])  <span class="comment"># 使用InnerProduct内积计算相似度，数据维度数为250维</span></span><br><span class="line">    item_index.add(item_emb_np)</span><br><span class="line">    sim_list, idx_list = item_index.search(item_emb_np, topk+<span class="number">1</span>)  <span class="comment"># 由于第一个会是自己，因此要找topk+1个出来</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;faiss 处理完毕.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立成为i2i矩阵</span></span><br><span class="line">    Sim = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    <span class="keyword">for</span> i, sim_l, idx_l <span class="keyword">in</span> tqdm(<span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(item_emb_np)), sim_list, idx_list), desc=<span class="string">&#x27;embedding_sim&#x27;</span>):</span><br><span class="line">        target_rawid = item_idx2rawid_dict[i]</span><br><span class="line">        <span class="keyword">for</span> sim, idx <span class="keyword">in</span> <span class="built_in">zip</span>(sim_l[<span class="number">1</span>:], idx_l[<span class="number">1</span>:]):  <span class="comment"># 第一个是自己，去掉</span></span><br><span class="line">            related_rawid = item_idx2rawid_dict[idx]</span><br><span class="line">            Sim[target_rawid][related_rawid] += sim</span><br><span class="line">    </span><br><span class="line">    i2i_sim = <span class="built_in">dict</span>(Sim)</span><br><span class="line">    save_name = save_path / <span class="string">&#x27;emb_i2i_sim.pkl&#x27;</span></span><br><span class="line">    pickle.dump(i2i_sim, <span class="built_in">open</span>(save_name, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;content-based相似度矩阵保存：<span class="subst">&#123;save_name&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> i2i_sim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_recall_results</span>(<span class="params">user_multi_recall_dict, weight_dict=<span class="literal">None</span>, topk=<span class="number">25</span></span>):</span><br><span class="line">    <span class="comment"># 对每一种召回结果按照用户进行归一化，方便后面多种召回结果，相同用户的物品之间权重相加</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">norm_user_recall_items_sim</span>(<span class="params">sorted_item_list</span>):</span><br><span class="line">        <span class="comment"># 如果冷启动中没有文章或者只有一篇文章，直接返回，出现这种情况的原因可能是冷启动召回的文章数量太少了，</span></span><br><span class="line">        <span class="comment"># 基于规则筛选之后就没有文章了, 这里还可以做一些其他的策略性的筛选</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(sorted_item_list) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> sorted_item_list</span><br><span class="line"></span><br><span class="line">        min_sim = sorted_item_list[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        max_sim = sorted_item_list[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        norm_sorted_item_list = []</span><br><span class="line">        <span class="keyword">for</span> item, score <span class="keyword">in</span> sorted_item_list:</span><br><span class="line">            <span class="keyword">if</span> max_sim &gt; <span class="number">0</span>:</span><br><span class="line">                norm_score = <span class="number">1.0</span> * (score - min_sim) / (max_sim - min_sim) <span class="keyword">if</span> max_sim &gt; min_sim <span class="keyword">else</span> <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                norm_score = <span class="number">0.0</span></span><br><span class="line">            norm_sorted_item_list.append((item, norm_score))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> norm_sorted_item_list</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;多路召回合并...&#x27;</span>)</span><br><span class="line">    final_recall_items_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> method, user_recall_items <span class="keyword">in</span> tqdm(user_multi_recall_dict.items(), desc=<span class="string">&#x27;Combine results&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(method + <span class="string">&#x27;...&#x27;</span>)</span><br><span class="line">        <span class="comment"># 在计算最终召回结果的时候，也可以为每一种召回结果设置一个权重</span></span><br><span class="line">        <span class="keyword">if</span> weight_dict == <span class="literal">None</span>:</span><br><span class="line">            recall_method_weight = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            recall_method_weight = weight_dict[method]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> user_id, sorted_item_list <span class="keyword">in</span> user_recall_items.items(): <span class="comment"># 进行归一化</span></span><br><span class="line">            user_recall_items[user_id] = norm_user_recall_items_sim(sorted_item_list)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> user_id, sorted_item_list <span class="keyword">in</span> user_recall_items.items():</span><br><span class="line">            final_recall_items_dict.setdefault(user_id, &#123;&#125;)</span><br><span class="line">            <span class="keyword">for</span> item, score <span class="keyword">in</span> sorted_item_list:</span><br><span class="line">                final_recall_items_dict[user_id].setdefault(item, <span class="number">0</span>)</span><br><span class="line">                final_recall_items_dict[user_id][item] += recall_method_weight * score</span><br><span class="line"></span><br><span class="line">    final_recall_items_dict_rank = &#123;&#125;</span><br><span class="line">    <span class="comment"># 多路召回时也可以控制最终的召回数量</span></span><br><span class="line">    <span class="keyword">for</span> user, recall_item_dict <span class="keyword">in</span> final_recall_items_dict.items():</span><br><span class="line">        final_recall_items_dict_rank[user] = <span class="built_in">sorted</span>(recall_item_dict.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:topk]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> final_recall_items_dict_rank</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="model-itemcf-py-2"><code>model_itemcf.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_user_item_time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># itemcf 相似度矩阵计算</span></span><br><span class="line"><span class="comment"># Sim = 共现权重W(i,j) / sqrt(Ni用户数, Nj用户数)</span></span><br><span class="line"><span class="comment"># 其中共现权重不是直接次数，而是这个用户是否活跃 1/log(活跃数+1)是权值</span></span><br><span class="line"><span class="comment"># 关联规则: 1. 用户点击的时间权重 2. 用户点击的顺序权重 3. 文章创建的时间权重</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">itemcf_sim</span>(<span class="params">df, save_path, item_creat_dict=<span class="literal">None</span></span>):</span><br><span class="line">    user_item_time_dict = get_user_item_time(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算共现权重W、每个物品的用户数Ni</span></span><br><span class="line">    Wij = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    Ni = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> user, item_list <span class="keyword">in</span> tqdm(user_item_time_dict.items(), desc=<span class="string">&#x27;ItemCF_sim&#x27;</span>):</span><br><span class="line">        len_w = math.log(<span class="built_in">len</span>(item_list)+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> iloc, (i, i_time) <span class="keyword">in</span> <span class="built_in">enumerate</span>(item_list):</span><br><span class="line">            Ni[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> jloc, (j, j_time) <span class="keyword">in</span> <span class="built_in">enumerate</span>(item_list):</span><br><span class="line">                <span class="keyword">if</span> i == j:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                dir_w = <span class="number">1.0</span> <span class="keyword">if</span> jloc&gt;iloc <span class="keyword">else</span> <span class="number">0.7</span></span><br><span class="line">                loc_w = dir_w * (<span class="number">0.9</span> ** (np.<span class="built_in">abs</span>(jloc-iloc)-<span class="number">1</span>))</span><br><span class="line">                t_click_w = np.exp(<span class="number">0.7</span> ** np.<span class="built_in">abs</span>(j_time-i_time))</span><br><span class="line">                <span class="keyword">if</span> item_creat_dict:</span><br><span class="line">                    t_creat_w = np.exp(<span class="number">0.8</span> ** np.<span class="built_in">abs</span>(item_creat_dict[j]-item_creat_dict[i]))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    t_creat_w = <span class="number">1.0</span></span><br><span class="line">                Wij[i][j] += loc_w * t_click_w * t_creat_w * <span class="number">1.0</span> / len_w</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 Sim</span></span><br><span class="line">    Sim = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    <span class="keyword">for</span> i, wj <span class="keyword">in</span> Wij.items():</span><br><span class="line">        <span class="keyword">for</span> j, w <span class="keyword">in</span> wj.items():</span><br><span class="line">            Sim[i][j] = w / math.sqrt(Ni[i] * Ni[j])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转为普通字典</span></span><br><span class="line">    i2i_Sim = <span class="built_in">dict</span>(Sim)</span><br><span class="line">    <span class="comment"># 存储相似度矩阵</span></span><br><span class="line">    save_name = save_path / <span class="string">&#x27;itemcf_i2i_sim.pkl&#x27;</span></span><br><span class="line">    pickle.dump(i2i_Sim, <span class="built_in">open</span>(save_name, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;itemcf相似度矩阵保存：<span class="subst">&#123;save_name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> i2i_Sim</span><br><span class="line"></span><br><span class="line"><span class="comment"># itemcf 召回</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">item_based_recommend</span>(<span class="params">user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click,</span></span><br><span class="line"><span class="params">                         item_creat_dict=<span class="literal">None</span>, emb_i2i_sim=<span class="literal">None</span></span>):</span><br><span class="line">    user_history = user_item_time_dict[user_id]</span><br><span class="line">    <span class="comment"># user_history = [item for item, _ in user_history]</span></span><br><span class="line"></span><br><span class="line">    item_rank = defaultdict(<span class="built_in">float</span>)</span><br><span class="line">    <span class="comment"># 每个历史物品都找到 k 个相似物品（此处k不是最终数量）</span></span><br><span class="line">    <span class="keyword">for</span> iloc, (i, click_time) <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_history):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> i2i_sim: <span class="comment"># 没有相似的物品，不在相似度矩阵中</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        items = <span class="built_in">sorted</span>(i2i_sim[i].items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:sim_item_topk]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j, w <span class="keyword">in</span> items:</span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">in</span> user_history:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 文章创建时间差权重</span></span><br><span class="line">            creat_w = np.exp(<span class="number">0.8</span> ** np.<span class="built_in">abs</span>(item_creat_dict[i] - item_creat_dict[j])) \</span><br><span class="line">                                    <span class="keyword">if</span> item_creat_dict <span class="keyword">else</span> <span class="number">1.0</span></span><br><span class="line">            <span class="comment"># 相似文章和历史点击文章序列中历史文章所在的位置权重</span></span><br><span class="line">            loc_w = (<span class="number">0.9</span> ** (<span class="built_in">len</span>(user_history) - iloc))</span><br><span class="line">            <span class="comment"># 文章内容相似度权重</span></span><br><span class="line">            content_w = <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">if</span> emb_i2i_sim:</span><br><span class="line">                <span class="keyword">if</span> emb_i2i_sim.get(i, &#123;&#125;).get(j, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    content_w += emb_i2i_sim[i][j]</span><br><span class="line">                <span class="keyword">if</span> emb_i2i_sim.get(j, &#123;&#125;).get(i, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    content_w += emb_i2i_sim[j][i]</span><br><span class="line"></span><br><span class="line">            item_rank[j] += w * creat_w * loc_w * content_w</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数量不足则用热门补全</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(item_rank) &lt; recall_item_num:</span><br><span class="line">        <span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(item_topk_click):</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> item_rank:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            item_rank[i] = -idx-<span class="number">100</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(item_rank) == recall_item_num:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 排序输出最终所需的K个（这里是最终的召回K）</span></span><br><span class="line">    res = <span class="built_in">sorted</span>(item_rank.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:recall_item_num]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行 itemcf 召回</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">itemcf_recall</span>(<span class="params">hist_click_df, item_topk_click, i2i_sim, save_path, item_creat_dict, emb_i2i_sim, sim_item_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span></span>):</span><br><span class="line">    user_recall_items_dict = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    user_item_time_dict = get_user_item_time(hist_click_df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> tqdm(hist_click_df[<span class="string">&#x27;user_id&#x27;</span>].unique(), desc=<span class="string">&#x27;ItemCF i2i recall&#x27;</span>):</span><br><span class="line">        user_recall_items_dict[user] = item_based_recommend(</span><br><span class="line">                                            user, user_item_time_dict, i2i_sim, \</span><br><span class="line">                                            sim_item_topk, recall_item_num, item_topk_click, \</span><br><span class="line">                                            item_creat_dict, emb_i2i_sim</span><br><span class="line">                                        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_recall_items_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cold_start_prepare</span>(<span class="params">hist_click_df, i2i_sim, item_topk_click, save_path, item_creat_dict, emb_i2i_sim</span>):</span><br><span class="line">    <span class="comment"># 先进行itemcf召回，这里不需要做召回评估，这里只是一种策略</span></span><br><span class="line">    sim_item_topk = <span class="number">150</span></span><br><span class="line">    recall_item_num = <span class="number">100</span> <span class="comment"># 稍微召回多一点文章，便于后续的规则筛选</span></span><br><span class="line">    user_recall_items_dict = itemcf_recall(hist_click_df, item_topk_click, i2i_sim, save_path, \</span><br><span class="line">                  item_creat_dict, emb_i2i_sim,\</span><br><span class="line">                      sim_item_topk, recall_item_num)  </span><br><span class="line">    <span class="keyword">return</span> user_recall_items_dict</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于规则进行文章过滤</span></span><br><span class="line"><span class="comment"># 保留文章主题与用户历史浏览主题相似的文章</span></span><br><span class="line"><span class="comment"># 保留文章字数与用户历史浏览文章字数相差不大的文章</span></span><br><span class="line"><span class="comment"># 保留最后一次点击当天的文章</span></span><br><span class="line"><span class="comment"># 按照相似度返回最终的结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cold_start_recall</span>(<span class="params">user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \</span></span><br><span class="line"><span class="params">                     user_last_item_created_time_dict, item_type_dict, item_words_dict,</span></span><br><span class="line"><span class="params">                     item_created_time_dict, click_article_ids_set, recall_item_num</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        冷启动的情况下召回一些文章</span></span><br><span class="line"><span class="string">        :param user_recall_items_dict: 基于内容embedding相似性召回来的很多文章， 字典， &#123;user1: [item1, item2, ..], &#125;</span></span><br><span class="line"><span class="string">        :param user_hist_item_typs_dict: 字典， 用户点击的文章的主题映射</span></span><br><span class="line"><span class="string">        :param user_hist_item_words_dict: 字典， 用户点击的历史文章的字数映射</span></span><br><span class="line"><span class="string">        :param user_last_item_created_time_idct: 字典，用户点击的历史文章创建时间映射</span></span><br><span class="line"><span class="string">        :param item_tpye_idct: 字典，文章主题映射</span></span><br><span class="line"><span class="string">        :param item_words_dict: 字典，文章字数映射</span></span><br><span class="line"><span class="string">        :param item_created_time_dict: 字典， 文章创建时间映射</span></span><br><span class="line"><span class="string">        :param click_article_ids_set: 集合，用户点击过得文章, 也就是日志里面出现过的文章</span></span><br><span class="line"><span class="string">        :param recall_item_num: 召回文章的数量， 这个指的是没有出现在日志里面的文章数量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cold_start_user_items_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user, item_list <span class="keyword">in</span> tqdm(user_recall_items_dict.items(), desc=<span class="string">&#x27;Cold start recall&#x27;</span>):</span><br><span class="line">        cold_start_user_items_dict.setdefault(user, [])</span><br><span class="line">        <span class="keyword">for</span> item, score <span class="keyword">in</span> item_list:</span><br><span class="line">            <span class="comment"># 获取历史文章信息</span></span><br><span class="line">            hist_item_type_set = user_hist_item_typs_dict[user]</span><br><span class="line">            hist_mean_words = user_hist_item_words_dict[user]</span><br><span class="line">            hist_last_item_created_time = user_last_item_created_time_dict[user]</span><br><span class="line">            hist_last_item_created_time = datetime.fromtimestamp(hist_last_item_created_time)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取当前召回文章的信息</span></span><br><span class="line">            curr_item_type = item_type_dict[item]</span><br><span class="line">            curr_item_words = item_words_dict[item]</span><br><span class="line">            curr_item_created_time = item_created_time_dict[item]</span><br><span class="line">            curr_item_created_time = datetime.fromtimestamp(curr_item_created_time)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 删除：文章不能出现在用户的历史点击中， 然后根据文章主题，文章单词数，文章创建时间进行筛选</span></span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> click_article_ids_set <span class="keyword">or</span> \</span><br><span class="line">                curr_item_type <span class="keyword">not</span> <span class="keyword">in</span> hist_item_type_set <span class="keyword">or</span> \</span><br><span class="line">                <span class="built_in">abs</span>(curr_item_words - hist_mean_words) &gt; <span class="number">200</span> <span class="keyword">or</span> \</span><br><span class="line">                <span class="built_in">abs</span>((curr_item_created_time - hist_last_item_created_time).days) &gt; <span class="number">90</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            cold_start_user_items_dict[user].append((item, score))      <span class="comment"># &#123;user1: [(item1, score1), (item2, score2)..]...&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 需要控制一下冷启动召回的数量</span></span><br><span class="line">    cold_start_user_items_dict = &#123;k: <span class="built_in">sorted</span>(v, key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:recall_item_num] \</span><br><span class="line">                                  <span class="keyword">for</span> k, v <span class="keyword">in</span> cold_start_user_items_dict.items()&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cold_start_user_items_dict</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="model-usercf-py"><code>model_usercf.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math, pickle, faiss</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_item_user_time, get_user_item_time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于用户的协同过滤 UserCF 计算相似度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">usercf_sim</span>(<span class="params">all_click_df, save_path, user_active_dict</span>):</span><br><span class="line">    item_user_time_dict = get_item_user_time(all_click_df)</span><br><span class="line"></span><br><span class="line">    Wuv = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    Nu = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> item, user_time <span class="keyword">in</span> tqdm(item_user_time_dict.items(), desc=<span class="string">&#x27;UserCF_sim&#x27;</span>):</span><br><span class="line">        len_w = <span class="built_in">len</span>(user_time)</span><br><span class="line">        <span class="keyword">for</span> u, ut <span class="keyword">in</span> user_time:</span><br><span class="line">            Nu[u] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> v, vt <span class="keyword">in</span> user_time:</span><br><span class="line">                <span class="keyword">if</span> u == v:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                active_w = <span class="number">100</span> * <span class="number">0.5</span> * (user_active_dict[u] + user_active_dict[v])</span><br><span class="line">                Wuv[u][v] += active_w * <span class="number">1.0</span> / len_w</span><br><span class="line">    </span><br><span class="line">    Sim = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    <span class="keyword">for</span> u, wv <span class="keyword">in</span> Wuv.items():</span><br><span class="line">        <span class="keyword">for</span> v, w <span class="keyword">in</span> wv.items():</span><br><span class="line">            Sim[u][v] = w / math.sqrt(Nu[u] * Nu[v])</span><br><span class="line"></span><br><span class="line">    u2u_sim = <span class="built_in">dict</span>(Sim)</span><br><span class="line">    save_name = save_path / <span class="string">&#x27;usercf_u2u_sim.pkl&#x27;</span></span><br><span class="line">    pickle.dump(u2u_sim, <span class="built_in">open</span>(save_name, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;usercf相似度矩阵保存：<span class="subst">&#123;save_name&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> u2u_sim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于用户的召回 u2u2i</span></span><br><span class="line"><span class="comment"># 第一步的 u2u 看 UserCF_sim</span></span><br><span class="line"><span class="comment"># 第二步的 u2i 看这个相似用户u看的完整中有没有 user_hist 中的相似物品(如何判断物品相似：看emb_sim)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_based_recommend</span>(<span class="params">user_id, user_item_time_dict, u2u_sim, sim_user_topk, recall_item_num,</span></span><br><span class="line"><span class="params">                         item_topk_click, item_created_time_dict, emb_i2i_sim</span>):</span><br><span class="line">    <span class="comment"># 历史交互</span></span><br><span class="line">    user_item_time_list = user_item_time_dict[user_id]    <span class="comment"># &#123;item1: time1, item2: time2...&#125;</span></span><br><span class="line">    user_hist_items = <span class="built_in">set</span>([i <span class="keyword">for</span> i, t <span class="keyword">in</span> user_item_time_list])   <span class="comment"># 存在一个用户与某篇文章的多次交互， 这里得去重</span></span><br><span class="line"></span><br><span class="line">    items_rank = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> user_id <span class="keyword">in</span> u2u_sim:</span><br><span class="line">        <span class="keyword">for</span> sim_u, wuv <span class="keyword">in</span> <span class="built_in">sorted</span>(u2u_sim[user_id].items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:sim_user_topk]:</span><br><span class="line">            <span class="keyword">for</span> i, click_time <span class="keyword">in</span> user_item_time_dict[sim_u]:</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> user_hist_items:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                items_rank.setdefault(i, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                loc_weight = <span class="number">1.0</span></span><br><span class="line">                content_weight = <span class="number">1.0</span></span><br><span class="line">                created_time_weight = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 当前文章与该用户看的历史文章进行一个权重交互</span></span><br><span class="line">                <span class="keyword">for</span> loc, (j, click_time) <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_item_time_list):</span><br><span class="line">                    <span class="comment"># 点击时的相对位置权重</span></span><br><span class="line">                    loc_weight += <span class="number">0.9</span> ** (<span class="built_in">len</span>(user_item_time_list) - loc)</span><br><span class="line">                    <span class="comment"># 内容相似性权重</span></span><br><span class="line">                    <span class="keyword">if</span> emb_i2i_sim.get(i, &#123;&#125;).get(j, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        content_weight += emb_i2i_sim[i][j]</span><br><span class="line">                    <span class="keyword">if</span> emb_i2i_sim.get(j, &#123;&#125;).get(i, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        content_weight += emb_i2i_sim[j][i]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 创建时间差权重</span></span><br><span class="line">                    created_time_weight += np.exp(<span class="number">0.8</span> * np.<span class="built_in">abs</span>(item_created_time_dict[i] - item_created_time_dict[j]))</span><br><span class="line"></span><br><span class="line">                items_rank[i] += loc_weight * content_weight * created_time_weight * wuv</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 热度补全</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(items_rank) &lt; recall_item_num:</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(item_topk_click):</span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> items_rank.items(): <span class="comment"># 填充的item应该不在原来的列表中</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            items_rank[item] = - i - <span class="number">100</span> <span class="comment"># 随便给个复数就行</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(items_rank) == recall_item_num:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    items_rank = <span class="built_in">sorted</span>(items_rank.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:recall_item_num]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> items_rank</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Embedding的方式获取u2u的相似性矩阵</span></span><br><span class="line"><span class="comment"># topk指的是每个user, faiss搜索后返回最相似的topk个user</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">u2u_embdding_sim</span>(<span class="params">click_df, user_emb_dict, save_path, topk</span>):</span><br><span class="line"></span><br><span class="line">    user_list = []</span><br><span class="line">    user_emb_list = []</span><br><span class="line">    <span class="keyword">for</span> user_id, user_emb <span class="keyword">in</span> user_emb_dict.items():</span><br><span class="line">        user_list.append(user_id)</span><br><span class="line">        user_emb_list.append(user_emb)</span><br><span class="line"></span><br><span class="line">    user_index_2_rawid_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(user_list)), user_list)&#125;</span><br><span class="line"></span><br><span class="line">    user_emb_np = np.array(user_emb_list, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立faiss索引</span></span><br><span class="line">    user_index = faiss.IndexFlatIP(user_emb_np.shape[<span class="number">1</span>])</span><br><span class="line">    user_index.add(user_emb_np)</span><br><span class="line">    <span class="comment"># 相似度查询，给每个索引位置上的向量返回topk个item以及相似度</span></span><br><span class="line">    sim, idx = user_index.search(user_emb_np, topk) <span class="comment"># 返回的是列表</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将向量检索的结果保存成原始id的对应关系</span></span><br><span class="line">    user_sim_dict = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    <span class="keyword">for</span> target_idx, sim_value_list, rele_idx_list <span class="keyword">in</span> tqdm(<span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(user_emb_np)), sim, idx), desc=<span class="string">&#x27;UserCF u2u_sim&#x27;</span>):</span><br><span class="line">        target_raw_id = user_index_2_rawid_dict[target_idx]</span><br><span class="line">        <span class="comment"># 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1</span></span><br><span class="line">        <span class="keyword">for</span> rele_idx, sim_value <span class="keyword">in</span> <span class="built_in">zip</span>(rele_idx_list[<span class="number">1</span>:], sim_value_list[<span class="number">1</span>:]):</span><br><span class="line">            rele_raw_id = user_index_2_rawid_dict[rele_idx]</span><br><span class="line">            user_sim_dict[target_raw_id][rele_raw_id] = user_sim_dict.get(target_raw_id, &#123;&#125;).get(rele_raw_id, <span class="number">0</span>) + sim_value</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存i2i相似度矩阵</span></span><br><span class="line">    pickle.dump(user_sim_dict, <span class="built_in">open</span>(save_path / <span class="string">&#x27;youtube_u2u_sim.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> user_sim_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">usercf_recall</span>(<span class="params">hist_click_df, item_topk_click, u2u_sim, item_creat_dict, emb_i2i_sim, sim_user_topk=<span class="number">20</span>, recall_item_num=<span class="number">10</span></span>):</span><br><span class="line">    user_item_time_dict = get_user_item_time(hist_click_df)</span><br><span class="line">    user_recall_items_dict = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> tqdm(hist_click_df[<span class="string">&#x27;user_id&#x27;</span>].unique(), desc=<span class="string">&#x27;UserCF u2u2i recall&#x27;</span>):</span><br><span class="line">        user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, \</span><br><span class="line">                                                            sim_user_topk, recall_item_num, item_topk_click, \</span><br><span class="line">                                                            item_creat_dict, emb_i2i_sim)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> user_recall_items_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">usercf_recall_YoutubeUser</span>(<span class="params">hist_click_df, item_topk_click, u2u_sim, item_creat_dict, emb_i2i_sim, save_path, sim_user_topk=<span class="number">20</span>,recall_item_num=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># UserCF emb u2u2i</span></span><br><span class="line">    <span class="comment"># 读取YoutubeDNN过程中产生的user embedding, 然后使用faiss计算用户之间的相似度</span></span><br><span class="line">    <span class="comment"># 这里需要注意，这里得到的user embedding其实并不是很好，因为YoutubeDNN中使用的是用户点击序列来训练的user embedding,</span></span><br><span class="line">    <span class="comment"># 如果序列普遍都比较短的话，其实效果并不是很好</span></span><br><span class="line">    user_recall_items_dict = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    user_item_time_dict = get_user_item_time(hist_click_df)</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> tqdm(hist_click_df[<span class="string">&#x27;user_id&#x27;</span>].unique(), desc=<span class="string">&#x27;UserCF(YoutubeUser) recall&#x27;</span>):</span><br><span class="line">        user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \</span><br><span class="line">                                                            recall_item_num, item_topk_click, item_creat_dict, emb_i2i_sim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_recall_items_dict</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="model-youtubednn-py"><code>model_youtubednn.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random, pickle, faiss</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> feature <span class="keyword">import</span> FeatureColumn</span><br><span class="line"><span class="keyword">from</span> trainer <span class="keyword">import</span> train_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成所需数据集</span></span><br><span class="line"><span class="comment"># negsample 滑动窗口构建样本时负样本的数量(对于每个正样本选几个负样本)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_data_set</span>(<span class="params">click_df, negsample=<span class="number">0</span></span>):</span><br><span class="line">    click_df = click_df.sort_values(<span class="string">&#x27;click_timestamp&#x27;</span>)</span><br><span class="line">    item_ids = click_df[<span class="string">&#x27;click_article_id&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">    train_set = []</span><br><span class="line">    test_set = []</span><br><span class="line">    <span class="keyword">for</span> uid, hist <span class="keyword">in</span> tqdm(click_df.groupby(<span class="string">&#x27;user_id&#x27;</span>), desc=<span class="string">&#x27;gen_data_set&#x27;</span>):</span><br><span class="line">        pos_list = hist[<span class="string">&#x27;click_article_id&#x27;</span>].tolist()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> negsample &gt; <span class="number">0</span>:</span><br><span class="line">            candidate_set = <span class="built_in">list</span>(<span class="built_in">set</span>(item_ids) - <span class="built_in">set</span>(pos_list))</span><br><span class="line">            neg_list = np.random.choice(candidate_set, size=<span class="built_in">len</span>(pos_list)*negsample, replace=<span class="literal">True</span>) <span class="comment"># 有可能不够，因此允许重复拿</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 滑窗构造正负样本</span></span><br><span class="line">        <span class="comment"># 格式 ( user_id, his_item, pos_item, label, len(his_item) )</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(pos_list)):</span><br><span class="line">            ihist = pos_list[:i]</span><br><span class="line">            ihist = ihist[::-<span class="number">1</span>]   <span class="comment"># 倒序，最近的在最前面</span></span><br><span class="line">            <span class="comment"># 最长的做测试，其余的做训练</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(pos_list)-<span class="number">1</span>:</span><br><span class="line">                test_set.append((uid, ihist, pos_list[i], <span class="number">1</span>, i))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train_set.append((uid, ihist, pos_list[i], <span class="number">1</span>, i))</span><br><span class="line">                <span class="keyword">for</span> negi <span class="keyword">in</span> <span class="built_in">range</span>(negsample):</span><br><span class="line">                    train_set.append((uid, ihist, neg_list[i*negsample+negi], <span class="number">0</span>, i))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对于只有一个数据的，需要数据泄露一下，否则直接在train_set中丢失了</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_list) == <span class="number">1</span>:</span><br><span class="line">            train_set.append((uid, pos_list, pos_list[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">            test_set.append((uid, pos_list, pos_list[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    random.shuffle(train_set)</span><br><span class="line">    random.shuffle(test_set)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_set, test_set</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模型输入，保证数据规范</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_model_input</span>(<span class="params">train_set, seq_maxlen</span>):</span><br><span class="line">    <span class="comment"># 格式 ( user_id, his_item, pos_item, label, len(his_item) )</span></span><br><span class="line">    uid = np.array([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_set])</span><br><span class="line">    hist = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_set]</span><br><span class="line">    pos_item = np.array([x[<span class="number">2</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_set])</span><br><span class="line">    label = np.array([x[<span class="number">3</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_set])</span><br><span class="line">    hlen = np.array([x[<span class="number">4</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_set])</span><br><span class="line"></span><br><span class="line">    hist = pad_sequences(</span><br><span class="line">        hist,</span><br><span class="line">        maxlen=seq_maxlen,</span><br><span class="line">        padding=<span class="string">&#x27;post&#x27;</span>,</span><br><span class="line">        truncating=<span class="string">&#x27;post&#x27;</span>,</span><br><span class="line">        value=<span class="number">0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    train_model_input = &#123;</span><br><span class="line">        <span class="string">&quot;user_id&quot;</span>: uid, </span><br><span class="line">        <span class="string">&quot;click_article_id&quot;</span>: pos_item, </span><br><span class="line">        <span class="string">&quot;hist_article_id&quot;</span>: hist,</span><br><span class="line">        <span class="string">&quot;hist_len&quot;</span>: hlen&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_model_input, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># YoutubeDNN 召回</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">YoutubeDNN_u2i_dict</span>(<span class="params">click_df, save_path, topk=<span class="number">20</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    YoutubeDNN 双塔模型召回</span></span><br><span class="line"><span class="string">    - 训练完成后提取 user/item embedding，使用FAISS基于内积做 topk 召回</span></span><br><span class="line"><span class="string">    - 返回：&#123;user1:[(item1, score1),(item2, score2)], ...&#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 内联配置</span></span><br><span class="line">    SEQ_LEN = <span class="number">30</span></span><br><span class="line">    emb_dim = <span class="number">16</span></span><br><span class="line">    neg_sample = <span class="number">20</span></span><br><span class="line">    dnn_units = [<span class="number">32</span>]</span><br><span class="line">    label_name = <span class="string">&#x27;click_article_id&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 类别编码与回退映射</span></span><br><span class="line">    df = click_df.copy()</span><br><span class="line">    user_rawid = df[[<span class="string">&#x27;user_id&#x27;</span>]].drop_duplicates(<span class="string">&#x27;user_id&#x27;</span>)</span><br><span class="line">    item_rawid = df[[<span class="string">&#x27;click_article_id&#x27;</span>]].drop_duplicates(<span class="string">&#x27;click_article_id&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    encoders = &#123;&#125;</span><br><span class="line">    feature_maxidx = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>]:</span><br><span class="line">        lbe = LabelEncoder()</span><br><span class="line">        df[col] = lbe.fit_transform(df[col])</span><br><span class="line">        encoders[col] = lbe</span><br><span class="line">        feature_maxidx[col] = <span class="built_in">int</span>(df[col].<span class="built_in">max</span>())+<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    user_idx = df[[<span class="string">&#x27;user_id&#x27;</span>]].drop_duplicates(<span class="string">&#x27;user_id&#x27;</span>)</span><br><span class="line">    item_idx = df[[<span class="string">&#x27;click_article_id&#x27;</span>]].drop_duplicates(<span class="string">&#x27;click_article_id&#x27;</span>)</span><br><span class="line">    user_idx2rawid = <span class="built_in">dict</span>(<span class="built_in">zip</span>(user_idx[<span class="string">&#x27;user_id&#x27;</span>], user_rawid[<span class="string">&#x27;user_id&#x27;</span>]))</span><br><span class="line">    item_idx2rawid = <span class="built_in">dict</span>(<span class="built_in">zip</span>(item_idx[<span class="string">&#x27;click_article_id&#x27;</span>], item_rawid[<span class="string">&#x27;click_article_id&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建数据集</span></span><br><span class="line">    train_set, test_set = gen_data_set(df, negsample=<span class="number">0</span>)  <span class="comment"># 这里全用的正样本，没有负采样</span></span><br><span class="line">    train_model_input, train_label = gen_model_input(train_set, SEQ_LEN)</span><br><span class="line">    test_model_input, test_label = gen_model_input(test_set, SEQ_LEN)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 只用必要的数据</span></span><br><span class="line">    input_keys = [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;hist_article_id&#x27;</span>]</span><br><span class="line">    train_X = &#123;k: train_model_input[k] <span class="keyword">for</span> k <span class="keyword">in</span> input_keys&#125;</span><br><span class="line">    test_X = &#123;k: test_model_input[k] <span class="keyword">for</span> k <span class="keyword">in</span> input_keys&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 手动定义特征列（不依赖外部数据字典）</span></span><br><span class="line">    feature_columns = [</span><br><span class="line">        FeatureColumn(name=<span class="string">&#x27;user_id&#x27;</span>, group=[<span class="string">&#x27;user_dnn&#x27;</span>], </span><br><span class="line">                      <span class="built_in">type</span>=<span class="string">&#x27;sparse&#x27;</span>, vocab_size=feature_maxidx[<span class="string">&#x27;user_id&#x27;</span>], emb_dim=emb_dim),</span><br><span class="line"></span><br><span class="line">        FeatureColumn(name=<span class="string">&#x27;click_article_id&#x27;</span>, group=[<span class="string">&#x27;target_item&#x27;</span>], </span><br><span class="line">                      <span class="built_in">type</span>=<span class="string">&#x27;sparse&#x27;</span>, vocab_size=feature_maxidx[<span class="string">&#x27;click_article_id&#x27;</span>], emb_dim=emb_dim),</span><br><span class="line"></span><br><span class="line">        FeatureColumn(name=<span class="string">&#x27;hist_article_id&#x27;</span>, emb_name=<span class="string">&#x27;click_article_id&#x27;</span>, group=[<span class="string">&#x27;raw_hist_seq&#x27;</span>], </span><br><span class="line">                      <span class="built_in">type</span>=<span class="string">&#x27;varlen_sparse&#x27;</span>, max_len=SEQ_LEN, combiner=<span class="string">&#x27;mean&#x27;</span>, emb_dim=emb_dim, </span><br><span class="line">                      vocab_size=feature_maxidx[<span class="string">&#x27;click_article_id&#x27;</span>]),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 组装 processed_data</span></span><br><span class="line">    processed_data = &#123;</span><br><span class="line">        <span class="string">&#x27;train&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;features&#x27;</span>: train_X,</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: <span class="literal">None</span>  <span class="comment"># 由 positive_sampling_labels 规则内部替换为全 1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&#x27;test&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;features&#x27;</span>: test_X,</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line">            <span class="string">&#x27;eval_data&#x27;</span>: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&#x27;all_items&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;click_article_id&#x27;</span>: np.arange(feature_maxidx[<span class="string">&#x27;click_article_id&#x27;</span>], dtype=np.int32)</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&#x27;feature_dict&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;user_id&#x27;</span>: feature_maxidx[<span class="string">&#x27;user_id&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;click_article_id&#x27;</span>: feature_maxidx[<span class="string">&#x27;click_article_id&#x27;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练配置（内联）</span></span><br><span class="line">    training_config = &#123;</span><br><span class="line">        <span class="string">&#x27;build_function&#x27;</span>: <span class="string">&#x27;funrec.models.youtubednn.build_youtubednn_model&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;data_preprocessing&#x27;</span>: [</span><br><span class="line">            &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;positive_sampling_labels&#x27;</span>&#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&#x27;model_params&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;emb_dim&#x27;</span>: emb_dim,</span><br><span class="line">            <span class="string">&#x27;neg_sample&#x27;</span>: neg_sample,</span><br><span class="line">            <span class="string">&#x27;dnn_units&#x27;</span>: dnn_units,</span><br><span class="line">            <span class="string">&#x27;label_name&#x27;</span>: label_name</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&#x27;optimizer&#x27;</span>: <span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;optimizer_params&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">1e-4</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&#x27;loss&#x27;</span>: <span class="string">&#x27;sampledsoftmaxloss&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">128</span>,</span><br><span class="line">        <span class="string">&#x27;epochs&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模型（返回 main_model, user_model, item_model）</span></span><br><span class="line">    model, user_model, item_model = train_model(training_config, feature_columns, processed_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 user/item 的 embedding</span></span><br><span class="line">    user_inputs_for_pred = &#123;k: test_X[k] <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;hist_article_id&#x27;</span>]&#125;</span><br><span class="line">    user_embs = user_model.predict(user_inputs_for_pred, batch_size=<span class="number">2</span> ** <span class="number">12</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    item_embs = item_model.predict(processed_data[<span class="string">&#x27;all_items&#x27;</span>], batch_size=<span class="number">2</span> ** <span class="number">12</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 归一化（与现有逻辑一致）</span></span><br><span class="line">    user_embs = user_embs / np.linalg.norm(user_embs, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    item_embs = item_embs / np.linalg.norm(item_embs, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存 embedding（与现有逻辑一致，注意 id 回退）</span></span><br><span class="line">    raw_user_id_emb_dict = &#123;user_idx2rawid[k]: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(test_X[<span class="string">&#x27;user_id&#x27;</span>], user_embs)&#125;</span><br><span class="line">    raw_item_id_emb_dict = &#123;item_idx2rawid[k]: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(processed_data[<span class="string">&#x27;all_items&#x27;</span>][<span class="string">&#x27;click_article_id&#x27;</span>], item_embs)&#125;</span><br><span class="line">    save1 = save_path / <span class="string">&#x27;user_youtube_emb.pkl&#x27;</span></span><br><span class="line">    save2 = save_path / <span class="string">&#x27;item_youtube_emb.pkl&#x27;</span></span><br><span class="line">    pickle.dump(raw_user_id_emb_dict, <span class="built_in">open</span>(save1, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    pickle.dump(raw_item_id_emb_dict, <span class="built_in">open</span>(save2, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;YoutubeDNN训练后分离user向量矩阵保存：<span class="subst">&#123;save1&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;YoutubeDNN训练后分离item向量矩阵保存：<span class="subst">&#123;save2&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 FAISS 做向量检索召回</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;FAISS开始处理...&#x27;</span>)</span><br><span class="line">    index = faiss.IndexFlatIP(emb_dim)   <span class="comment"># 直接内积就是相似度，因为前面归一化过了</span></span><br><span class="line">    index.add(item_embs.astype(np.float32))</span><br><span class="line">    sim_lists, idx_lists = index.search(np.ascontiguousarray(user_embs.astype(np.float32)), topk)</span><br><span class="line">    <span class="comment"># 这里是把 item 在空间中保存好，用 user 去匹配最佳的 item 出来</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;FAISS处理完毕.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    user_recall_items_dict = defaultdict(<span class="keyword">lambda</span>: defaultdict(<span class="built_in">float</span>))</span><br><span class="line">    <span class="keyword">for</span> target_idx, sim_l, item_l <span class="keyword">in</span> tqdm(<span class="built_in">zip</span>(test_X[<span class="string">&#x27;user_id&#x27;</span>], sim_lists, idx_lists), desc=<span class="string">&#x27;YoutubeDNN_相似度矩阵&#x27;</span>):</span><br><span class="line">        target_rawid = user_idx2rawid[<span class="built_in">int</span>(target_idx)]</span><br><span class="line">        <span class="keyword">for</span> item, sim <span class="keyword">in</span> <span class="built_in">zip</span>(item_l[<span class="number">1</span>:], sim_l[<span class="number">1</span>:]):  <span class="comment"># 去除本身</span></span><br><span class="line">            item_rawid = item_idx2rawid[<span class="built_in">int</span>(item)]</span><br><span class="line">            user_recall_items_dict[target_rawid][item_rawid] += sim</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 排序并保存</span></span><br><span class="line">    user_recall_items_dict = &#123;</span><br><span class="line">        k: <span class="built_in">sorted</span>(v.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>) </span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> user_recall_items_dict.items()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    save_name = save_path / <span class="string">&#x27;youtube_u2i_dict.pkl&#x27;</span></span><br><span class="line">    pickle.dump(user_recall_items_dict, <span class="built_in">open</span>(save_name, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;YoutubeDNN_u2i矩阵保存：<span class="subst">&#123;save_name&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_recall_items_dict</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="preprocessor-py"><code>preprocessor.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">特征处理</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging, pickle</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Any</span>, <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> feature <span class="keyword">import</span> FeatureColumn</span><br><span class="line"><span class="keyword">from</span> data_config <span class="keyword">import</span> DATASET_CONFIG</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_pkl_data</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data_dict = pickle.load(f)</span><br><span class="line">    <span class="keyword">return</span> data_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_feature_transformations</span>(<span class="params"></span></span><br><span class="line"><span class="params">    features_config: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], data_dict: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    根据配置规则进行特征处理</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        features_config: 特征配置，包含变换规则</span></span><br><span class="line"><span class="string">        data_dict: 数据字典，包含需要变换的数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        变换后的数据字典</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    transformations = features_config.get(<span class="string">&quot;feature_transformations&quot;</span>, [])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> transformations:</span><br><span class="line">        <span class="keyword">return</span> data_dict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个副本，避免修改原始数据</span></span><br><span class="line">    transformed_data = data_dict.copy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> transform <span class="keyword">in</span> transformations:</span><br><span class="line">        transform_type = transform.get(<span class="string">&quot;type&quot;</span>)</span><br><span class="line">        source_features = transform.get(<span class="string">&quot;source_features&quot;</span>, [])</span><br><span class="line">        target_suffix = transform.get(<span class="string">&quot;target_suffix&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> transform_type == <span class="string">&quot;sequence_slice&quot;</span>:</span><br><span class="line">            slice_start = transform.get(<span class="string">&quot;slice_start&quot;</span>)</span><br><span class="line">            slice_end = transform.get(<span class="string">&quot;slice_end&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> source_feat <span class="keyword">in</span> source_features:</span><br><span class="line">                <span class="keyword">if</span> source_feat <span class="keyword">in</span> transformed_data:</span><br><span class="line">                    target_feat = source_feat + target_suffix</span><br><span class="line">                    <span class="keyword">if</span> slice_end <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        transformed_data[target_feat] = transformed_data[source_feat][</span><br><span class="line">                            :, slice_start:slice_end</span><br><span class="line">                        ]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        transformed_data[target_feat] = transformed_data[source_feat][</span><br><span class="line">                            :, slice_start:</span><br><span class="line">                        ]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> transform_type == <span class="string">&quot;sequence_copy&quot;</span>:</span><br><span class="line">            <span class="keyword">for</span> source_feat <span class="keyword">in</span> source_features:</span><br><span class="line">                <span class="keyword">if</span> source_feat <span class="keyword">in</span> transformed_data:</span><br><span class="line">                    target_feat = source_feat + target_suffix</span><br><span class="line">                    transformed_data[target_feat] = transformed_data[source_feat].copy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transformed_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_training_preprocessing</span>(<span class="params"></span></span><br><span class="line"><span class="params">    training_config: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], train_features: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], train_labels: <span class="type">Any</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], <span class="type">Any</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    训练数据预处理</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        training_config: 训练配置，包含预处理规则</span></span><br><span class="line"><span class="string">        train_features: 训练特征字典</span></span><br><span class="line"><span class="string">        train_labels: 训练标签</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Tuple of (processed_features, processed_labels)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    processed_features = train_features.copy()</span><br><span class="line">    processed_labels = train_labels</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果指定，采样训练数据</span></span><br><span class="line">    subsample_size = training_config.get(<span class="string">&quot;subsample_size&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> subsample_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> subsample_size &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 获取第一个特征的采样数量</span></span><br><span class="line">        current_size = <span class="built_in">len</span>(<span class="built_in">next</span>(<span class="built_in">iter</span>(processed_features.values())))</span><br><span class="line">        <span class="keyword">if</span> current_size &gt; subsample_size:</span><br><span class="line">            logger.debug(</span><br><span class="line">                <span class="string">f&quot;Subsampling training data from <span class="subst">&#123;current_size&#125;</span> to <span class="subst">&#123;subsample_size&#125;</span> samples&quot;</span></span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># 对所有特征进行采样</span></span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> processed_features:</span><br><span class="line">                processed_features[key] = processed_features[key][:subsample_size]</span><br><span class="line">            <span class="comment"># 对标签进行采样</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(processed_labels, <span class="built_in">list</span>):</span><br><span class="line">                processed_labels = [</span><br><span class="line">                    labels[:subsample_size] <span class="keyword">for</span> labels <span class="keyword">in</span> processed_labels</span><br><span class="line">                ]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                processed_labels = processed_labels[:subsample_size]</span><br><span class="line"></span><br><span class="line">    preprocessing_rules = training_config.get(<span class="string">&quot;data_preprocessing&quot;</span>, [])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> preprocessing_rules:</span><br><span class="line">        <span class="keyword">return</span> processed_features, processed_labels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> rule <span class="keyword">in</span> preprocessing_rules:</span><br><span class="line">        rule_type = rule.get(<span class="string">&quot;type&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rule_type == <span class="string">&quot;positive_sampling_labels&quot;</span>:</span><br><span class="line">            <span class="comment"># 将标签转换为全1，用于模型（YouTubeDNN, SDM, etc.）</span></span><br><span class="line">            processed_labels = np.ones_like(<span class="built_in">list</span>(processed_features.values())[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">elif</span> rule_type == <span class="string">&quot;eges_generate_walk_pairs&quot;</span>:</span><br><span class="line">            <span class="comment"># 构建EGES训练对，通过随机游走</span></span><br><span class="line">            num_walks = <span class="built_in">int</span>(rule.get(<span class="string">&quot;num_walks&quot;</span>, <span class="number">10</span>))</span><br><span class="line">            walk_length = <span class="built_in">int</span>(rule.get(<span class="string">&quot;walk_length&quot;</span>, <span class="number">10</span>))</span><br><span class="line">            window_size = <span class="built_in">int</span>(rule.get(<span class="string">&quot;window_size&quot;</span>, <span class="number">5</span>))</span><br><span class="line">            neg_samples = <span class="built_in">int</span>(rule.get(<span class="string">&quot;neg_samples&quot;</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 导入EGES辅助函数</span></span><br><span class="line">            <span class="keyword">from</span> ..models.eges <span class="keyword">import</span> (</span><br><span class="line">                SimpleWalker,</span><br><span class="line">                get_graph_context_all_pairs,</span><br><span class="line">                generate_negative_samples,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 需要从原始训练字典中获取输入</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;hist_movie_id&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> processed_features:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;EGES预处理需要&#x27;hist_movie_id&#x27;在训练特征中&quot;</span>)</span><br><span class="line"></span><br><span class="line">            hist_movie_id = processed_features[<span class="string">&quot;hist_movie_id&quot;</span>]</span><br><span class="line">            hist_len = processed_features.get(<span class="string">&quot;hist_len&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">            <span class="comment"># 构建会话列表</span></span><br><span class="line">            session_list = []</span><br><span class="line">            <span class="keyword">if</span> hist_len <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> seq, l <span class="keyword">in</span> <span class="built_in">zip</span>(hist_movie_id, hist_len):</span><br><span class="line">                    seq = seq[-<span class="built_in">int</span>(l) :] <span class="keyword">if</span> <span class="built_in">isinstance</span>(l, (<span class="built_in">int</span>, np.integer)) <span class="keyword">else</span> seq</span><br><span class="line">                    session_list.append(</span><br><span class="line">                        seq.tolist() <span class="keyword">if</span> <span class="built_in">hasattr</span>(seq, <span class="string">&quot;tolist&quot;</span>) <span class="keyword">else</span> <span class="built_in">list</span>(seq)</span><br><span class="line">                    )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> seq <span class="keyword">in</span> hist_movie_id:</span><br><span class="line">                    session_list.append(</span><br><span class="line">                        (seq.tolist() <span class="keyword">if</span> <span class="built_in">hasattr</span>(seq, <span class="string">&quot;tolist&quot;</span>) <span class="keyword">else</span> <span class="built_in">list</span>(seq))</span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 构建电影-&gt;genre映射</span></span><br><span class="line">            genre_map = &#123;&#125;</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;movie_id&quot;</span> <span class="keyword">in</span> processed_features <span class="keyword">and</span> <span class="string">&quot;genres&quot;</span> <span class="keyword">in</span> processed_features:</span><br><span class="line">                <span class="keyword">for</span> m, g <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                    processed_features[<span class="string">&quot;movie_id&quot;</span>], processed_features[<span class="string">&quot;genres&quot;</span>]</span><br><span class="line">                ):</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        genre_map[<span class="built_in">int</span>(m)] = <span class="built_in">int</span>(g)</span><br><span class="line">                    <span class="keyword">except</span> Exception:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 随机游走图</span></span><br><span class="line">            walker = SimpleWalker()</span><br><span class="line">            G, maps = walker.build_graph(session_list)</span><br><span class="line">            <span class="keyword">if</span> G <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;EGES预处理无法从会话列表构建图&quot;</span>)</span><br><span class="line"></span><br><span class="line">            walks = walker.generate_walks(</span><br><span class="line">                G, num_walks=num_walks, walk_length=walk_length</span><br><span class="line">            )</span><br><span class="line">            all_pairs = get_graph_context_all_pairs(walks, window_size=window_size)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 正样本</span></span><br><span class="line">            pos_dict = &#123;</span><br><span class="line">                <span class="string">&quot;movie_id&quot;</span>: np.array([<span class="built_in">int</span>(x[<span class="number">0</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> all_pairs], dtype=np.int32),</span><br><span class="line">                <span class="string">&quot;context_id&quot;</span>: np.array([<span class="built_in">int</span>(x[<span class="number">1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> all_pairs], dtype=np.int32),</span><br><span class="line">                <span class="string">&quot;genre_id&quot;</span>: np.array(</span><br><span class="line">                    [<span class="built_in">int</span>(genre_map.get(<span class="built_in">int</span>(x[<span class="number">0</span>]), <span class="number">0</span>)) <span class="keyword">for</span> x <span class="keyword">in</span> all_pairs],</span><br><span class="line">                    dtype=np.int32,</span><br><span class="line">                ),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 负样本</span></span><br><span class="line">            neg_dict = generate_negative_samples(pos_dict, num_negatives=neg_samples)</span><br><span class="line"></span><br><span class="line">            labels = np.concatenate(</span><br><span class="line">                [</span><br><span class="line">                    np.ones(<span class="built_in">len</span>(all_pairs), dtype=np.float32),</span><br><span class="line">                    np.zeros(<span class="built_in">len</span>(neg_dict[<span class="string">&quot;movie_id&quot;</span>]), dtype=np.float32),</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            new_features = &#123;</span><br><span class="line">                <span class="string">&quot;movie_id&quot;</span>: np.concatenate(</span><br><span class="line">                    [pos_dict[<span class="string">&quot;movie_id&quot;</span>], neg_dict[<span class="string">&quot;movie_id&quot;</span>]]</span><br><span class="line">                ),</span><br><span class="line">                <span class="string">&quot;context_id&quot;</span>: np.concatenate(</span><br><span class="line">                    [pos_dict[<span class="string">&quot;context_id&quot;</span>], neg_dict[<span class="string">&quot;context_id&quot;</span>]]</span><br><span class="line">                ),</span><br><span class="line">                <span class="string">&quot;genre_id&quot;</span>: np.concatenate(</span><br><span class="line">                    [pos_dict[<span class="string">&quot;genre_id&quot;</span>], neg_dict[<span class="string">&quot;genre_id&quot;</span>]]</span><br><span class="line">                ),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 打乱</span></span><br><span class="line">            idx = np.random.permutation(<span class="built_in">len</span>(new_features[<span class="string">&quot;movie_id&quot;</span>]))</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> new_features:</span><br><span class="line">                new_features[k] = new_features[k][idx]</span><br><span class="line">            labels = labels[idx]</span><br><span class="line"></span><br><span class="line">            processed_features = new_features</span><br><span class="line">            processed_labels = labels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> processed_features, processed_labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_features</span>(<span class="params"></span></span><br><span class="line"><span class="params">    features_config: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params">    train_data: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params">    test_data: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>[FeatureColumn], <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]]]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    准备特征列和处理后的数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        features_config: 特征配置字典</span></span><br><span class="line"><span class="string">        train_data: 训练数据字典</span></span><br><span class="line"><span class="string">        test_data: 测试数据字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Tuple of (feature_columns, processed_data)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果未定义特征，使用数据集配置中的特征字典</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> features_config <span class="keyword">or</span> <span class="keyword">not</span> features_config.get(<span class="string">&quot;features&quot;</span>):</span><br><span class="line">        feature_dict = <span class="literal">None</span></span><br><span class="line">        dataset_name = features_config.get(<span class="string">&quot;dataset_name&quot;</span>) <span class="keyword">if</span> features_config <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> dataset_name <span class="keyword">and</span> dataset_name <span class="keyword">in</span> DATASET_CONFIG:</span><br><span class="line">            dataset_config = DATASET_CONFIG[dataset_name]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                feature_dict = read_pkl_data(dataset_config[<span class="string">&quot;dict_path&quot;</span>])</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                feature_dict = <span class="literal">None</span></span><br><span class="line">        processed = &#123;<span class="string">&quot;train&quot;</span>: train_data, <span class="string">&quot;test&quot;</span>: test_data&#125;</span><br><span class="line">        <span class="keyword">if</span> feature_dict <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            processed[<span class="string">&quot;feature_dict&quot;</span>] = feature_dict</span><br><span class="line">        <span class="keyword">return</span> [], processed</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可选采样，用来加速特征准备</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_early_subsample</span>(<span class="params">data: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], size: <span class="built_in">int</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data <span class="keyword">or</span> size <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> size &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> data</span><br><span class="line">        <span class="comment"># 从第一个数组值确定数据长度</span></span><br><span class="line">        first_key = <span class="built_in">next</span>((k <span class="keyword">for</span> k, v <span class="keyword">in</span> data.items() <span class="keyword">if</span> <span class="built_in">hasattr</span>(v, <span class="string">&quot;__len__&quot;</span>)), <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> first_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> data</span><br><span class="line">        current_size = <span class="built_in">len</span>(data[first_key])</span><br><span class="line">        <span class="keyword">if</span> current_size &lt;= size:</span><br><span class="line">            <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">        sliced = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> data.items():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                sliced[k] = v[:size]</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                sliced[k] = v</span><br><span class="line">        <span class="keyword">return</span> sliced</span><br><span class="line"></span><br><span class="line">    pre_sub_train = features_config.get(</span><br><span class="line">        <span class="string">&quot;pre_subsample_size_train&quot;</span>, features_config.get(<span class="string">&quot;pre_subsample_size&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    pre_sub_test = features_config.get(</span><br><span class="line">        <span class="string">&quot;pre_subsample_size_test&quot;</span>, features_config.get(<span class="string">&quot;pre_subsample_size&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> pre_sub_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        train_data = _early_subsample(train_data, <span class="built_in">int</span>(pre_sub_train))</span><br><span class="line">    <span class="keyword">if</span> pre_sub_test <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        test_data = _early_subsample(test_data, <span class="built_in">int</span>(pre_sub_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取数据信息</span></span><br><span class="line">    dataset_name = features_config.get(<span class="string">&quot;dataset_name&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dataset_name:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;dataset_name must be specified in features config&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dataset_name <span class="keyword">not</span> <span class="keyword">in</span> DATASET_CONFIG:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Dataset <span class="subst">&#123;dataset_name&#125;</span> not found in DATASET_CONFIG&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load feature dictionary</span></span><br><span class="line">    <span class="comment"># 加载特征字典</span></span><br><span class="line">    dataset_config = DATASET_CONFIG[dataset_name]</span><br><span class="line">    feature_dict = read_pkl_data(dataset_config[<span class="string">&quot;dict_path&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取embedding维度</span></span><br><span class="line">    emb_dim = features_config.get(<span class="string">&quot;emb_dim&quot;</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建特征列</span></span><br><span class="line">    feature_columns = []</span><br><span class="line">    feature_definitions = features_config.get(<span class="string">&quot;features&quot;</span>, [])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取序列最大长度</span></span><br><span class="line">    max_seq_len = features_config.get(<span class="string">&quot;max_seq_len&quot;</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feat_def <span class="keyword">in</span> feature_definitions:</span><br><span class="line">        feature_name = feat_def[<span class="string">&quot;name&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 确定特征类型和参数</span></span><br><span class="line">        explicit_type = feat_def.get(<span class="string">&quot;type&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> feature_name == <span class="string">&quot;hist_len&quot;</span>:</span><br><span class="line">            <span class="comment"># 处理hist_len 长度信息</span></span><br><span class="line">            fc = FeatureColumn(name=feature_name, emb_name=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="string">&quot;sparse&quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> explicit_type == <span class="string">&quot;dense&quot;</span>:</span><br><span class="line">            <span class="comment"># 稠密特征</span></span><br><span class="line">            fc = FeatureColumn(</span><br><span class="line">                name=feature_name,</span><br><span class="line">                emb_name=<span class="literal">None</span>,</span><br><span class="line">                group=feat_def.get(<span class="string">&quot;group&quot;</span>, []),</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;dense&quot;</span>,</span><br><span class="line">                dimension=feat_def.get(<span class="string">&quot;dimension&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                max_len=feat_def.get(<span class="string">&quot;max_len&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                dtype=feat_def.get(<span class="string">&quot;dtype&quot;</span>, <span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> explicit_type == <span class="string">&quot;varlen_sparse&quot;</span> <span class="keyword">or</span> (</span><br><span class="line">            feature_name.startswith(<span class="string">&quot;hist_&quot;</span>) <span class="keyword">and</span> explicit_type <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">        ):</span><br><span class="line">            <span class="comment"># 序列特征</span></span><br><span class="line">            <span class="keyword">if</span> feature_name == <span class="string">&quot;timestamps&quot;</span>:</span><br><span class="line">                fc = FeatureColumn(</span><br><span class="line">                    name=feature_name,</span><br><span class="line">                    emb_name=<span class="literal">None</span>,</span><br><span class="line">                    emb_dim=<span class="number">1</span>,</span><br><span class="line">                    vocab_size=<span class="number">1</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="string">&quot;varlen_sparse&quot;</span>,</span><br><span class="line">                    max_len=feat_def.get(<span class="string">&quot;max_len&quot;</span>, max_seq_len),</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fc = FeatureColumn(</span><br><span class="line">                    name=feature_name,</span><br><span class="line">                    emb_name=feat_def.get(<span class="string">&quot;emb_name&quot;</span>, feature_name),</span><br><span class="line">                    emb_dim=emb_dim,</span><br><span class="line">                    vocab_size=feature_dict[feat_def.get(<span class="string">&quot;emb_name&quot;</span>, feature_name)],</span><br><span class="line">                    group=feat_def.get(<span class="string">&quot;group&quot;</span>, []),</span><br><span class="line">                    <span class="built_in">type</span>=<span class="string">&quot;varlen_sparse&quot;</span>,</span><br><span class="line">                    max_len=feat_def.get(<span class="string">&quot;max_len&quot;</span>, max_seq_len),</span><br><span class="line">                    combiner=feat_def.get(<span class="string">&quot;combiner&quot;</span>, <span class="string">&quot;mean&quot;</span>),</span><br><span class="line">                    att_key_name=feat_def.get(<span class="string">&quot;att_key_name&quot;</span>),</span><br><span class="line">                )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 常规稀疏特征</span></span><br><span class="line">            emb_name = feat_def.get(<span class="string">&quot;emb_name&quot;</span>, feature_name)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> feature_name == <span class="string">&quot;timestamps&quot;</span>:</span><br><span class="line">                fc = FeatureColumn(</span><br><span class="line">                    name=feature_name,</span><br><span class="line">                    emb_name=<span class="literal">None</span>,</span><br><span class="line">                    emb_dim=<span class="number">1</span>,</span><br><span class="line">                    vocab_size=<span class="number">1</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="string">&quot;varlen_sparse&quot;</span>,</span><br><span class="line">                    max_len=feat_def.get(<span class="string">&quot;max_len&quot;</span>, <span class="number">50</span>),</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fc = FeatureColumn(</span><br><span class="line">                    name=feature_name,</span><br><span class="line">                    emb_name=emb_name,</span><br><span class="line">                    emb_dim=emb_dim,</span><br><span class="line">                    vocab_size=feature_dict[emb_name],</span><br><span class="line">                    group=feat_def.get(<span class="string">&quot;group&quot;</span>, []),</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">        feature_columns.append(fc)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取特征名称和任务名称</span></span><br><span class="line">    feature_name_list = [fc.name <span class="keyword">for</span> fc <span class="keyword">in</span> feature_columns]</span><br><span class="line">    task_name_list = features_config.get(<span class="string">&quot;task_names&quot;</span>, [<span class="string">&quot;label&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 特征变换</span></span><br><span class="line">    train_data_transformed = apply_feature_transformations(features_config, train_data)</span><br><span class="line">    test_data_transformed = apply_feature_transformations(features_config, test_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># DSIN会话特征构造</span></span><br><span class="line">    dsin_cfg = features_config.get(<span class="string">&quot;dsin_session&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> dsin_cfg:</span><br><span class="line">        sess_max_count = dsin_cfg.get(<span class="string">&quot;sess_max_count&quot;</span>, <span class="number">5</span>)</span><br><span class="line">        sess_max_len = dsin_cfg.get(<span class="string">&quot;sess_max_len&quot;</span>, <span class="number">10</span>)</span><br><span class="line">        session_feature_list = dsin_cfg.get(<span class="string">&quot;session_feature_list&quot;</span>, [<span class="string">&quot;video_id&quot;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_create_session_features_from_session_id</span>(<span class="params"></span></span><br><span class="line"><span class="params">            data_dict: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params">        </span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]:</span><br><span class="line">            <span class="comment"># 构建DataFrame</span></span><br><span class="line">            df = pd.DataFrame(</span><br><span class="line">                &#123;<span class="string">&quot;user_id&quot;</span>: data_dict[<span class="string">&quot;user_id&quot;</span>], <span class="string">&quot;session_id&quot;</span>: data_dict[<span class="string">&quot;session_id&quot;</span>]&#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> feat <span class="keyword">in</span> session_feature_list:</span><br><span class="line">                <span class="keyword">if</span> feat <span class="keyword">in</span> data_dict:</span><br><span class="line">                    df[feat] = data_dict[feat]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 按用户分组</span></span><br><span class="line">            user_sessions: <span class="type">Dict</span>[<span class="type">Any</span>, <span class="type">Dict</span>[<span class="type">Any</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">list</span>]]] = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> user_id <span class="keyword">in</span> df[<span class="string">&quot;user_id&quot;</span>].unique():</span><br><span class="line">                user_df = df[df[<span class="string">&quot;user_id&quot;</span>] == user_id]</span><br><span class="line">                sessions: <span class="type">Dict</span>[<span class="type">Any</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">list</span>]] = &#123;&#125;</span><br><span class="line">                <span class="keyword">for</span> sid <span class="keyword">in</span> user_df[<span class="string">&quot;session_id&quot;</span>].unique():</span><br><span class="line">                    s_df = user_df[user_df[<span class="string">&quot;session_id&quot;</span>] == sid]</span><br><span class="line">                    sessions[sid] = &#123;&#125;</span><br><span class="line">                    <span class="keyword">for</span> feat <span class="keyword">in</span> session_feature_list:</span><br><span class="line">                        <span class="keyword">if</span> feat <span class="keyword">in</span> s_df.columns:</span><br><span class="line">                            seq = s_df[feat].tolist()</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(seq) &gt; sess_max_len:</span><br><span class="line">                                seq = seq[:sess_max_len]</span><br><span class="line">                            <span class="keyword">elif</span> <span class="built_in">len</span>(seq) &lt; sess_max_len:</span><br><span class="line">                                seq = seq + [<span class="number">0</span>] * (sess_max_len - <span class="built_in">len</span>(seq))</span><br><span class="line">                            sessions[sid][feat] = seq</span><br><span class="line">                user_sessions[user_id] = sessions</span><br><span class="line"></span><br><span class="line">            batch_size = <span class="built_in">len</span>(data_dict[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">            <span class="keyword">for</span> sess_idx <span class="keyword">in</span> <span class="built_in">range</span>(sess_max_count):</span><br><span class="line">                <span class="keyword">for</span> feat <span class="keyword">in</span> session_feature_list:</span><br><span class="line">                    key = <span class="string">f&quot;sess_<span class="subst">&#123;sess_idx&#125;</span>_<span class="subst">&#123;feat&#125;</span>&quot;</span></span><br><span class="line">                    out = []</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">                        uid = data_dict[<span class="string">&quot;user_id&quot;</span>][i]</span><br><span class="line">                        user_sess = user_sessions.get(uid, &#123;&#125;)</span><br><span class="line">                        sids = <span class="built_in">list</span>(user_sess.keys())</span><br><span class="line">                        <span class="keyword">if</span> sess_idx &lt; <span class="built_in">len</span>(sids):</span><br><span class="line">                            sid = sids[sess_idx]</span><br><span class="line">                            seq = user_sess[sid].get(feat, [<span class="number">0</span>] * sess_max_len)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            seq = [<span class="number">0</span>] * sess_max_len</span><br><span class="line">                        out.append(seq)</span><br><span class="line">                    data_dict[key] = np.array(out, dtype=np.int32)</span><br><span class="line">            <span class="keyword">return</span> data_dict</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用到训练和测试数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;session_id&quot;</span> <span class="keyword">in</span> train_data_transformed:</span><br><span class="line">            train_data_transformed = _create_session_features_from_session_id(</span><br><span class="line">                train_data_transformed</span><br><span class="line">            )</span><br><span class="line">            train_data_transformed.pop(<span class="string">&quot;session_id&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;session_id&quot;</span> <span class="keyword">in</span> test_data_transformed:</span><br><span class="line">            test_data_transformed = _create_session_features_from_session_id(</span><br><span class="line">                test_data_transformed</span><br><span class="line">            )</span><br><span class="line">            test_data_transformed.pop(<span class="string">&quot;session_id&quot;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理训练数据</span></span><br><span class="line">    train_sample_dict = &#123;</span><br><span class="line">        k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> train_data_transformed.items() <span class="keyword">if</span> k <span class="keyword">in</span> feature_name_list</span><br><span class="line">    &#125;</span><br><span class="line">    train_label_list = [</span><br><span class="line">        v <span class="keyword">for</span> k, v <span class="keyword">in</span> train_data_transformed.items() <span class="keyword">if</span> k <span class="keyword">in</span> task_name_list</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理测试数据</span></span><br><span class="line">    test_sample_dict = &#123;</span><br><span class="line">        k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> test_data_transformed.items() <span class="keyword">if</span> k <span class="keyword">in</span> feature_name_list</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保留测试标签和其他评估数据</span></span><br><span class="line">    test_labels = &#123;</span><br><span class="line">        k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> test_data_transformed.items() <span class="keyword">if</span> k <span class="keyword">in</span> task_name_list</span><br><span class="line">    &#125;</span><br><span class="line">    test_eval_data = &#123;</span><br><span class="line">        k: v</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> test_data_transformed.items()</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> feature_name_list <span class="keyword">and</span> k <span class="keyword">not</span> <span class="keyword">in</span> task_name_list</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理特定特征处理</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;movie_id&quot;</span> <span class="keyword">in</span> train_sample_dict <span class="keyword">and</span> <span class="string">&quot;genres&quot;</span> <span class="keyword">in</span> train_sample_dict:</span><br><span class="line">        movie_id_to_genre_id_dict = &#123;</span><br><span class="line">            movie_id: genre_id</span><br><span class="line">            <span class="keyword">for</span> movie_id, genre_id <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                train_sample_dict[<span class="string">&quot;movie_id&quot;</span>], train_sample_dict[<span class="string">&quot;genres&quot;</span>]</span><br><span class="line">            )</span><br><span class="line">        &#125;</span><br><span class="line">        movie_id_to_genre_id_dict.update(</span><br><span class="line">            &#123;</span><br><span class="line">                movie_id: genre_id</span><br><span class="line">                <span class="keyword">for</span> movie_id, genre_id <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                    test_sample_dict[<span class="string">&quot;movie_id&quot;</span>], test_sample_dict[<span class="string">&quot;genres&quot;</span>]</span><br><span class="line">                )</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 准备所有物品数据</span></span><br><span class="line">        all_item_model_input = &#123;</span><br><span class="line">            <span class="string">&quot;movie_id&quot;</span>: np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(feature_dict[<span class="string">&quot;movie_id&quot;</span>])))</span><br><span class="line">        &#125;</span><br><span class="line">        all_item_model_input[<span class="string">&quot;genres&quot;</span>] = np.array(</span><br><span class="line">            [</span><br><span class="line">                movie_id_to_genre_id_dict.get(movie_id, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">for</span> movie_id <span class="keyword">in</span> all_item_model_input[<span class="string">&quot;movie_id&quot;</span>]</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        all_item_model_input = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    processed_data = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: &#123;<span class="string">&quot;features&quot;</span>: train_sample_dict, <span class="string">&quot;labels&quot;</span>: train_label_list&#125;,</span><br><span class="line">        <span class="string">&quot;test&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;features&quot;</span>: test_sample_dict,</span><br><span class="line">            <span class="string">&quot;labels&quot;</span>: test_labels,</span><br><span class="line">            <span class="string">&quot;eval_data&quot;</span>: test_eval_data,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;all_items&quot;</span>: all_item_model_input,</span><br><span class="line">        <span class="string">&quot;feature_dict&quot;</span>: feature_dict,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feature_columns, processed_data</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="trainer-py"><code>trainer.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">模型训练</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Any</span>, <span class="type">List</span>, <span class="type">Tuple</span>, <span class="type">Union</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> feature <span class="keyword">import</span> FeatureColumn</span><br><span class="line"><span class="keyword">from</span> processor <span class="keyword">import</span> apply_training_preprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params"></span></span><br><span class="line"><span class="params">    training_config: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params">    feature_columns: <span class="type">List</span>[FeatureColumn],</span></span><br><span class="line"><span class="params">    processed_data: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Union</span>[<span class="type">Tuple</span>[tf.keras.Model, tf.keras.Model, tf.keras.Model], <span class="type">Any</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    基于配置和处理后的数据训练模型。</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        training_config: 训练配置字典，包含以下内容：</span></span><br><span class="line"><span class="string">            - build_function: 模型构建函数的完整路径 (例如：&#x27;funrec.models.dssm.build_dssm_model&#x27;)</span></span><br><span class="line"><span class="string">            - model_params: 模型特定参数</span></span><br><span class="line"><span class="string">            - classical_model: 布尔值，指示是否为经典模型 (默认: False)</span></span><br><span class="line"><span class="string">            - data_preprocessing: 要应用的预处理规则列表</span></span><br><span class="line"><span class="string">            - optimizer: 使用的优化器 (默认: &#x27;adam&#x27;)</span></span><br><span class="line"><span class="string">            - loss: 损失函数 (默认: [&#x27;binary_crossentropy&#x27;])</span></span><br><span class="line"><span class="string">            - metrics: 要跟踪的指标 (默认: [&#x27;binary_accuracy&#x27;])</span></span><br><span class="line"><span class="string">            - batch_size: 训练批次大小 (默认: 1024)</span></span><br><span class="line"><span class="string">            - epochs: 训练轮数 (默认: 1)</span></span><br><span class="line"><span class="string">            - validation_split: 验证集分割比例 (默认: 0.2)</span></span><br><span class="line"><span class="string">            - verbose: 训练详细程度 (默认: 1)</span></span><br><span class="line"><span class="string">        feature_columns: 特征列规范列表</span></span><br><span class="line"><span class="string">        processed_data: 处理后的数据字典，包含训练/测试特征和标签</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        对于神经网络模型: 元组 (main_model, user_model, item_model)</span></span><br><span class="line"><span class="string">        对于经典模型: 训练后的经典模型实例</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 从配置中获取构建函数路径和参数</span></span><br><span class="line">    build_function_path = training_config.get(</span><br><span class="line">        <span class="string">&quot;build_function&quot;</span>, <span class="string">&quot;funrec.models.dssm.build_dssm_model&quot;</span></span><br><span class="line">    )</span><br><span class="line">    model_params = training_config.get(<span class="string">&quot;model_params&quot;</span>, &#123;&#125;)</span><br><span class="line">    is_classical = training_config.get(<span class="string">&quot;classical_model&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">    is_external_embedding = training_config.get(<span class="string">&quot;embedding_external&quot;</span>, <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析模块和函数名</span></span><br><span class="line">    module_path, function_name = build_function_path.rsplit(<span class="string">&quot;.&quot;</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 动态导入并调用构建函数</span></span><br><span class="line">    module = importlib.import_module(module_path)</span><br><span class="line">    build_function = <span class="built_in">getattr</span>(module, function_name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_classical:</span><br><span class="line">        <span class="comment"># 经典模型：直接构建和拟合</span></span><br><span class="line">        model = build_function(feature_columns, model_params)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 经典模型：准备交互数据</span></span><br><span class="line">        <span class="comment"># 经典模型期望用户-物品交互：[(user_id, item_id, label), ...]</span></span><br><span class="line">        train_interactions = []</span><br><span class="line">        <span class="comment"># 当特征配置为空时，processed_data已经直接包含训练字典</span></span><br><span class="line">        train_features = (</span><br><span class="line">            processed_data[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;features&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;features&quot;</span> <span class="keyword">in</span> processed_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">            <span class="keyword">else</span> processed_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">        )</span><br><span class="line">        train_labels = processed_data[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;labels&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从特征中提取用户和物品ID</span></span><br><span class="line">        <span class="comment"># 假设第一个特征是user_id，第二个是item_id</span></span><br><span class="line">        user_ids = (</span><br><span class="line">            train_features[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_features, <span class="built_in">list</span>)</span><br><span class="line">            <span class="keyword">else</span> train_features[<span class="string">&quot;user_id&quot;</span>]</span><br><span class="line">        )</span><br><span class="line">        item_ids = (</span><br><span class="line">            train_features[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_features, <span class="built_in">list</span>)</span><br><span class="line">            <span class="keyword">else</span> train_features[<span class="string">&quot;item_id&quot;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转换为交互格式</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(user_ids)):</span><br><span class="line">            train_interactions.append((user_ids[i], item_ids[i], train_labels[i]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练经典模型</span></span><br><span class="line">        model.fit(train_interactions)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回模型和None作为用户和物品模型（经典模型）</span></span><br><span class="line">        <span class="keyword">return</span> model, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> is_external_embedding:</span><br><span class="line">        <span class="comment"># 外部嵌入模型（例如Item2Vec）从用户历史序列训练</span></span><br><span class="line">        <span class="comment"># 使用自己的参数签名构建模型</span></span><br><span class="line">        model = build_function(model_params)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从处理后的数据准备训练序列</span></span><br><span class="line">        train_features = (</span><br><span class="line">            processed_data[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;features&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;features&quot;</span> <span class="keyword">in</span> processed_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">            <span class="keyword">else</span> processed_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 支持多个潜在键</span></span><br><span class="line">        hist_key_candidates = [</span><br><span class="line">            <span class="string">&quot;hist_movie_id_list&quot;</span>,</span><br><span class="line">            <span class="string">&quot;hist_movie_ids&quot;</span>,</span><br><span class="line">            <span class="string">&quot;hist_item_id_list&quot;</span>,</span><br><span class="line">            <span class="string">&quot;hist_item_ids&quot;</span>,</span><br><span class="line">        ]</span><br><span class="line">        hist_array = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> hist_key_candidates:</span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> train_features:</span><br><span class="line">                hist_array = train_features[key]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> hist_array <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;外部嵌入训练需要训练特征中包含&#x27;hist_movie_id_list&#x27;（或兼容键）&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转换为token序列列表（过滤填充0）</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(hist_array, <span class="built_in">list</span>):</span><br><span class="line">                train_sequences = [np.array(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> hist_array]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train_sequences = [hist_array[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(hist_array))]</span><br><span class="line">            train_hist_sequences = [</span><br><span class="line">                seq[np.where(seq != <span class="number">0</span>)[<span class="number">0</span>]].tolist() <span class="keyword">for</span> seq <span class="keyword">in</span> train_sequences</span><br><span class="line">            ]</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            train_hist_sequences = []</span><br><span class="line">            <span class="keyword">for</span> seq <span class="keyword">in</span> hist_array:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    train_hist_sequences.append([token <span class="keyword">for</span> token <span class="keyword">in</span> seq <span class="keyword">if</span> token != <span class="number">0</span>])</span><br><span class="line">                <span class="keyword">except</span> Exception:</span><br><span class="line">                    train_hist_sequences.append(<span class="built_in">list</span>(seq))</span><br><span class="line"></span><br><span class="line">        model.fit(train_hist_sequences)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 以统一元组形式返回</span></span><br><span class="line">        <span class="keyword">return</span> model, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 神经网络模型：原始训练流水线</span></span><br><span class="line">        model, user_model, item_model = build_function(feature_columns, model_params)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编译模型</span></span><br><span class="line">        optimizer_name = training_config.get(<span class="string">&quot;optimizer&quot;</span>, <span class="string">&quot;adam&quot;</span>)</span><br><span class="line">        optimizer_params = training_config.get(<span class="string">&quot;optimizer_params&quot;</span>, &#123;&#125;)</span><br><span class="line">        loss = training_config.get(<span class="string">&quot;loss&quot;</span>, [<span class="string">&quot;binary_crossentropy&quot;</span>])</span><br><span class="line">        loss_weights = training_config.get(<span class="string">&quot;loss_weights&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">        metrics = training_config.get(<span class="string">&quot;metrics&quot;</span>, [<span class="string">&quot;binary_accuracy&quot;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理自定义损失函数</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(loss, <span class="built_in">str</span>) <span class="keyword">and</span> loss == <span class="string">&quot;sampledsoftmaxloss&quot;</span>:</span><br><span class="line">            <span class="keyword">from</span> loss <span class="keyword">import</span> sampledsoftmaxloss</span><br><span class="line"></span><br><span class="line">            loss = sampledsoftmaxloss</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理优化器 - 对Apple Silicon使用legacy Adam</span></span><br><span class="line">        is_apple_silicon = platform.machine().lower() <span class="keyword">in</span> [<span class="string">&quot;arm64&quot;</span>, <span class="string">&quot;aarch64&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> optimizer_name == <span class="string">&quot;adam&quot;</span>:</span><br><span class="line">            <span class="keyword">if</span> is_apple_silicon:</span><br><span class="line">                optimizer = (</span><br><span class="line">                    tf.keras.optimizers.legacy.Adam(**optimizer_params)</span><br><span class="line">                    <span class="keyword">if</span> optimizer_params</span><br><span class="line">                    <span class="keyword">else</span> tf.keras.optimizers.legacy.Adam()</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                optimizer = (</span><br><span class="line">                    tf.keras.optimizers.Adam(**optimizer_params)</span><br><span class="line">                    <span class="keyword">if</span> optimizer_params</span><br><span class="line">                    <span class="keyword">else</span> tf.keras.optimizers.Adam()</span><br><span class="line">                )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            optimizer = optimizer_name</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编译时包含loss_weights如果提供的话</span></span><br><span class="line">        compile_kwargs = &#123;<span class="string">&quot;optimizer&quot;</span>: optimizer, <span class="string">&quot;loss&quot;</span>: loss, <span class="string">&quot;metrics&quot;</span>: metrics&#125;</span><br><span class="line">        <span class="keyword">if</span> loss_weights <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            compile_kwargs[<span class="string">&quot;loss_weights&quot;</span>] = loss_weights</span><br><span class="line">        model.<span class="built_in">compile</span>(**compile_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取训练参数</span></span><br><span class="line">        batch_size = training_config.get(<span class="string">&quot;batch_size&quot;</span>, <span class="number">1024</span>)</span><br><span class="line">        epochs = training_config.get(<span class="string">&quot;epochs&quot;</span>, <span class="number">1</span>)</span><br><span class="line">        validation_split = training_config.get(<span class="string">&quot;validation_split&quot;</span>, <span class="number">0.2</span>)</span><br><span class="line">        verbose = training_config.get(<span class="string">&quot;verbose&quot;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 基于配置应用训练特定的预处理</span></span><br><span class="line">        <span class="comment"># 支持完全准备的字典和原始字典</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;features&quot;</span> <span class="keyword">in</span> processed_data[<span class="string">&quot;train&quot;</span>]:</span><br><span class="line">            train_features = processed_data[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;features&quot;</span>]</span><br><span class="line">            train_labels = processed_data[<span class="string">&quot;train&quot;</span>].get(<span class="string">&quot;labels&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_features = processed_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">            train_labels = (</span><br><span class="line">                processed_data[<span class="string">&quot;train&quot;</span>].get(<span class="string">&quot;labels&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(processed_data[<span class="string">&quot;train&quot;</span>], <span class="built_in">dict</span>)</span><br><span class="line">                <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            )</span><br><span class="line">        train_features, train_labels = apply_training_preprocessing(</span><br><span class="line">            training_config, train_features, train_labels</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        labels_for_fit = train_labels</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(labels_for_fit, <span class="built_in">list</span>) <span class="keyword">and</span> <span class="built_in">len</span>(labels_for_fit) == <span class="number">1</span>:</span><br><span class="line">            labels_for_fit = labels_for_fit[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理多输出模型：如果模型有多个输出但只有一个标签集，复制标签</span></span><br><span class="line">        <span class="keyword">if</span> (</span><br><span class="line">            <span class="built_in">isinstance</span>(loss, <span class="built_in">list</span>)</span><br><span class="line">            <span class="keyword">and</span> <span class="built_in">len</span>(loss) &gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(labels_for_fit, <span class="built_in">list</span>)</span><br><span class="line">        ):</span><br><span class="line">            <span class="comment"># 对于PRS等模型：两个输出都使用相同的标签</span></span><br><span class="line">            labels_for_fit = [labels_for_fit] * <span class="built_in">len</span>(loss)</span><br><span class="line"></span><br><span class="line">        history = model.fit(</span><br><span class="line">            train_features,</span><br><span class="line">            labels_for_fit,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            epochs=epochs,</span><br><span class="line">            verbose=verbose,</span><br><span class="line">            validation_split=validation_split,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> model, user_model, item_model</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="feature-py"><code>feature.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">特征列</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass, field</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.initializers <span class="keyword">import</span> Initializer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeatureColumn</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;特征列配置类，用于定义特征的属性和嵌入参数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes:</span></span><br><span class="line"><span class="string">        name: 特征名称，唯一标识符</span></span><br><span class="line"><span class="string">        emb_name: 嵌入名称，可选值为字符串或字符串列表。默认与特征名称相同</span></span><br><span class="line"><span class="string">        emb_dim: 嵌入维度，默认为4</span></span><br><span class="line"><span class="string">        vocab_size: 词汇表大小，默认为1（表示未指定）</span></span><br><span class="line"><span class="string">        group: 特征所属组，例如线性组、DNN组、FM组等，默认为空列表</span></span><br><span class="line"><span class="string">        type: 特征类型，可选值为&quot; sparse&quot;（稀疏特征）、&quot;dense&quot;（稠密特征）、&quot;varlen_sparse&quot;（变长稀疏特征）</span></span><br><span class="line"><span class="string">        dimension: 稠密特征的维度，默认为1</span></span><br><span class="line"><span class="string">        trainable: 是否可训练，默认为True</span></span><br><span class="line"><span class="string">        max_len: 最大长度，默认为1</span></span><br><span class="line"><span class="string">        combiner: 合并方式，默认为&quot;mean&quot;</span></span><br><span class="line"><span class="string">        l2_reg: L2正则化系数，默认为0.0</span></span><br><span class="line"><span class="string">        initializer: 初始化器，默认为&quot;uniform&quot;</span></span><br><span class="line"><span class="string">        dtype: 数据类型，默认为&quot;int32&quot;</span></span><br><span class="line"><span class="string">        att_key_name: 注意力键名称，默认为None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    emb_name: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">str</span>]] = <span class="literal">None</span>  <span class="comment"># 嵌入名称，可以是单个字符串或多个字符串列表</span></span><br><span class="line">    emb_dim: <span class="built_in">int</span> = <span class="number">4</span>  <span class="comment"># 嵌入维度</span></span><br><span class="line">    vocab_size: <span class="built_in">int</span> = <span class="number">1</span>  <span class="comment"># 词汇表大小，1表示未指定</span></span><br><span class="line">    group: <span class="type">List</span>[<span class="built_in">str</span>] = field(</span><br><span class="line">        default_factory=<span class="built_in">list</span></span><br><span class="line">    )  <span class="comment"># 特征所属组，例如线性组、DNN组、FM组等</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="built_in">str</span> = <span class="string">&quot;sparse&quot;</span>  <span class="comment"># 特征类型，可选值为&quot; sparse&quot;、&quot;dense&quot;、&quot;varlen_sparse&quot;</span></span><br><span class="line">    dimension: <span class="built_in">int</span> = <span class="number">1</span>  <span class="comment"># 稠密特征的维度</span></span><br><span class="line">    trainable: <span class="built_in">bool</span> = <span class="literal">True</span>  <span class="comment"># 是否可训练</span></span><br><span class="line">    max_len: <span class="built_in">int</span> = <span class="number">1</span>  <span class="comment"># 最大长度</span></span><br><span class="line">    combiner: <span class="built_in">str</span> = <span class="string">&quot;mean&quot;</span>  <span class="comment"># 变长特征聚合方式</span></span><br><span class="line">    l2_reg: <span class="built_in">float</span> = <span class="number">0.0</span>  <span class="comment"># L2正则化系数</span></span><br><span class="line">    initializer: <span class="type">Union</span>[<span class="built_in">str</span>, Initializer] = <span class="string">&quot;uniform&quot;</span>  <span class="comment"># 初始化器</span></span><br><span class="line">    dtype: <span class="built_in">str</span> = <span class="string">&quot;int32&quot;</span>  <span class="comment"># 数据类型</span></span><br><span class="line">    att_key_name: <span class="built_in">str</span> = (</span><br><span class="line">        <span class="literal">None</span>  <span class="comment"># 注意力键名称，当特征是变长特征且通过din方式进行聚合时使用</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__post_init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;初始化后处理方法，用于设置默认值和基本验证&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 如果emb_name未指定，则默认与特征名称相同</span></span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">type</span> <span class="keyword">in</span> [<span class="string">&quot;sparse&quot;</span>, <span class="string">&quot;varlen_sparse&quot;</span>] <span class="keyword">and</span> self.emb_name <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.emb_name = self.name</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 验证特征类型是否有效</span></span><br><span class="line">        valid_types = [<span class="string">&quot;sparse&quot;</span>, <span class="string">&quot;dense&quot;</span>, <span class="string">&quot;varlen_sparse&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">type</span> <span class="keyword">not</span> <span class="keyword">in</span> valid_types:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Invalid type: <span class="subst">&#123;self.<span class="built_in">type</span>&#125;</span>. Must be one of <span class="subst">&#123;valid_types&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 验证combiner是否有效（仅对变长特征有意义）</span></span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">type</span> == <span class="string">&quot;varlen_sparse&quot;</span>:</span><br><span class="line">            valid_combiners = [</span><br><span class="line">                <span class="string">&quot;mean&quot;</span>,</span><br><span class="line">                <span class="string">&quot;din&quot;</span>,</span><br><span class="line">                <span class="string">&quot;mha&quot;</span>,</span><br><span class="line">                <span class="string">&quot;dien&quot;</span>,</span><br><span class="line">            ]  <span class="comment"># None表示不聚合, 返回原始序列特征</span></span><br><span class="line">            <span class="keyword">if</span> self.combiner <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> t <span class="keyword">in</span> self.combiner.split(<span class="string">&quot;,&quot;</span>):</span><br><span class="line">                    <span class="keyword">if</span> t <span class="keyword">not</span> <span class="keyword">in</span> valid_combiners:</span><br><span class="line">                        <span class="keyword">raise</span> ValueError(</span><br><span class="line">                            <span class="string">f&quot;combiner: <span class="subst">&#123;self.combiner&#125;</span>. 必须为 <span class="subst">&#123;valid_combiners&#125;</span> 中的一个&quot;</span></span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列din聚合时需要指定对应的key</span></span><br><span class="line">        <span class="keyword">if</span> self.combiner <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="string">&quot;din&quot;</span> <span class="keyword">in</span> self.combiner:</span><br><span class="line">            <span class="keyword">if</span> self.att_key_name <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;att_key_name 不能为空，当combiner为&#x27;din&#x27;时&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.att_key_name, <span class="built_in">str</span>):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;att_key_name 必须为字符串，当combiner为&#x27;din&#x27;时&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列dien聚合时需要指定对应的key</span></span><br><span class="line">        <span class="keyword">if</span> self.combiner <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="string">&quot;dien&quot;</span> <span class="keyword">in</span> self.combiner:</span><br><span class="line">            <span class="keyword">if</span> self.att_key_name <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;att_key_name 不能为空，当combiner为&#x27;dien&#x27;时&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.att_key_name, <span class="built_in">str</span>):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;att_key_name 必须为字符串，当combiner为&#x27;dien&#x27;时&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="loss-py"><code>loss.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">contrastive_loss</span>(<span class="params">y_true, y_pred, temperature=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Batch内对比损失 (InfoNCE)。</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        y_true: 未使用，但为了与Keras兼容而保留</span></span><br><span class="line"><span class="string">        y_pred: 来自模型的余弦相似度分数</span></span><br><span class="line"><span class="string">        temperature: 温度参数控制分布的集中度</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        对比损失值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batch_size = tf.shape(y_pred)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过温度参数缩放相似度</span></span><br><span class="line">    scaled_sim = y_pred / temperature</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为正样本对创建掩码（对角线元素）</span></span><br><span class="line">    pos_mask = tf.eye(batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算log softmax</span></span><br><span class="line">    log_softmax = scaled_sim - tf.math.log(</span><br><span class="line">        tf.reduce_sum(tf.exp(scaled_sim), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算损失作为选择正样本的负对数似然</span></span><br><span class="line">    loss = -tf.reduce_sum(pos_mask * log_softmax, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sampledsoftmaxloss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;因为在模型构建的时候使用了sampled_softmax_loss,这里只需要计算mean就可以了&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> K.mean(y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sum_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> K.<span class="built_in">sum</span>(y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> K.mean(y_pred)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="data-config-py"><code>data_config.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">数据配置</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_env_with_fallback</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动加载环境变量</span></span><br><span class="line">load_env_with_fallback()</span><br><span class="line"></span><br><span class="line">PROCESSED_DATA_PATH = os.getenv(<span class="string">&#x27;FUNREC_PROCESSED_DATA_PATH&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> PROCESSED_DATA_PATH:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&quot;FUNREC_PROCESSED_DATA_PATH 未设置, 请在环境变量中设置&quot;</span>)</span><br><span class="line"></span><br><span class="line">DATASET_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;ml_latest_small_youtubednn&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml_latest_small&quot;</span>,</span><br><span class="line">        <span class="string">&quot;links&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/ml-latest-small/links.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;movies&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/ml-latest-small/movies.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;ratings&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/ml-latest-small/ratings.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;tags&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/ml-latest-small/tags.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml_latest_small_youtubednn.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;raw_log_data&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml_latest_small_youtubednn.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_raw&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_raw/ml_latest_small_youtubednn_raw.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml_latest_small_youtubednn_final.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;e_commerce_rerank_data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;e_commerce_rerank_data&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/rerank_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/rerank_data.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;kuairand_data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;kuairand_data&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/kuairand_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_sample_raw&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_raw/kuairand_1k_train.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;test_sample_raw&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_raw/kuairand_1k_test.csv&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/kuairand_train_eval.pkl&quot;</span></span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="string">&quot;ml-1m_sasrec&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml-1m_sasrec&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml-1m_sequence_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml-1m_sequence_data_dict.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;ml-1m_recall_data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml-1m_recall_data&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml-1m_recall_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml-1m_recall_train_eval.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;ml-1m_recall_pos_neg_data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml-1m_recall_pos_neg_data&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml-1m_recall_pos_neg_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml-1m_recall_pos_neg_train_eval.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;ml-1m_tiger&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml-1m_tiger&quot;</span>,        </span><br><span class="line">        <span class="string">&quot;dense_feature_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/dense_feature/ml-1m_dense_feature.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml-1m_sequence_feature_dict.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml-1m_sequence_data_dict.pkl&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;ml_latest_small_classical&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;dataset_name&quot;</span>: <span class="string">&quot;ml_latest_small_classical&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dict_path&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/feature_dict/ml_latest_small_classical.pkl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_eval_sample_final&quot;</span>: PROCESSED_DATA_PATH + <span class="string">&quot;/train_eval_sample_final/ml_latest_small_classical.pkl&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="运行输出">运行输出</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">已加载 .env 文件： /Users/seymour/GitHub/LLM4Rec/FunRec/.env</span><br><span class="line">[INFO] 14:28:47 Start...</span><br><span class="line"></span><br><span class="line">[1] 采样数据...</span><br><span class="line">[1] 新闻数据...</span><br><span class="line">[2] 相似矩阵...</span><br><span class="line">ItemCF_sim: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 2356880.20it/s]</span><br><span class="line">itemcf相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/itemcf_i2i_sim.pkl</span><br><span class="line">UserCF_sim: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 9622/9622 [00:06&lt;00:00, 1533.21it/s]</span><br><span class="line">usercf相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/usercf_u2u_sim.pkl</span><br><span class="line">faiss 正在处理(等待时间较长)...</span><br><span class="line">faiss 处理完毕.</span><br><span class="line">embedding_sim: 364047it [00:03, 101248.70it/s]</span><br><span class="line">content-based相似度矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/emb_i2i_sim.pkl</span><br><span class="line"></span><br><span class="line">[INFO] 1. YoutubeDNN recall ==============</span><br><span class="line">gen_data_set: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 91134.86it/s]</span><br><span class="line">YoutubeDNN训练后分离user向量矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/user_youtube_emb.pkl</span><br><span class="line">YoutubeDNN训练后分离item向量矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/item_youtube_emb.pkl</span><br><span class="line">FAISS开始处理...</span><br><span class="line">FAISS处理完毕.</span><br><span class="line">YoutubeDNN_相似度矩阵: 20000it [00:00, 68662.67it/s]</span><br><span class="line">YoutubeDNN_u2i矩阵保存：/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/youtube_u2i_dict.pkl</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/YoutubeDNN_recall_12-21 14:30.pkl</span><br><span class="line">Hit@5     2.72% (544/20000)</span><br><span class="line">Hit@10    4.78% (955/20000)</span><br><span class="line">Hit@15    6.61% (1322/20000)</span><br><span class="line">Hit@20    7.82% (1563/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 2. ItemCF(itemcf) recall ===============</span><br><span class="line">ItemCF i2i recall: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 398453.80it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/ItemCF(itemcf)_recall_12-21 14:30.pkl</span><br><span class="line">Hit@5     5.58% (1117/20000)</span><br><span class="line">Hit@10   10.18% (2036/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 3. ItemCF(emb) recall ===============</span><br><span class="line">ItemCF i2i recall: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 62596.41it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/ItemCF(emb)_recall_12-21 14:30.pkl</span><br><span class="line">Hit@5     1.24% (248/20000)</span><br><span class="line">Hit@10    1.47% (293/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 4. UserCF(emb+usercf) recall ===============</span><br><span class="line">UserCF u2u2i recall: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:02&lt;00:00, 6715.24it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/UserCF(emb+usercf)_recall_12-21 14:31.pkl</span><br><span class="line">Hit@5    12.99% (2599/20000)</span><br><span class="line">Hit@10   17.82% (3564/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 5. UserCF(emb+youtubeuser) recall ===============</span><br><span class="line">UserCF u2u_sim: 20000it [00:00, 99120.86it/s] </span><br><span class="line">UserCF(YoutubeUser) recall: 100%|█████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 61500.24it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/UserCF(emb+youtubeuser)_recall_12-21 14:31.pkl</span><br><span class="line">Hit@5     0.98% (196/20000)</span><br><span class="line">Hit@10    4.23% (846/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 6. Coldstart recall ===============</span><br><span class="line">ItemCF i2i recall: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 113369.68it/s]</span><br><span class="line">Cold start recall: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00&lt;00:00, 27419.95it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/Coldstart_recall_12-21 14:31.pkl</span><br><span class="line">Hit@5     0.00% (0/20000)</span><br><span class="line">Hit@10    0.00% (0/20000)</span><br><span class="line"></span><br><span class="line">[INFO] Combine recall results ===============</span><br><span class="line">多路召回合并...</span><br><span class="line">Combine results:   0%|                                                                                                               | 0/6 [00:00&lt;?, ?it/s]YoutubeDNN_recall...</span><br><span class="line">Combine results:  17%|█████████████████▏                                                                                     | 1/6 [00:00&lt;00:00,  7.58it/s]ItemCF(itemcf)_recall...</span><br><span class="line">ItemCF(emb)_recall...</span><br><span class="line">Combine results:  50%|███████████████████████████████████████████████████▌                                                   | 3/6 [00:00&lt;00:00, 11.43it/s]UserCF(emb+usercf)_recall...</span><br><span class="line">UserCF(emb+youtubeuser)_recall...</span><br><span class="line">Combine results:  83%|█████████████████████████████████████████████████████████████████████████████████████▊                 | 5/6 [00:00&lt;00:00, 11.16it/s]Coldstart_recall...</span><br><span class="line">Combine results: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00&lt;00:00, 12.92it/s]</span><br><span class="line">itemcf recall结果保存:/Users/seymour/GitHub/LLM4Rec/FunRec/dataset_processed/projects/news_recommendation/Final_recall_12-21 14:31.pkl</span><br><span class="line">Hit@5    11.84% (2368/20000)</span><br><span class="line">Hit@10   13.63% (2726/20000)</span><br><span class="line">Hit@15   15.66% (3133/20000)</span><br><span class="line">Hit@20   18.55% (3711/20000)</span><br><span class="line">Hit@25   20.75% (4151/20000)</span><br><span class="line">Hit@30   22.70% (4540/20000)</span><br><span class="line"></span><br><span class="line">[INFO] 14:31:05 Finished. (2.30 mins)</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://isSeymour.github.io/butterflyblog">isSeymour</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://isseymour.github.io/butterflyblog/2025/12/21/FunRec_6/">https://isseymour.github.io/butterflyblog/2025/12/21/FunRec_6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://isSeymour.github.io/butterflyblog" target="_blank">isSeymour</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/butterflyblog/tags/%E9%A1%B9%E7%9B%AE/">项目</a></div><div class="post_share"><div class="social-share" data-image="https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" alt="微信支付"/></a><div class="post-qr-code-desc">微信支付</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/butterflyblog/2025/12/18/FunRec_5_3/" title="热点（三）生成式推荐"><img class="cover" src="https://datawhalechina.github.io/fun-rec/_images/onerec.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">热点（三）生成式推荐</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">isSeymour</div><div class="author-info__description">志之所趋，无远弗届，穷山距海，不能限也。</div></div><div class="card-info-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">89</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">43</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isSeymour/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://isSeymour.github.io/" target="_blank" title="学术主页"><i class="fa-regular fa-address-card" style="color: #000000;"></i></a><a class="social-icon" href="https://github.com/isSeymour/" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="https://space.bilibili.com/79699613/" target="_blank" title="B站"><i class="fa-brands fa-bilibili" style="color: #000000;"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_63205991/" target="_blank" title="CSDN"><i class="fa-solid fa-code" style="color: #000000;"></i></a><a class="social-icon" href="mailto:seymour0314@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">赛题项目：阿里天池新闻推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3"><span class="toc-text">一、赛题理解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%95%B0%E6%8D%AE%E6%A6%82%E5%86%B5"><span class="toc-text">1、数据概况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E8%AF%84%E4%BB%B7%E6%96%B9%E5%BC%8F%E7%90%86%E8%A7%A3"><span class="toc-text">2、评价方式理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90"><span class="toc-text">3、问题分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Baseline"><span class="toc-text">二、Baseline</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-text">代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#requirements-txt"><span class="toc-text">requirements.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Baseline-py"><span class="toc-text">Baseline.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#utils-py"><span class="toc-text">utils.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model-itemcf-py"><span class="toc-text">model_itemcf.py</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-text">三、数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%95%B0%E6%8D%AE%E6%9F%A5%E7%9C%8B%E5%88%86%E6%9E%90"><span class="toc-text">1、数据查看分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E6%95%B0%E6%8D%AE%E6%80%BB%E7%BB%93"><span class="toc-text">2、数据总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E"><span class="toc-text">四、多路召回</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9F%A9%E9%98%B5"><span class="toc-text">1、相似度矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%8F%AC%E5%9B%9E"><span class="toc-text">2、召回</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#YoutubeDNN%E5%8F%AC%E5%9B%9E"><span class="toc-text">YoutubeDNN召回</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ItemCF%E5%8F%AC%E5%9B%9E"><span class="toc-text">ItemCF召回</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UserCF%E5%8F%AC%E5%9B%9E"><span class="toc-text">UserCF召回</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%95%88%E6%9E%9C"><span class="toc-text">运行效果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98"><span class="toc-text">3、冷启动问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E%E5%90%88%E5%B9%B6"><span class="toc-text">4、多路召回合并</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-text">五、特征工程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B"><span class="toc-text">六、排序模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%8E%92%E5%BA%8F"><span class="toc-text">1、排序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LGB%E6%8E%92%E5%BA%8F"><span class="toc-text">LGB排序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LGB%E5%88%86%E7%B1%BB"><span class="toc-text">LGB分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DIN"><span class="toc-text">DIN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E6%8E%92%E5%BA%8F%E8%9E%8D%E5%90%88"><span class="toc-text">2、排序融合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88"><span class="toc-text">加权融合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Staking"><span class="toc-text">Staking</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%EF%BC%9A%E4%BB%A3%E7%A0%81"><span class="toc-text">附：代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#recall-py"><span class="toc-text">recall.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#utils-py-2"><span class="toc-text">utils.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model-itemcf-py-2"><span class="toc-text">model_itemcf.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model-usercf-py"><span class="toc-text">model_usercf.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model-youtubednn-py"><span class="toc-text">model_youtubednn.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#preprocessor-py"><span class="toc-text">preprocessor.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#trainer-py"><span class="toc-text">trainer.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#feature-py"><span class="toc-text">feature.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#loss-py"><span class="toc-text">loss.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#data-config-py"><span class="toc-text">data_config.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E8%BE%93%E5%87%BA"><span class="toc-text">运行输出</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://datawhalechina.github.io/fun-rec/_images/3_multi_channel_recall.png')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By isSeymour</div><div class="footer_custom_text">欢迎乘坐我的生活地铁！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/butterflyblog/js/utils.js"></script><script src="/butterflyblog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23liAZxomGv7Hapw8g',
      clientSecret: 'f7cafde192c4ada8bef4b76952c422d90575cf8b',
      repo: 'gitalk',
      owner: 'isSeymour',
      admin: ['isSeymour'],
      id: '60ed560abbe80a5478daffd53f2f588e',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/butterflyblog/js/search/local-search.js"></script></div></div></body></html>