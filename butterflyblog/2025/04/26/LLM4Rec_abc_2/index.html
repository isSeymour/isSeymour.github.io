<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大模型推荐系统（2）预训练范式 | isSeymour</title><meta name="author" content="isSeymour"><meta name="copyright" content="isSeymour"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="阅读书籍: 《大模型推荐系统 | 算法原理、代码实战与案例分析》刘强 数据集来源：  MIND 新闻数据集对应论文MIND: A Large-scale Dataset for News Recommendation Amazon 电商数据集  注：大型文件包工具git-lfs、强化学习训练工具trl  预训练范式  通过大模型预训练进行推荐  1、预训练的一般思路与方法 1.1 预训练数据的准备">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型推荐系统（2）预训练范式">
<meta property="og:url" content="https://isseymour.github.io/butterflyblog/2025/04/26/LLM4Rec_abc_2/index.html">
<meta property="og:site_name" content="isSeymour">
<meta property="og:description" content="阅读书籍: 《大模型推荐系统 | 算法原理、代码实战与案例分析》刘强 数据集来源：  MIND 新闻数据集对应论文MIND: A Large-scale Dataset for News Recommendation Amazon 电商数据集  注：大型文件包工具git-lfs、强化学习训练工具trl  预训练范式  通过大模型预训练进行推荐  1、预训练的一般思路与方法 1.1 预训练数据的准备">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png">
<meta property="article:published_time" content="2025-04-26T04:00:00.000Z">
<meta property="article:modified_time" content="2025-04-26T04:00:00.000Z">
<meta property="article:author" content="isSeymour">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/IC1011.ico"><link rel="canonical" href="https://isseymour.github.io/butterflyblog/2025/04/26/LLM4Rec_abc_2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/butterflyblog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/butterflyblog/',
  algolia: undefined,
  localSearch: {"path":"/butterflyblog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大模型推荐系统（2）预训练范式',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-04-26 12:00:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyblog/code/style.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">74</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">37</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/luogu/"><i class="fa-fw fa-solid fa-magnet"></i><span> 洛谷</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png')"><nav id="nav"><span id="blog-info"><a href="/butterflyblog/" title="isSeymour"><span class="site-name">isSeymour</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/luogu/"><i class="fa-fw fa-solid fa-magnet"></i><span> 洛谷</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大模型推荐系统（2）预训练范式</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-26T04:00:00.000Z" title="发表于 2025-04-26 12:00:00">2025-04-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-26T04:00:00.000Z" title="更新于 2025-04-26 12:00:00">2025-04-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/butterflyblog/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大模型推荐系统（2）预训练范式"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note danger no-icon flat"><p>阅读书籍: 《大模型推荐系统 | 算法原理、代码实战与案例分析》刘强<br>
数据集来源：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://msnews.github.io">MIND 新闻数据集</a>对应论文<a target="_blank" rel="noopener" href="https://msnews.github.io/assets/doc/ACL2020_MIND.pdf">MIND: A Large-scale Dataset for News Recommendation</a></li>
<li><a target="_blank" rel="noopener" href="https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/">Amazon 电商数据集</a></li>
</ul>
<p>注：大型文件包工具<a target="_blank" rel="noopener" href="https://git-lfs.com">git-lfs</a>、强化学习训练工具<a target="_blank" rel="noopener" href="https://github.com/huggingface/trl">trl</a></p>
</div>
<h1>预训练范式</h1>
<blockquote>
<p>通过大模型预训练进行推荐</p>
</blockquote>
<h2 id="1、预训练的一般思路与方法">1、预训练的一般思路与方法</h2>
<h3 id="1-1-预训练数据的准备">1.1 预训练数据的准备</h3>
<ul>
<li>直接利用用户行为序列</li>
<li>将用户行为序列 ID 转为相关文本</li>
<li>在用户行为序列中整合用户的特征</li>
</ul>
<h3 id="1-2-大模型架构的选择">1.2 大模型架构的选择</h3>
<ul>
<li>BERT4Rec</li>
<li>PTUM</li>
<li>P5</li>
<li>M6-Rec</li>
</ul>
<h3 id="1-3-大模型预训练">1.3 大模型预训练</h3>
<ul>
<li>Transformers 库</li>
<li>苹果 MLX 框架</li>
</ul>
<h3 id="1-4-大模型推理">1.4 大模型推理</h3>
<ul>
<li>Transformers 库</li>
<li>llama.cpp推理</li>
</ul>
<h2 id="2、案例">2、案例</h2>
<h3 id="2-1-基于-PTUM-架构的预训练推荐系统">2.1 基于 PTUM 架构的预训练推荐系统</h3>
<blockquote>
<p>PTUM : Pre-Training User Model</p>
</blockquote>
<ol>
<li>掩码行为预测</li>
<li>后续行为预测</li>
</ol>
<h3 id="2-2-基于-P5-的预训练推荐系统">2.2 基于 P5 的预训练推荐系统</h3>
<blockquote>
<p>P5: Pretrain, Personalized Prompt, and Predict Paradigm</p>
</blockquote>
<ul>
<li>预训练数据准备
<ol>
<li>评分、评论、解释</li>
<li>序列推荐</li>
<li>直接推荐</li>
</ol>
</li>
<li>P5 模型架构</li>
<li>P5 预训练</li>
<li>P5 推理</li>
</ul>
<h2 id="3、基于-MIND-数据集的代码实战">3、基于 MIND 数据集的代码实战</h2>
<h3 id="3-1-预训练数据集准备">3.1 预训练数据集准备</h3>
<p>(1)生成预训练的序列数据<br>
文件<code>generate_user_sequence.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">user_sequence_list = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;../data/mind/behaviors.tsv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    reader = csv.reader(file, delimiter=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        uid = row[<span class="number">1</span>]</span><br><span class="line">        history = row[<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(history.split(<span class="string">&quot; &quot;</span>)) &gt;= <span class="number">5</span>:  <span class="comment"># 用户至少要有5个点击历史</span></span><br><span class="line">            r = uid + <span class="string">&quot; &quot;</span> + history</span><br><span class="line">            user_sequence_list.append(r)</span><br><span class="line"></span><br><span class="line">user_sequence_path = <span class="string">&quot;../data/mind/user_sequence.txt&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(user_sequence_path, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> user_sequence_list:</span><br><span class="line">        file.write(r + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>(2) 生成预训练数据<br>
文件<code>generate_dataset_train.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&#x27;../&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> sequential_indexing, load_prompt_template, check_task_prompt, get_info_from_prompt</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> construct_user_sequence_dict, read_line</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">data_path: <span class="built_in">str</span>, item_indexing: <span class="built_in">str</span>, task: <span class="built_in">str</span>, dataset: <span class="built_in">str</span>, prompt_file: <span class="built_in">str</span>, sequential_order: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">         max_his: <span class="built_in">int</span>, his_sep: <span class="built_in">str</span>, his_prefix: <span class="built_in">int</span>, skip_empty_his: <span class="built_in">int</span></span>):</span><br><span class="line">    file_data = <span class="built_in">dict</span>()</span><br><span class="line">    file_data[<span class="string">&#x27;arguments&#x27;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;data_path&quot;</span>: data_path, <span class="string">&quot;item_indexing&quot;</span>: item_indexing, <span class="string">&quot;task&quot;</span>: task,</span><br><span class="line">        <span class="string">&quot;dataset&quot;</span>: dataset, <span class="string">&quot;prompt_file&quot;</span>: prompt_file, <span class="string">&quot;sequential_order&quot;</span>: sequential_order,</span><br><span class="line">        <span class="string">&quot;max_his&quot;</span>: max_his, <span class="string">&quot;his_sep&quot;</span>: his_sep, <span class="string">&quot;his_prefix&quot;</span>: his_prefix, <span class="string">&quot;skip_empty_his&quot;</span>: skip_empty_his</span><br><span class="line">    &#125;</span><br><span class="line">    file_data[<span class="string">&#x27;data&#x27;</span>] = []</span><br><span class="line">    tasks = <span class="built_in">list</span>(task)</span><br><span class="line">    user_sequence = read_line(os.path.join(data_path, dataset, <span class="string">&#x27;user_sequence.txt&#x27;</span>))</span><br><span class="line">    user_sequence_dict = construct_user_sequence_dict(user_sequence)</span><br><span class="line"></span><br><span class="line">    reindex_user_seq_dict, item_map = sequential_indexing(data_path, dataset,</span><br><span class="line">                                                          user_sequence_dict, sequential_order)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get prompt</span></span><br><span class="line">    prompt = load_prompt_template(prompt_file, tasks)</span><br><span class="line">    info = get_info_from_prompt(prompt)</span><br><span class="line">    check_task_prompt(prompt, tasks)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load training data samples</span></span><br><span class="line">    training_data_samples = []</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> reindex_user_seq_dict:</span><br><span class="line">        items = reindex_user_seq_dict[user][:-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(items)):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> skip_empty_his &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">            one_sample = <span class="built_in">dict</span>()</span><br><span class="line">            one_sample[<span class="string">&#x27;dataset&#x27;</span>] = dataset</span><br><span class="line">            one_sample[<span class="string">&#x27;user_id&#x27;</span>] = user</span><br><span class="line">            <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;target&#x27;</span>] = <span class="string">&#x27;item_&#x27;</span> + items[i]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;target&#x27;</span>] = items[i]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;history&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">                history = items[:i]</span><br><span class="line">                <span class="keyword">if</span> max_his &gt; <span class="number">0</span>:</span><br><span class="line">                    history = history[-max_his:]</span><br><span class="line">                <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">                    one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join([<span class="string">&quot;item_&quot;</span> + item_idx <span class="keyword">for</span> item_idx <span class="keyword">in</span> history])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join(history)</span><br><span class="line">            training_data_samples.append(one_sample)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;load training data&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;there are <span class="subst">&#123;<span class="built_in">len</span>(training_data_samples)&#125;</span> samples in training data.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># construct sentences</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(training_data_samples)):</span><br><span class="line">        one_sample = training_data_samples[i]</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> tasks:</span><br><span class="line">            datapoint = &#123;<span class="string">&#x27;task&#x27;</span>: dataset + t, <span class="string">&#x27;data_id&#x27;</span>: i&#125;</span><br><span class="line">            <span class="keyword">for</span> pid <span class="keyword">in</span> prompt[t][<span class="string">&#x27;seen&#x27;</span>]:</span><br><span class="line">                datapoint[<span class="string">&#x27;instruction&#x27;</span>] = prompt[t][<span class="string">&#x27;seen&#x27;</span>][pid][<span class="string">&#x27;Input&#x27;</span>]</span><br><span class="line">                datapoint[<span class="string">&#x27;input&#x27;</span>] = prompt[t][<span class="string">&#x27;seen&#x27;</span>][pid][<span class="string">&#x27;Input&#x27;</span>].<span class="built_in">format</span>(**one_sample)</span><br><span class="line">                datapoint[<span class="string">&#x27;output&#x27;</span>] = prompt[t][<span class="string">&#x27;seen&#x27;</span>][pid][<span class="string">&#x27;Output&#x27;</span>].<span class="built_in">format</span>(**one_sample)</span><br><span class="line">                file_data[<span class="string">&#x27;data&#x27;</span>].append(datapoint.copy())</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data constructed&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;there are <span class="subst">&#123;<span class="built_in">len</span>(file_data[<span class="string">&#x27;data&#x27;</span>])&#125;</span> prompts in training data.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># save the data to json file</span></span><br><span class="line">    output_path = <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_train.json&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_path, dataset, output_path), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> openfile:</span><br><span class="line">        json.dump(file_data, openfile)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fire.Fire(main)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>附录<code>utils.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dict_from_lines</span>(<span class="params">lines</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Used to get user or item map from lines loaded from txt file.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index_map = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        info = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">        index_map[info[<span class="number">0</span>]] = info[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> index_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_line</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError</span><br><span class="line">    lines = []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">            lines.append(line.rstrip(<span class="string">&#x27;\n&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_dict_2_file</span>(<span class="params">path, write_dict</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> out:</span><br><span class="line">        <span class="keyword">for</span> user, items <span class="keyword">in</span> write_dict.items():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(items) == <span class="built_in">list</span>:</span><br><span class="line">                out.write(user + <span class="string">&#x27; &#x27;</span> + <span class="string">&#x27; &#x27;</span>.join(items) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                out.write(user + <span class="string">&#x27; &#x27;</span> + <span class="built_in">str</span>(items) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EvaluationDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, tokenizer, cutoff</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.<span class="built_in">input</span> = tokenizer(</span><br><span class="line">            dataset[<span class="string">&#x27;input&#x27;</span>], padding=<span class="string">&quot;longest&quot;</span>, truncation=<span class="literal">True</span>, max_length=cutoff</span><br><span class="line">        )</span><br><span class="line">        self.output = tokenizer(</span><br><span class="line">            dataset[<span class="string">&#x27;output&#x27;</span>], padding=<span class="string">&quot;longest&quot;</span>, truncation=<span class="literal">True</span>, max_length=cutoff</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.<span class="built_in">input</span>[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;input_ids&quot;</span>: torch.tensor(self.<span class="built_in">input</span>[<span class="string">&quot;input_ids&quot;</span>][index]),</span><br><span class="line">            <span class="string">&quot;attention_mask&quot;</span>: torch.tensor(self.<span class="built_in">input</span>[<span class="string">&quot;attention_mask&quot;</span>][index]),</span><br><span class="line">            <span class="string">&#x27;label&#x27;</span>: torch.tensor(self.output[<span class="string">&quot;input_ids&quot;</span>][index])</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_prompt_template</span>(<span class="params">path, task_list</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Load prompt template from the file. Keep training tasks only.</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - path: The path for prompt template txt file.</span></span><br><span class="line"><span class="string">    - task_list: A list of required tasks.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">    - prompt_templates: a dictionary of prompt templates. e.g., &#123;task: &#123;&#x27;seen&#x27;: &#123;&#x27;0&#x27;: &#123;&#x27;Input&#x27;: template_input, &#x27;Output&#x27;: template_output&#125;&#125;&#125;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError</span><br><span class="line">    prompt_info = read_line(path)</span><br><span class="line">    prompt_templates = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> prompt <span class="keyword">in</span> prompt_info:</span><br><span class="line">        t = [sens.strip() <span class="keyword">for</span> sens <span class="keyword">in</span> prompt.split(<span class="string">&#x27;;&#x27;</span>)]</span><br><span class="line">        <span class="keyword">if</span> t[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> task_list:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> t[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> prompt_templates:</span><br><span class="line">            prompt_templates[t[<span class="number">0</span>]] = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">if</span> t[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> prompt_templates[t[<span class="number">0</span>]]:</span><br><span class="line">            prompt_templates[t[<span class="number">0</span>]][t[<span class="number">1</span>]] = <span class="built_in">dict</span>()</span><br><span class="line">        num = <span class="built_in">len</span>(prompt_templates[t[<span class="number">0</span>]][t[<span class="number">1</span>]])</span><br><span class="line">        prompt_templates[t[<span class="number">0</span>]][t[<span class="number">1</span>]][<span class="built_in">str</span>(num)] = <span class="built_in">dict</span>()</span><br><span class="line">        prompt_templates[t[<span class="number">0</span>]][t[<span class="number">1</span>]][<span class="built_in">str</span>(num)][<span class="string">&#x27;Input&#x27;</span>] = t[<span class="number">2</span>]</span><br><span class="line">        prompt_templates[t[<span class="number">0</span>]][t[<span class="number">1</span>]][<span class="built_in">str</span>(num)][<span class="string">&#x27;Output&#x27;</span>] = t[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">return</span> prompt_templates</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_user_map</span>(<span class="params">user_sequence_dict</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    generate user map based on user sequence dict.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    user_map = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> user_sequence_dict.keys():</span><br><span class="line">        user_map[user] = <span class="built_in">str</span>(<span class="built_in">len</span>(user_map) + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> user_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reindex</span>(<span class="params">user_sequence_dict, user_map, item_map</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    reindex the given user sequence dict by given user map and item map</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    reindex_user_sequence_dict = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> user_sequence_dict:</span><br><span class="line">        uid = user_map[user]</span><br><span class="line">        items = user_sequence_dict[user]</span><br><span class="line">        reindex_user_sequence_dict[uid] = [item_map[i] <span class="keyword">for</span> i <span class="keyword">in</span> items]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reindex_user_sequence_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">construct_user_sequence_dict</span>(<span class="params">user_sequence</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Convert a list of string to a user sequence dict. user as key, item list as value.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    user_seq_dict = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> user_sequence:</span><br><span class="line">        user_seq = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">        user_seq_dict[user_seq[<span class="number">0</span>]] = user_seq[<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">return</span> user_seq_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sequential_indexing</span>(<span class="params">data_path, dataset, user_sequence_dict, order</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use sequential indexing method to index the given user seuqnece dict.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    user_index_file = os.path.join(data_path, dataset, <span class="string">&#x27;user_indexing.txt&#x27;</span>)</span><br><span class="line">    item_index_file = os.path.join(data_path, dataset, <span class="string">f&#x27;item_sequential_indexing_<span class="subst">&#123;order&#125;</span>.txt&#x27;</span>)</span><br><span class="line">    reindex_sequence_file = os.path.join(data_path, dataset, <span class="string">f&#x27;user_sequence_sequential_indexing_<span class="subst">&#123;order&#125;</span>.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(reindex_sequence_file):</span><br><span class="line">        user_sequence = read_line(reindex_sequence_file)</span><br><span class="line"></span><br><span class="line">        item_info = read_line(item_index_file)</span><br><span class="line">        item_map = get_dict_from_lines(item_info)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> construct_user_sequence_dict(user_sequence), item_map</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For user index, load from txt file if already exists, otherwise generate from user sequence and save.</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(user_index_file):</span><br><span class="line">        user_info = read_line(user_index_file)</span><br><span class="line">        user_map = get_dict_from_lines(user_info)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        user_map = generate_user_map(user_sequence_dict)</span><br><span class="line">        write_dict_2_file(user_index_file, user_map)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For item index, load from txt file if already exists, otherwise generate from user sequence and save.</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(item_index_file):</span><br><span class="line">        item_info = read_line(item_index_file)</span><br><span class="line">        item_map = get_dict_from_lines(item_info)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        item_map = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">if</span> order == <span class="string">&#x27;original&#x27;</span>:</span><br><span class="line">            user_list = user_sequence_dict.keys()</span><br><span class="line">        <span class="keyword">elif</span> order == <span class="string">&#x27;short2long&#x27;</span>:</span><br><span class="line">            user_list = <span class="built_in">sorted</span>(user_sequence_dict, key=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(user_sequence_dict[x]), reverse=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">elif</span> order == <span class="string">&#x27;long2short&#x27;</span>:</span><br><span class="line">            user_list = <span class="built_in">sorted</span>(user_sequence_dict, key=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(user_sequence_dict[x]), reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> user_list:</span><br><span class="line">            items = user_sequence_dict[user][:-<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> item_map:</span><br><span class="line">                    item_map[item] = <span class="built_in">str</span>(<span class="built_in">len</span>(item_map) + <span class="number">1001</span>)</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> user_list:</span><br><span class="line">            items = user_sequence_dict[user][-<span class="number">2</span>:]</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> item_map:</span><br><span class="line">                    item_map[item] = <span class="built_in">str</span>(<span class="built_in">len</span>(item_map) + <span class="number">1001</span>)</span><br><span class="line">        write_dict_2_file(item_index_file, item_map)</span><br><span class="line"></span><br><span class="line">    reindex_user_sequence_dict = reindex(user_sequence_dict, user_map, item_map)</span><br><span class="line">    write_dict_2_file(reindex_sequence_file, reindex_user_sequence_dict)</span><br><span class="line">    <span class="keyword">return</span> reindex_user_sequence_dict, item_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_info_from_prompt</span>(<span class="params">prompt_templates</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Extract the require information from the prompt templates.</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - prompt_templates: a dictionary of prompt templates.</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    - info: a list of required information.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    info = []</span><br><span class="line">    <span class="keyword">for</span> task <span class="keyword">in</span> prompt_templates:</span><br><span class="line">        <span class="keyword">for</span> see <span class="keyword">in</span> prompt_templates[task]:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> prompt_templates[task][see]:</span><br><span class="line">                info += re.findall(<span class="string">r&#x27;\&#123;.*?\&#125;&#x27;</span>, prompt_templates[task][see][i][<span class="string">&#x27;Input&#x27;</span>])</span><br><span class="line">                info += re.findall(<span class="string">r&#x27;\&#123;.*?\&#125;&#x27;</span>, prompt_templates[task][see][i][<span class="string">&#x27;Output&#x27;</span>])</span><br><span class="line">    info = [i[<span class="number">1</span>:-<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">set</span>(info)]</span><br><span class="line">    <span class="keyword">return</span> info</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_task_prompt</span>(<span class="params">prompt_templates, task_list</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Check if all tasks have prompt templates. Raise Error if training tasks have no prompt.</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - prompt_templates: A dictionary of prompt templates.</span></span><br><span class="line"><span class="string">    - task_list: A list of training tasks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> task <span class="keyword">in</span> task_list:</span><br><span class="line">        <span class="keyword">assert</span> task <span class="keyword">in</span> prompt_templates, <span class="string">f&quot;No prompt for <span class="subst">&#123;task&#125;</span> task&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluation_results</span>(<span class="params">predictions, targets, scores, k</span>):</span><br><span class="line">    results = []</span><br><span class="line">    batch_length = <span class="built_in">len</span>(targets)</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(batch_length):</span><br><span class="line">        one_batch_sequence = predictions[</span><br><span class="line">                             b * k: (b + <span class="number">1</span>) * k</span><br><span class="line">                             ]</span><br><span class="line">        one_batch_score = scores[</span><br><span class="line">                          b * k: (b + <span class="number">1</span>) * k</span><br><span class="line">                          ]</span><br><span class="line">        pairs = [(a, b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(one_batch_sequence, one_batch_score)]</span><br><span class="line">        sorted_pairs = <span class="built_in">sorted</span>(pairs, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        gt = targets[b]</span><br><span class="line">        one_results = []</span><br><span class="line">        <span class="keyword">for</span> sorted_pred <span class="keyword">in</span> sorted_pairs:</span><br><span class="line">            <span class="keyword">if</span> sorted_pred[<span class="number">0</span>] == gt:</span><br><span class="line">                one_results.append(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                one_results.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        results.append(one_results)</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ndcg_at_k</span>(<span class="params">relevance, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Since we apply leave-one-out, each user only have one ground truth item, so the idcg would be 1.0</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ndcg = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> relevance:</span><br><span class="line">        rel = row[:k]</span><br><span class="line">        one_ndcg = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(rel)):</span><br><span class="line">            one_ndcg += rel[i] / math.log(i + <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        ndcg += one_ndcg</span><br><span class="line">    <span class="keyword">return</span> ndcg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hit_at_k</span>(<span class="params">relevance, k</span>):</span><br><span class="line">    correct = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> relevance:</span><br><span class="line">        rel = row[:k]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span>(rel) &gt; <span class="number">0</span>:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> correct</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics_results</span>(<span class="params">rel_results, metrics</span>):</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> metrics:</span><br><span class="line">        <span class="keyword">if</span> m.lower().startswith(<span class="string">&#x27;hit&#x27;</span>):</span><br><span class="line">            k = <span class="built_in">int</span>(m.split(<span class="string">&#x27;@&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">            res.append(hit_at_k(rel_results, k))</span><br><span class="line">        <span class="keyword">elif</span> m.lower().startswith(<span class="string">&#x27;ndcg&#x27;</span>):</span><br><span class="line">            k = <span class="built_in">int</span>(m.split(<span class="string">&#x27;@&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">            res.append(ndcg_at_k(rel_results, k))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_test</span>(<span class="params">reindex_user_seq_dict, info, dataset, his_prefix, max_his, his_sep</span>):</span><br><span class="line">    data_samples = []</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> reindex_user_seq_dict:</span><br><span class="line">        items = reindex_user_seq_dict[user]</span><br><span class="line">        one_sample = <span class="built_in">dict</span>()</span><br><span class="line">        one_sample[<span class="string">&#x27;dataset&#x27;</span>] = dataset</span><br><span class="line">        one_sample[<span class="string">&#x27;user_id&#x27;</span>] = user</span><br><span class="line">        <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">            one_sample[<span class="string">&#x27;target&#x27;</span>] = <span class="string">&#x27;item_&#x27;</span> + items[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            one_sample[<span class="string">&#x27;target&#x27;</span>] = items[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;history&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">            history = items[:-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> max_his &gt; <span class="number">0</span>:</span><br><span class="line">                history = history[-max_his:]</span><br><span class="line">            <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join([<span class="string">&quot;item_&quot;</span> + item_idx <span class="keyword">for</span> item_idx <span class="keyword">in</span> history])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join(history)</span><br><span class="line">        data_samples.append(one_sample)</span><br><span class="line">    <span class="keyword">return</span> data_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_validation</span>(<span class="params">reindex_user_seq_dict, info, dataset, his_prefix, max_his, his_sep</span>):</span><br><span class="line">    data_samples = []</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> reindex_user_seq_dict:</span><br><span class="line">        items = reindex_user_seq_dict[user]</span><br><span class="line">        one_sample = <span class="built_in">dict</span>()</span><br><span class="line">        one_sample[<span class="string">&#x27;dataset&#x27;</span>] = dataset</span><br><span class="line">        one_sample[<span class="string">&#x27;user_id&#x27;</span>] = user</span><br><span class="line">        <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">            one_sample[<span class="string">&#x27;target&#x27;</span>] = <span class="string">&#x27;item_&#x27;</span> + items[-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            one_sample[<span class="string">&#x27;target&#x27;</span>] = items[-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;history&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">            history = items[:-<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> max_his &gt; <span class="number">0</span>:</span><br><span class="line">                history = history[-max_his:]</span><br><span class="line">            <span class="keyword">if</span> his_prefix &gt; <span class="number">0</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join([<span class="string">&quot;item_&quot;</span> + item_idx <span class="keyword">for</span> item_idx <span class="keyword">in</span> history])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                one_sample[<span class="string">&#x27;history&#x27;</span>] = his_sep.join(history)</span><br><span class="line">        data_samples.append(one_sample)</span><br><span class="line">    <span class="keyword">return</span> data_samples</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>(3)生成测试、验证数据<br>
文件<code>generate_dataset_eval.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&#x27;../&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> sequential_indexing, load_prompt_template, check_task_prompt, get_info_from_prompt</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> construct_user_sequence_dict, read_line, load_test, load_validation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">data_path: <span class="built_in">str</span>, item_indexing: <span class="built_in">str</span>, task: <span class="built_in">str</span>, dataset: <span class="built_in">str</span>, prompt_file: <span class="built_in">str</span>, sequential_order: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">         max_his: <span class="built_in">int</span>, his_sep: <span class="built_in">str</span>, his_prefix: <span class="built_in">int</span>, skip_empty_his: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">         mode: <span class="built_in">str</span>, prompt: <span class="built_in">str</span></span>):</span><br><span class="line">    file_data = <span class="built_in">dict</span>()</span><br><span class="line">    file_data[<span class="string">&#x27;arguments&#x27;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;data_path&quot;</span>: data_path, <span class="string">&quot;item_indexing&quot;</span>: item_indexing, <span class="string">&quot;task&quot;</span>: task,</span><br><span class="line">        <span class="string">&quot;dataset&quot;</span>: dataset, <span class="string">&quot;prompt_file&quot;</span>: prompt_file, <span class="string">&quot;sequential_order&quot;</span>: sequential_order,</span><br><span class="line">        <span class="string">&quot;max_his&quot;</span>: max_his, <span class="string">&quot;his_sep&quot;</span>: his_sep, <span class="string">&quot;his_prefix&quot;</span>: his_prefix, <span class="string">&quot;skip_empty_his&quot;</span>: skip_empty_his,</span><br><span class="line">        <span class="string">&quot;mode&quot;</span>: mode, <span class="string">&quot;prompt&quot;</span>: prompt</span><br><span class="line">    &#125;</span><br><span class="line">    file_data[<span class="string">&#x27;data&#x27;</span>] = []</span><br><span class="line">    tasks = <span class="built_in">list</span>(task)</span><br><span class="line"></span><br><span class="line">    user_sequence = read_line(os.path.join(data_path, dataset, <span class="string">&#x27;user_sequence.txt&#x27;</span>))</span><br><span class="line">    user_sequence_dict = construct_user_sequence_dict(user_sequence)</span><br><span class="line">    reindex_user_seq_dict, item_map = sequential_indexing(data_path, dataset,</span><br><span class="line">                                                          user_sequence_dict, sequential_order)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get prompt</span></span><br><span class="line">    prompt_ = load_prompt_template(prompt_file, tasks)</span><br><span class="line">    info = get_info_from_prompt(prompt_)</span><br><span class="line">    check_task_prompt(prompt_, tasks)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load data samples</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;validation&#x27;</span>:</span><br><span class="line">        data_samples = load_validation(reindex_user_seq_dict, info, dataset, his_prefix, max_his, his_sep)</span><br><span class="line">        prompt_info = prompt.split(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">        output_path = <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_validation_<span class="subst">&#123;prompt&#125;</span>.json&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        data_samples = load_test(reindex_user_seq_dict, info, dataset, his_prefix, max_his, his_sep)</span><br><span class="line">        prompt_info = prompt.split(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">        output_path = <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_test_<span class="subst">&#123;prompt&#125;</span>.json&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="comment"># construct sentences</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data_samples)):</span><br><span class="line">        one_sample = data_samples[i]</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> tasks:</span><br><span class="line">            datapoint = &#123;<span class="string">&#x27;task&#x27;</span>: dataset + t,</span><br><span class="line">                         <span class="string">&#x27;instruction&#x27;</span>: prompt_[t][prompt_info[<span class="number">0</span>]][prompt_info[<span class="number">1</span>]][<span class="string">&#x27;Input&#x27;</span>],</span><br><span class="line">                         <span class="string">&#x27;input&#x27;</span>: prompt_[t][prompt_info[<span class="number">0</span>]][prompt_info[<span class="number">1</span>]][<span class="string">&#x27;Input&#x27;</span>].<span class="built_in">format</span>(**one_sample),</span><br><span class="line">                         <span class="string">&#x27;output&#x27;</span>: prompt_[t][prompt_info[<span class="number">0</span>]][prompt_info[<span class="number">1</span>]][<span class="string">&#x27;Output&#x27;</span>].<span class="built_in">format</span>(**one_sample)&#125;</span><br><span class="line">            file_data[<span class="string">&#x27;data&#x27;</span>].append(datapoint.copy())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_path, dataset, output_path), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> openfile:</span><br><span class="line">        json.dump(file_data, openfile)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fire.Fire(main)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-2-模型预训练">3.2 模型预训练</h3>
<p>基于 T5 基地<br>
文件<code>t5_pre-train.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    T5Config,</span><br><span class="line">    T5ForConditionalGeneration,</span><br><span class="line">    AutoTokenizer,</span><br><span class="line">    Trainer,</span><br><span class="line">    TrainingArguments</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">backbone: <span class="built_in">str</span>, data_path: <span class="built_in">str</span>, item_indexing: <span class="built_in">str</span>, task: <span class="built_in">str</span>, dataset: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">         valid_prompt: <span class="built_in">str</span>, cutoff: <span class="built_in">int</span>, model_dir: <span class="built_in">str</span>, batch_size: <span class="built_in">int</span>, valid_select: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">         epochs: <span class="built_in">int</span>, lr: <span class="built_in">float</span>, warmup_steps: <span class="built_in">int</span>, gradient_accumulation_steps: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">         logging_steps: <span class="built_in">int</span>, optim: <span class="built_in">str</span>, eval_steps: <span class="built_in">int</span>, save_steps: <span class="built_in">int</span>, save_total_limit: <span class="built_in">int</span></span>):</span><br><span class="line"></span><br><span class="line">    config = T5Config.from_pretrained(backbone)</span><br><span class="line">    model = T5ForConditionalGeneration.from_pretrained(backbone, config=config)</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(backbone)</span><br><span class="line"></span><br><span class="line">    train_data_file = os.path.join(data_path, dataset,</span><br><span class="line">                                   <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_train.json&#x27;</span>)</span><br><span class="line">    valid_data_file = os.path.join(data_path, dataset,</span><br><span class="line">                                   <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_validation_<span class="subst">&#123;valid_prompt&#125;</span>.json&#x27;</span>)</span><br><span class="line">    train_data = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=train_data_file, field=<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    valid_data = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=valid_data_file, field=<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">prompt, add_eos_token=<span class="literal">True</span></span>):</span><br><span class="line">        result = tokenizer(</span><br><span class="line">            prompt, truncation=<span class="literal">True</span>, max_length=cutoff, padding=<span class="literal">False</span>, return_tensors=<span class="literal">None</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isinstance</span>(result[<span class="string">&quot;input_ids&quot;</span>][-<span class="number">1</span>], <span class="built_in">int</span>) <span class="keyword">and</span> result[<span class="string">&quot;input_ids&quot;</span>][-<span class="number">1</span>] != tokenizer.eos_token_id</span><br><span class="line">                <span class="keyword">and</span> <span class="built_in">len</span>(result[<span class="string">&quot;input_ids&quot;</span>]) &lt; cutoff</span><br><span class="line">                <span class="keyword">and</span> add_eos_token</span><br><span class="line">        ):</span><br><span class="line">            result[<span class="string">&quot;input_ids&quot;</span>].append(tokenizer.eos_token_id)</span><br><span class="line">            result[<span class="string">&quot;attention_mask&quot;</span>].append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(result[<span class="string">&quot;input_ids&quot;</span>][-<span class="number">1</span>], <span class="built_in">list</span>) <span class="keyword">and</span> add_eos_token:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result[<span class="string">&#x27;input_ids&#x27;</span>])):</span><br><span class="line">                <span class="keyword">if</span> result[<span class="string">&quot;input_ids&quot;</span>][i][-<span class="number">1</span>] != tokenizer.eos_token_id <span class="keyword">and</span> <span class="built_in">len</span>(result[<span class="string">&quot;input_ids&quot;</span>][i]) &lt; cutoff:</span><br><span class="line">                    result[<span class="string">&quot;input_ids&quot;</span>][i].append(tokenizer.eos_token_id)</span><br><span class="line">                    result[<span class="string">&quot;attention_mask&quot;</span>][i].append(<span class="number">1</span>)</span><br><span class="line">        result[<span class="string">&quot;labels&quot;</span>] = result[<span class="string">&quot;input_ids&quot;</span>].copy()</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_func</span>(<span class="params">datapoint</span>):</span><br><span class="line">        encoding = tokenize(datapoint[<span class="string">&#x27;input&#x27;</span>], add_eos_token=<span class="literal">True</span>)</span><br><span class="line">        labels = tokenize(datapoint[<span class="string">&#x27;output&#x27;</span>], add_eos_token=<span class="literal">True</span>)</span><br><span class="line">        encoding[<span class="string">&#x27;labels&#x27;</span>] = labels[<span class="string">&#x27;input_ids&#x27;</span>].copy()</span><br><span class="line">        <span class="comment"># return encoding</span></span><br><span class="line">        <span class="keyword">return</span> &#123;**datapoint, **encoding&#125;</span><br><span class="line"></span><br><span class="line">    tokenizer.pad_token_id = (</span><br><span class="line">        <span class="number">0</span>  <span class="comment"># unk. we want this to be different from the eos token</span></span><br><span class="line">    )</span><br><span class="line">    tokenizer.padding_side = <span class="string">&quot;left&quot;</span></span><br><span class="line">    train_set = train_data[<span class="string">&#x27;train&#x27;</span>].shuffle().<span class="built_in">map</span>(process_func, batched=<span class="literal">True</span>)</span><br><span class="line">    valid_set = valid_data[<span class="string">&#x27;train&#x27;</span>].shuffle().<span class="built_in">map</span>(process_func, batched=<span class="literal">True</span>)</span><br><span class="line">    output_dir = os.path.join(model_dir, dataset, item_indexing, backbone)</span><br><span class="line">    trainer = Trainer(</span><br><span class="line">        model=model,</span><br><span class="line">        train_dataset=train_set,</span><br><span class="line">        eval_dataset=valid_set <span class="keyword">if</span> valid_select &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">        args=TrainingArguments(</span><br><span class="line">            per_device_train_batch_size=batch_size,</span><br><span class="line">            gradient_accumulation_steps=gradient_accumulation_steps,</span><br><span class="line">            warmup_steps=warmup_steps,</span><br><span class="line">            num_train_epochs=epochs,</span><br><span class="line">            learning_rate=lr,</span><br><span class="line">            logging_steps=logging_steps,</span><br><span class="line">            optim=optim,</span><br><span class="line">            evaluation_strategy=<span class="string">&quot;steps&quot;</span> <span class="keyword">if</span> valid_select &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;no&quot;</span>,</span><br><span class="line">            save_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">            eval_steps=eval_steps <span class="keyword">if</span> valid_select &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">            save_steps=save_steps,</span><br><span class="line">            output_dir=output_dir,</span><br><span class="line">            save_total_limit=save_total_limit,</span><br><span class="line">            load_best_model_at_end=<span class="literal">True</span> <span class="keyword">if</span> valid_select &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">False</span>,</span><br><span class="line">            group_by_length=<span class="literal">False</span>,</span><br><span class="line">        ),</span><br><span class="line">        data_collator=transformers.DataCollatorForSeq2Seq(</span><br><span class="line">            tokenizer, pad_to_multiple_of=<span class="number">8</span>, return_tensors=<span class="string">&quot;pt&quot;</span>, padding=<span class="literal">True</span></span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line">    trainer.train()  <span class="comment"># 进行模型训练</span></span><br><span class="line">    model.save_pretrained(output_dir)  <span class="comment"># 保存预训练好的模型</span></span><br><span class="line">    tokenizer.save_pretrained(output_dir)  <span class="comment"># 保存token</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fire.Fire(main)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>文件<code>pre-train.sh</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">dir_path=<span class="string">&quot;../logs/mind/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">&quot;<span class="variable">$dir_path</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$dir_path</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">PYTORCH_ENABLE_MPS_FALLBACK=1 torchrun t5_pre-train.py --item_indexing sequential \</span><br><span class="line">--task sequential,straightforward --dataset mind --epochs 1 --batch_size 1024 \</span><br><span class="line">--backbone t5-small --cutoff 1024 --data_path /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/data \</span><br><span class="line">--valid_prompt seen:0 --model_dir /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/models \</span><br><span class="line">--lr 1e-3 --valid_select 1 --warmup_steps 100 --gradient_accumulation_steps 10 --logging_steps 10 --optim <span class="string">&#x27;adamw_torch&#x27;</span> \</span><br><span class="line">--eval_steps 200 --save_steps 200 --save_total_limit 3</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-3-模型推理与验证">3.3 模型推理与验证</h3>
<p>文件<code>t5_evaluate.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    T5ForConditionalGeneration,</span><br><span class="line">    AutoTokenizer,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&#x27;../&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> EvaluationDataset, evaluation_results, get_metrics_results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">log_dir: <span class="built_in">str</span>, checkpoint_path: <span class="built_in">str</span>, data_path: <span class="built_in">str</span>, item_indexing: <span class="built_in">str</span>, task: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">         dataset: <span class="built_in">str</span>, cutoff: <span class="built_in">int</span>, test_prompt: <span class="built_in">str</span>, eval_batch_size: <span class="built_in">int</span>, metrics: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="comment"># setup</span></span><br><span class="line">    log_file = os.path.join(log_dir, dataset,</span><br><span class="line">                            checkpoint_path.replace(<span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;_&#x27;</span>) + <span class="string">&#x27;.log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> handler <span class="keyword">in</span> logging.root.handlers[:]:</span><br><span class="line">        logging.root.removeHandler(handler)</span><br><span class="line">    logging.basicConfig(filename=log_file, level=logging.INFO,</span><br><span class="line">                        <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)</span><br><span class="line">    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))</span><br><span class="line"></span><br><span class="line">    model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)</span><br><span class="line">    tokenizer.pad_token_id = (</span><br><span class="line">        <span class="number">0</span>  <span class="comment"># unk. we want this to be different from the eos token</span></span><br><span class="line">    )</span><br><span class="line">    tokenizer.padding_side = <span class="string">&quot;left&quot;</span></span><br><span class="line">    <span class="comment"># load test data</span></span><br><span class="line">    test_data_file = os.path.join(data_path, dataset,</span><br><span class="line">                                  <span class="string">f&#x27;<span class="subst">&#123;dataset&#125;</span>_<span class="subst">&#123;task&#125;</span>_<span class="subst">&#123;item_indexing&#125;</span>_test_<span class="subst">&#123;test_prompt&#125;</span>.json&#x27;</span>)</span><br><span class="line">    logging.info(<span class="string">&quot;test_data_file=&quot;</span> + test_data_file)</span><br><span class="line">    test_data = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=test_data_file, field=<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    metrics = <span class="built_in">list</span>(metrics)</span><br><span class="line">    generate_num = <span class="built_in">max</span>([<span class="built_in">int</span>(m.split(<span class="string">&#x27;@&#x27;</span>)[<span class="number">1</span>]) <span class="keyword">for</span> m <span class="keyword">in</span> metrics])</span><br><span class="line">    task_list = np.unique(test_data[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;task&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> task_list:</span><br><span class="line">        logging.info(<span class="string">f&#x27;testing on <span class="subst">&#123;t&#125;</span>&#x27;</span>)</span><br><span class="line">        subset_data = test_data.<span class="built_in">filter</span>(<span class="keyword">lambda</span> example: example[<span class="string">&#x27;task&#x27;</span>] == t)</span><br><span class="line">        dataset = EvaluationDataset(subset_data[<span class="string">&#x27;train&#x27;</span>], tokenizer, cutoff)</span><br><span class="line">        dataloader = DataLoader(dataset, batch_size=eval_batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line">        test_total = <span class="number">0</span></span><br><span class="line">        metrics_res = np.array([<span class="number">0.0</span>] * <span class="built_in">len</span>(metrics))</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            下面是一个batch的案例：</span></span><br><span class="line"><span class="string">                &#123;&#x27;input_ids&#x27;: tensor([[    3, 21419, 12587,  ...,     0,     0,     0],</span></span><br><span class="line"><span class="string">                ...,</span></span><br><span class="line"><span class="string">                [    3, 21419, 12587,  ...,     0,     0,     0]]), </span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">                &#x27;attention_mask&#x27;: tensor([[1, 1, 1,  ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">                ...,</span></span><br><span class="line"><span class="string">                [1, 1, 1,  ..., 0, 0, 0]]), </span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">                &#x27;label&#x27;: tensor([[12587,  2118,   834, 22504,  2577,     1,     0],</span></span><br><span class="line"><span class="string">                [12587,  2118,   834, 19993,  4867,     1,     0],</span></span><br><span class="line"><span class="string">                ...,</span></span><br><span class="line"><span class="string">                [12587,  2118,   834, 19993,  5062,     1,     0]])&#125;</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">            prediction = model.generate(  <span class="comment"># 大模型模型生成函数</span></span><br><span class="line">                input_ids=batch[<span class="string">&quot;input_ids&quot;</span>],  <span class="comment"># torch.LongTensor of shape (batch_size, sequence_length)</span></span><br><span class="line">                attention_mask=batch[<span class="string">&quot;attention_mask&quot;</span>],  <span class="comment"># torch.FloatTensor of shape (batch_size, sequence_length)</span></span><br><span class="line">                max_length=<span class="number">30</span>,</span><br><span class="line">                num_beams=generate_num,</span><br><span class="line">                num_return_sequences=generate_num,</span><br><span class="line">                output_scores=<span class="literal">True</span>,</span><br><span class="line">                return_dict_in_generate=<span class="literal">True</span>,</span><br><span class="line">            )</span><br><span class="line">            output_ids = batch[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">            prediction_ids = prediction[<span class="string">&quot;sequences&quot;</span>]  <span class="comment"># 利用大模型进行预测，输出的向量化的，需要解码</span></span><br><span class="line">            prediction_scores = prediction[<span class="string">&quot;sequences_scores&quot;</span>]</span><br><span class="line">            gold_sents = tokenizer.batch_decode(  <span class="comment"># 用户真实的点击记录</span></span><br><span class="line">                output_ids, skip_special_tokens=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">            generated_sents = tokenizer.batch_decode(  <span class="comment"># 大模型预测的点击记录</span></span><br><span class="line">                prediction_ids, skip_special_tokens=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">            rel_results = evaluation_results(generated_sents, gold_sents, prediction_scores, generate_num)</span><br><span class="line">            test_total += <span class="built_in">len</span>(rel_results)</span><br><span class="line">            metrics_res += get_metrics_results(rel_results, metrics)</span><br><span class="line"></span><br><span class="line">        metrics_res /= test_total</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(metrics)):</span><br><span class="line">            logging.info(<span class="string">f&#x27;<span class="subst">&#123;metrics[i]&#125;</span>: <span class="subst">&#123;metrics_res[i]&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fire.Fire(main)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>执行<code>t5_evaluate.sh</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">python t5_evaluate.py --dataset mind --task sequential,straightforward --item_indexing sequential --backbone t5-small \</span><br><span class="line">--checkpoint_path /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/models/mind/sequential/t5-small/ \</span><br><span class="line"> --test_prompt seen:0 --log_dir <span class="string">&#x27;../logs&#x27;</span> \</span><br><span class="line">--data_path /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/data \</span><br><span class="line">--cutoff 1024 --eval_batch_size 32 --metrics hit@5,hit@10,ndcg@5,ndcg@10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">python t5_evaluate.py --dataset mind --task sequential,straightforward --item_indexing sequential --backbone t5-small \</span><br><span class="line">--checkpoint_path /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/models/mind/sequential/t5-small/ \</span><br><span class="line">--test_prompt unseen:0 --log_dir <span class="string">&#x27;../logs&#x27;</span> \</span><br><span class="line">--data_path /Users/liuqiang/Desktop/code/llm4rec/llm4rec_abc/src/basic_skills/train-llm/data \</span><br><span class="line">--cutoff 1024 --eval_batch_size 32 --metrics hit@5,hit@10,ndcg@5,ndcg@10</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://isSeymour.github.io/butterflyblog">isSeymour</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://isseymour.github.io/butterflyblog/2025/04/26/LLM4Rec_abc_2/">https://isseymour.github.io/butterflyblog/2025/04/26/LLM4Rec_abc_2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://isSeymour.github.io/butterflyblog" target="_blank">isSeymour</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/butterflyblog/tags/LLM/">LLM</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" alt="微信支付"/></a><div class="post-qr-code-desc">微信支付</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/butterflyblog/2025/04/25/LLM4Rec_abc_1/" title="大模型推荐系统（1）生成范式"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/1/llm4rec-abc-1-Page.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">大模型推荐系统（1）生成范式</div></div></a></div><div class="next-post pull-right"><a href="/butterflyblog/2025/04/26/LLM4Rec_abc_3/" title="大模型推荐系统（3）微调范式"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/3/llm4rec-abc-3-Page.webp" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大模型推荐系统（3）微调范式</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/butterflyblog/2025/04/25/LLM4Rec_abc_1/" title="大模型推荐系统（1）生成范式"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/1/llm4rec-abc-1-Page.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-25</div><div class="title">大模型推荐系统（1）生成范式</div></div></a></div><div><a href="/butterflyblog/2025/04/26/LLM4Rec_abc_4/" title="大模型推荐系统（4）直接推荐范式"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/4/llm4rec-abc-4-Page.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-26</div><div class="title">大模型推荐系统（4）直接推荐范式</div></div></a></div><div><a href="/butterflyblog/2025/04/26/LLM4Rec_abc_3/" title="大模型推荐系统（3）微调范式"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/3/llm4rec-abc-3-Page.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-26</div><div class="title">大模型推荐系统（3）微调范式</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">isSeymour</div><div class="author-info__description">志之所趋，无远弗届，穷山距海，不能限也。</div></div><div class="card-info-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">74</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">37</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isSeymour/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://isSeymour.github.io/" target="_blank" title="学术主页"><i class="fa-regular fa-address-card" style="color: #000000;"></i></a><a class="social-icon" href="https://github.com/isSeymour/" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="https://space.bilibili.com/79699613/" target="_blank" title="B站"><i class="fa-brands fa-bilibili" style="color: #000000;"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_63205991/" target="_blank" title="CSDN"><i class="fa-solid fa-code" style="color: #000000;"></i></a><a class="social-icon" href="mailto:seymour0314@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">预训练范式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-text">1、预训练的一般思路与方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E5%87%86%E5%A4%87"><span class="toc-text">1.1 预训练数据的准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-text">1.2 大模型架构的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-text">1.3 大模型预训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="toc-text">1.4 大模型推理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E6%A1%88%E4%BE%8B"><span class="toc-text">2、案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9F%BA%E4%BA%8E-PTUM-%E6%9E%B6%E6%9E%84%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-text">2.1 基于 PTUM 架构的预训练推荐系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%9F%BA%E4%BA%8E-P5-%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-text">2.2 基于 P5 的预训练推荐系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E5%9F%BA%E4%BA%8E-MIND-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98"><span class="toc-text">3、基于 MIND 数据集的代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87"><span class="toc-text">3.1 预训练数据集准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-text">3.2 模型预训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E4%B8%8E%E9%AA%8C%E8%AF%81"><span class="toc-text">3.3 模型推理与验证</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By isSeymour</div><div class="footer_custom_text">欢迎乘坐我的生活地铁！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/butterflyblog/js/utils.js"></script><script src="/butterflyblog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23liAZxomGv7Hapw8g',
      clientSecret: 'f7cafde192c4ada8bef4b76952c422d90575cf8b',
      repo: 'gitalk',
      owner: 'isSeymour',
      admin: ['isSeymour'],
      id: '5f8ce9fdf9ab21df892e3fdf1f550cad',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/butterflyblog/js/search/local-search.js"></script></div></div></body></html>