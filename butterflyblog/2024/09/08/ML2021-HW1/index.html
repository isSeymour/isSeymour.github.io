<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ML2021 - HW 1 | isSeymour</title><meta name="author" content="isSeymour"><meta name="copyright" content="isSeymour"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="HW1: COVID-19 Cases Prediction (Regression)  Platform : Kaggle Sample Code : Google Colab  Objectives:  Solve a regression problem with deep neural network. (DNN) Understand basic DNN training tips. G">
<meta property="og:type" content="article">
<meta property="og:title" content="ML2021 - HW 1">
<meta property="og:url" content="https://isseymour.github.io/butterflyblog/2024/09/08/ML2021-HW1/index.html">
<meta property="og:site_name" content="isSeymour">
<meta property="og:description" content="HW1: COVID-19 Cases Prediction (Regression)  Platform : Kaggle Sample Code : Google Colab  Objectives:  Solve a regression problem with deep neural network. (DNN) Understand basic DNN training tips. G">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/header.png">
<meta property="article:published_time" content="2024-09-07T16:00:00.000Z">
<meta property="article:modified_time" content="2024-09-07T16:00:00.000Z">
<meta property="article:author" content="isSeymour">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/header.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/IC1011.ico"><link rel="canonical" href="https://isseymour.github.io/butterflyblog/2024/09/08/ML2021-HW1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/butterflyblog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/butterflyblog/',
  algolia: undefined,
  localSearch: {"path":"/butterflyblog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ML2021 - HW 1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-08 00:00:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyblog/code/style.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">67</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">34</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/lanqiao/"><i class="fa-fw fa-solid fa-magnet"></i><span> 蓝桥杯2025</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/diary/"><i class="fa-fw fa-solid fa-hashtag"></i><span> 心路</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/major/"><i class="fa-fw fa-solid fa-map"></i><span> 专业课</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/header.png')"><nav id="nav"><span id="blog-info"><a href="/butterflyblog/" title="isSeymour"><span class="site-name">isSeymour</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/lanqiao/"><i class="fa-fw fa-solid fa-magnet"></i><span> 蓝桥杯2025</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/diary/"><i class="fa-fw fa-solid fa-hashtag"></i><span> 心路</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/major/"><i class="fa-fw fa-solid fa-map"></i><span> 专业课</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">ML2021 - HW 1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-07T16:00:00.000Z" title="发表于 2024-09-08 00:00:00">2024-09-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-07T16:00:00.000Z" title="更新于 2024-09-08 00:00:00">2024-09-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/butterflyblog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="ML2021 - HW 1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>HW1: COVID-19 Cases Prediction (Regression)</h1>
<blockquote>
<p>Platform : <a target="_blank" rel="noopener" href="https://www.kaggle.com/c/ml2021spring-hw1">Kaggle</a></p>
<p>Sample Code : <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb">Google Colab</a></p>
</blockquote>
<p>Objectives:</p>
<ul>
<li>Solve a regression problem with deep neural network. (DNN)</li>
<li>Understand basic DNN training tips.</li>
<li>Get familiar with PyTorch.</li>
</ul>
<iframe src="/butterflyblog-src/02-1-overfit-v6.pdf" width="100%" height="500px"></iframe>
<h2 id="0-Prepare">0. Prepare</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="预览数据">预览数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tr_path = <span class="string">&#x27;input/covid.train.csv&#x27;</span></span><br><span class="line">tt_path = <span class="string">&#x27;input/covid.test.csv&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预览数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(tr_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape:&quot;</span>,data.shape)</span><br><span class="line">data.iloc[:,<span class="number">40</span>:].describe()   <span class="comment"># 40 列之后</span></span><br></pre></td></tr></table></figure>
<pre><code>Shape: (2700, 95)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WI</th>
      <th>cli</th>
      <th>ili</th>
      <th>hh_cmnty_cli</th>
      <th>nohh_cmnty_cli</th>
      <th>wearing_mask</th>
      <th>travel_outside_state</th>
      <th>work_outside_home</th>
      <th>shop</th>
      <th>restaurant</th>
      <th>spent_time</th>
      <th>large_event</th>
      <th>public_transit</th>
      <th>anxious</th>
      <th>depressed</th>
      <th>felt_isolated</th>
      <th>worried_become_ill</th>
      <th>worried_finances</th>
      <th>tested_positive</th>
      <th>cli.1</th>
      <th>ili.1</th>
      <th>hh_cmnty_cli.1</th>
      <th>nohh_cmnty_cli.1</th>
      <th>wearing_mask.1</th>
      <th>travel_outside_state.1</th>
      <th>work_outside_home.1</th>
      <th>shop.1</th>
      <th>restaurant.1</th>
      <th>spent_time.1</th>
      <th>large_event.1</th>
      <th>public_transit.1</th>
      <th>anxious.1</th>
      <th>depressed.1</th>
      <th>felt_isolated.1</th>
      <th>worried_become_ill.1</th>
      <th>worried_finances.1</th>
      <th>tested_positive.1</th>
      <th>cli.2</th>
      <th>ili.2</th>
      <th>hh_cmnty_cli.2</th>
      <th>nohh_cmnty_cli.2</th>
      <th>wearing_mask.2</th>
      <th>travel_outside_state.2</th>
      <th>work_outside_home.2</th>
      <th>shop.2</th>
      <th>restaurant.2</th>
      <th>spent_time.2</th>
      <th>large_event.2</th>
      <th>public_transit.2</th>
      <th>anxious.2</th>
      <th>depressed.2</th>
      <th>felt_isolated.2</th>
      <th>worried_become_ill.2</th>
      <th>worried_finances.2</th>
      <th>tested_positive.2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
      <td>2700.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.025185</td>
      <td>0.991587</td>
      <td>1.016136</td>
      <td>29.442496</td>
      <td>24.323054</td>
      <td>89.682322</td>
      <td>8.894498</td>
      <td>31.703307</td>
      <td>55.277153</td>
      <td>16.694342</td>
      <td>36.283177</td>
      <td>10.352273</td>
      <td>2.393285</td>
      <td>18.074684</td>
      <td>13.075498</td>
      <td>19.213321</td>
      <td>64.633769</td>
      <td>44.519474</td>
      <td>16.300893</td>
      <td>0.994568</td>
      <td>1.019135</td>
      <td>29.529305</td>
      <td>24.402875</td>
      <td>89.736737</td>
      <td>8.861371</td>
      <td>31.664651</td>
      <td>55.198075</td>
      <td>16.635440</td>
      <td>36.176886</td>
      <td>10.304595</td>
      <td>2.389372</td>
      <td>18.071667</td>
      <td>13.067127</td>
      <td>19.228457</td>
      <td>64.734139</td>
      <td>44.544124</td>
      <td>16.366695</td>
      <td>0.997986</td>
      <td>1.022472</td>
      <td>29.610807</td>
      <td>24.477913</td>
      <td>89.790227</td>
      <td>8.830759</td>
      <td>31.624272</td>
      <td>55.119903</td>
      <td>16.578290</td>
      <td>36.074941</td>
      <td>10.257474</td>
      <td>2.385735</td>
      <td>18.067635</td>
      <td>13.058828</td>
      <td>19.243283</td>
      <td>64.834307</td>
      <td>44.568440</td>
      <td>16.431280</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.156716</td>
      <td>0.420296</td>
      <td>0.423629</td>
      <td>9.093738</td>
      <td>8.446750</td>
      <td>5.380027</td>
      <td>3.404027</td>
      <td>4.928902</td>
      <td>4.525917</td>
      <td>5.668479</td>
      <td>6.675206</td>
      <td>4.698705</td>
      <td>1.053270</td>
      <td>2.248750</td>
      <td>1.621328</td>
      <td>2.706605</td>
      <td>6.232239</td>
      <td>5.265787</td>
      <td>7.637823</td>
      <td>0.420114</td>
      <td>0.423538</td>
      <td>9.082940</td>
      <td>8.443146</td>
      <td>5.366067</td>
      <td>3.389310</td>
      <td>4.916168</td>
      <td>4.524887</td>
      <td>5.660085</td>
      <td>6.664218</td>
      <td>4.692479</td>
      <td>1.053237</td>
      <td>2.249864</td>
      <td>1.625269</td>
      <td>2.707148</td>
      <td>6.226622</td>
      <td>5.248787</td>
      <td>7.627538</td>
      <td>0.420205</td>
      <td>0.423705</td>
      <td>9.070537</td>
      <td>8.437044</td>
      <td>5.351574</td>
      <td>3.377722</td>
      <td>4.901857</td>
      <td>4.524442</td>
      <td>5.651583</td>
      <td>6.655166</td>
      <td>4.686263</td>
      <td>1.053147</td>
      <td>2.250081</td>
      <td>1.628589</td>
      <td>2.708339</td>
      <td>6.220087</td>
      <td>5.232030</td>
      <td>7.619354</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.126321</td>
      <td>0.132470</td>
      <td>9.961640</td>
      <td>6.857181</td>
      <td>70.950912</td>
      <td>1.252983</td>
      <td>18.311941</td>
      <td>43.220187</td>
      <td>3.637414</td>
      <td>21.485815</td>
      <td>2.118674</td>
      <td>0.728770</td>
      <td>12.980786</td>
      <td>8.370536</td>
      <td>13.400399</td>
      <td>48.225603</td>
      <td>33.113882</td>
      <td>2.338708</td>
      <td>0.126321</td>
      <td>0.132470</td>
      <td>9.961640</td>
      <td>6.857181</td>
      <td>72.330064</td>
      <td>1.252983</td>
      <td>18.311941</td>
      <td>43.220187</td>
      <td>3.637414</td>
      <td>21.485815</td>
      <td>2.118674</td>
      <td>0.728770</td>
      <td>12.980786</td>
      <td>8.370536</td>
      <td>13.400399</td>
      <td>48.225603</td>
      <td>33.113882</td>
      <td>2.338708</td>
      <td>0.126321</td>
      <td>0.132470</td>
      <td>9.961640</td>
      <td>6.857181</td>
      <td>72.356322</td>
      <td>1.252983</td>
      <td>18.311941</td>
      <td>43.220187</td>
      <td>3.637414</td>
      <td>21.485815</td>
      <td>2.118674</td>
      <td>0.728770</td>
      <td>12.980786</td>
      <td>8.370536</td>
      <td>13.400399</td>
      <td>48.225603</td>
      <td>33.113882</td>
      <td>2.338708</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.673929</td>
      <td>0.697515</td>
      <td>23.203165</td>
      <td>18.539153</td>
      <td>86.309537</td>
      <td>6.177754</td>
      <td>28.247865</td>
      <td>51.547206</td>
      <td>13.311050</td>
      <td>30.740931</td>
      <td>6.653427</td>
      <td>1.720601</td>
      <td>16.420485</td>
      <td>11.943953</td>
      <td>17.292063</td>
      <td>59.529326</td>
      <td>40.520369</td>
      <td>10.200722</td>
      <td>0.676205</td>
      <td>0.699773</td>
      <td>23.264324</td>
      <td>18.607342</td>
      <td>86.386111</td>
      <td>6.168986</td>
      <td>28.202745</td>
      <td>51.403036</td>
      <td>13.248788</td>
      <td>30.646955</td>
      <td>6.605724</td>
      <td>1.715372</td>
      <td>16.423140</td>
      <td>11.933745</td>
      <td>17.303887</td>
      <td>59.703583</td>
      <td>40.533768</td>
      <td>10.251453</td>
      <td>0.680065</td>
      <td>0.703390</td>
      <td>23.307794</td>
      <td>18.644297</td>
      <td>86.436468</td>
      <td>6.159286</td>
      <td>28.187875</td>
      <td>51.262363</td>
      <td>13.200532</td>
      <td>30.606711</td>
      <td>6.532543</td>
      <td>1.714080</td>
      <td>16.420485</td>
      <td>11.914167</td>
      <td>17.322912</td>
      <td>59.782876</td>
      <td>40.549987</td>
      <td>10.327314</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.912747</td>
      <td>0.940295</td>
      <td>28.955738</td>
      <td>23.819761</td>
      <td>90.819435</td>
      <td>8.288288</td>
      <td>32.143140</td>
      <td>55.257262</td>
      <td>16.371699</td>
      <td>36.267966</td>
      <td>9.802380</td>
      <td>2.204258</td>
      <td>17.685476</td>
      <td>12.963659</td>
      <td>18.735807</td>
      <td>65.688024</td>
      <td>43.911769</td>
      <td>15.479766</td>
      <td>0.917343</td>
      <td>0.942587</td>
      <td>29.061296</td>
      <td>23.905188</td>
      <td>90.859943</td>
      <td>8.274067</td>
      <td>32.108420</td>
      <td>55.129326</td>
      <td>16.293314</td>
      <td>36.169954</td>
      <td>9.738629</td>
      <td>2.203602</td>
      <td>17.684970</td>
      <td>12.956723</td>
      <td>18.745824</td>
      <td>65.783579</td>
      <td>43.947131</td>
      <td>15.572281</td>
      <td>0.920815</td>
      <td>0.948001</td>
      <td>29.137273</td>
      <td>24.010817</td>
      <td>90.912271</td>
      <td>8.251691</td>
      <td>32.051128</td>
      <td>54.990445</td>
      <td>16.227010</td>
      <td>36.041389</td>
      <td>9.700368</td>
      <td>2.199521</td>
      <td>17.684197</td>
      <td>12.948749</td>
      <td>18.760267</td>
      <td>65.932259</td>
      <td>43.997637</td>
      <td>15.646480</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.000000</td>
      <td>1.266849</td>
      <td>1.302040</td>
      <td>36.109114</td>
      <td>30.238061</td>
      <td>93.937119</td>
      <td>11.582209</td>
      <td>35.387315</td>
      <td>58.866130</td>
      <td>21.396971</td>
      <td>41.659971</td>
      <td>13.734197</td>
      <td>2.745406</td>
      <td>19.501218</td>
      <td>14.214320</td>
      <td>20.665840</td>
      <td>69.497484</td>
      <td>48.098224</td>
      <td>22.503685</td>
      <td>1.268148</td>
      <td>1.301877</td>
      <td>36.233383</td>
      <td>30.318671</td>
      <td>93.955966</td>
      <td>11.525572</td>
      <td>35.362666</td>
      <td>58.797715</td>
      <td>21.333613</td>
      <td>41.562070</td>
      <td>13.684985</td>
      <td>2.734372</td>
      <td>19.503419</td>
      <td>14.214320</td>
      <td>20.693846</td>
      <td>69.578458</td>
      <td>48.108341</td>
      <td>22.527315</td>
      <td>1.269136</td>
      <td>1.304112</td>
      <td>36.345667</td>
      <td>30.459044</td>
      <td>93.975501</td>
      <td>11.477910</td>
      <td>35.299957</td>
      <td>58.752924</td>
      <td>21.207162</td>
      <td>41.508520</td>
      <td>13.602566</td>
      <td>2.730469</td>
      <td>19.503419</td>
      <td>14.214320</td>
      <td>20.713638</td>
      <td>69.719651</td>
      <td>48.118283</td>
      <td>22.535165</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>2.597732</td>
      <td>2.625885</td>
      <td>56.832289</td>
      <td>51.550450</td>
      <td>98.087160</td>
      <td>18.552325</td>
      <td>42.359074</td>
      <td>65.673889</td>
      <td>28.488220</td>
      <td>50.606465</td>
      <td>24.496711</td>
      <td>8.162275</td>
      <td>28.574091</td>
      <td>18.715944</td>
      <td>28.366270</td>
      <td>77.701014</td>
      <td>58.433600</td>
      <td>38.670000</td>
      <td>2.597732</td>
      <td>2.625885</td>
      <td>56.832289</td>
      <td>51.550450</td>
      <td>98.087160</td>
      <td>18.552325</td>
      <td>42.359074</td>
      <td>65.673889</td>
      <td>28.488220</td>
      <td>50.606465</td>
      <td>24.496711</td>
      <td>8.162275</td>
      <td>28.574091</td>
      <td>18.715944</td>
      <td>28.366270</td>
      <td>77.701014</td>
      <td>58.433600</td>
      <td>40.959495</td>
      <td>2.597732</td>
      <td>2.625885</td>
      <td>56.832289</td>
      <td>51.550450</td>
      <td>98.087160</td>
      <td>18.552325</td>
      <td>42.359074</td>
      <td>65.673889</td>
      <td>28.488220</td>
      <td>50.606465</td>
      <td>24.496711</td>
      <td>8.162275</td>
      <td>28.574091</td>
      <td>18.715944</td>
      <td>28.366270</td>
      <td>77.701014</td>
      <td>58.433600</td>
      <td>40.959495</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head(<span class="number">10</span>).iloc[:, <span class="number">40</span>:]</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WI</th>
      <th>cli</th>
      <th>ili</th>
      <th>hh_cmnty_cli</th>
      <th>nohh_cmnty_cli</th>
      <th>wearing_mask</th>
      <th>travel_outside_state</th>
      <th>work_outside_home</th>
      <th>shop</th>
      <th>restaurant</th>
      <th>spent_time</th>
      <th>large_event</th>
      <th>public_transit</th>
      <th>anxious</th>
      <th>depressed</th>
      <th>felt_isolated</th>
      <th>worried_become_ill</th>
      <th>worried_finances</th>
      <th>tested_positive</th>
      <th>cli.1</th>
      <th>ili.1</th>
      <th>hh_cmnty_cli.1</th>
      <th>nohh_cmnty_cli.1</th>
      <th>wearing_mask.1</th>
      <th>travel_outside_state.1</th>
      <th>work_outside_home.1</th>
      <th>shop.1</th>
      <th>restaurant.1</th>
      <th>spent_time.1</th>
      <th>large_event.1</th>
      <th>public_transit.1</th>
      <th>anxious.1</th>
      <th>depressed.1</th>
      <th>felt_isolated.1</th>
      <th>worried_become_ill.1</th>
      <th>worried_finances.1</th>
      <th>tested_positive.1</th>
      <th>cli.2</th>
      <th>ili.2</th>
      <th>hh_cmnty_cli.2</th>
      <th>nohh_cmnty_cli.2</th>
      <th>wearing_mask.2</th>
      <th>travel_outside_state.2</th>
      <th>work_outside_home.2</th>
      <th>shop.2</th>
      <th>restaurant.2</th>
      <th>spent_time.2</th>
      <th>large_event.2</th>
      <th>public_transit.2</th>
      <th>anxious.2</th>
      <th>depressed.2</th>
      <th>felt_isolated.2</th>
      <th>worried_become_ill.2</th>
      <th>worried_finances.2</th>
      <th>tested_positive.2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.814610</td>
      <td>0.771356</td>
      <td>25.648907</td>
      <td>21.242063</td>
      <td>84.644672</td>
      <td>13.462475</td>
      <td>36.519841</td>
      <td>63.139094</td>
      <td>23.835119</td>
      <td>44.726055</td>
      <td>16.946929</td>
      <td>1.716262</td>
      <td>15.494193</td>
      <td>12.043275</td>
      <td>17.000647</td>
      <td>53.439316</td>
      <td>43.279629</td>
      <td>19.586492</td>
      <td>0.838995</td>
      <td>0.807767</td>
      <td>25.679101</td>
      <td>21.280270</td>
      <td>84.005294</td>
      <td>13.467716</td>
      <td>36.637887</td>
      <td>63.318650</td>
      <td>23.688882</td>
      <td>44.385166</td>
      <td>16.463551</td>
      <td>1.664819</td>
      <td>15.299228</td>
      <td>12.051505</td>
      <td>16.552264</td>
      <td>53.256795</td>
      <td>43.622728</td>
      <td>20.151838</td>
      <td>0.897802</td>
      <td>0.887893</td>
      <td>26.060544</td>
      <td>21.503832</td>
      <td>84.438618</td>
      <td>13.038611</td>
      <td>36.429119</td>
      <td>62.434539</td>
      <td>23.812411</td>
      <td>43.430423</td>
      <td>16.151527</td>
      <td>1.602635</td>
      <td>15.409449</td>
      <td>12.088688</td>
      <td>16.702086</td>
      <td>53.991549</td>
      <td>43.604229</td>
      <td>20.704935</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.838995</td>
      <td>0.807767</td>
      <td>25.679101</td>
      <td>21.280270</td>
      <td>84.005294</td>
      <td>13.467716</td>
      <td>36.637887</td>
      <td>63.318650</td>
      <td>23.688882</td>
      <td>44.385166</td>
      <td>16.463551</td>
      <td>1.664819</td>
      <td>15.299228</td>
      <td>12.051505</td>
      <td>16.552264</td>
      <td>53.256795</td>
      <td>43.622728</td>
      <td>20.151838</td>
      <td>0.897802</td>
      <td>0.887893</td>
      <td>26.060544</td>
      <td>21.503832</td>
      <td>84.438618</td>
      <td>13.038611</td>
      <td>36.429119</td>
      <td>62.434539</td>
      <td>23.812411</td>
      <td>43.430423</td>
      <td>16.151527</td>
      <td>1.602635</td>
      <td>15.409449</td>
      <td>12.088688</td>
      <td>16.702086</td>
      <td>53.991549</td>
      <td>43.604229</td>
      <td>20.704935</td>
      <td>0.972842</td>
      <td>0.965496</td>
      <td>25.754087</td>
      <td>21.016210</td>
      <td>84.133873</td>
      <td>12.581952</td>
      <td>36.416557</td>
      <td>62.024517</td>
      <td>23.682974</td>
      <td>43.196313</td>
      <td>16.123386</td>
      <td>1.641863</td>
      <td>15.230063</td>
      <td>11.809047</td>
      <td>16.506973</td>
      <td>54.185521</td>
      <td>42.665766</td>
      <td>21.292911</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.897802</td>
      <td>0.887893</td>
      <td>26.060544</td>
      <td>21.503832</td>
      <td>84.438618</td>
      <td>13.038611</td>
      <td>36.429119</td>
      <td>62.434539</td>
      <td>23.812411</td>
      <td>43.430423</td>
      <td>16.151527</td>
      <td>1.602635</td>
      <td>15.409449</td>
      <td>12.088688</td>
      <td>16.702086</td>
      <td>53.991549</td>
      <td>43.604229</td>
      <td>20.704935</td>
      <td>0.972842</td>
      <td>0.965496</td>
      <td>25.754087</td>
      <td>21.016210</td>
      <td>84.133873</td>
      <td>12.581952</td>
      <td>36.416557</td>
      <td>62.024517</td>
      <td>23.682974</td>
      <td>43.196313</td>
      <td>16.123386</td>
      <td>1.641863</td>
      <td>15.230063</td>
      <td>11.809047</td>
      <td>16.506973</td>
      <td>54.185521</td>
      <td>42.665766</td>
      <td>21.292911</td>
      <td>0.955306</td>
      <td>0.963079</td>
      <td>25.947015</td>
      <td>20.941798</td>
      <td>83.995931</td>
      <td>12.938675</td>
      <td>37.014578</td>
      <td>62.116842</td>
      <td>23.593983</td>
      <td>43.362200</td>
      <td>16.159971</td>
      <td>1.677523</td>
      <td>15.717207</td>
      <td>12.355918</td>
      <td>16.273294</td>
      <td>53.637069</td>
      <td>42.972417</td>
      <td>21.166656</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.972842</td>
      <td>0.965496</td>
      <td>25.754087</td>
      <td>21.016210</td>
      <td>84.133873</td>
      <td>12.581952</td>
      <td>36.416557</td>
      <td>62.024517</td>
      <td>23.682974</td>
      <td>43.196313</td>
      <td>16.123386</td>
      <td>1.641863</td>
      <td>15.230063</td>
      <td>11.809047</td>
      <td>16.506973</td>
      <td>54.185521</td>
      <td>42.665766</td>
      <td>21.292911</td>
      <td>0.955306</td>
      <td>0.963079</td>
      <td>25.947015</td>
      <td>20.941798</td>
      <td>83.995931</td>
      <td>12.938675</td>
      <td>37.014578</td>
      <td>62.116842</td>
      <td>23.593983</td>
      <td>43.362200</td>
      <td>16.159971</td>
      <td>1.677523</td>
      <td>15.717207</td>
      <td>12.355918</td>
      <td>16.273294</td>
      <td>53.637069</td>
      <td>42.972417</td>
      <td>21.166656</td>
      <td>0.947513</td>
      <td>0.968764</td>
      <td>26.350501</td>
      <td>21.109971</td>
      <td>83.819531</td>
      <td>12.452336</td>
      <td>36.270021</td>
      <td>61.294809</td>
      <td>22.576992</td>
      <td>42.954574</td>
      <td>15.544373</td>
      <td>1.578030</td>
      <td>15.295650</td>
      <td>12.218123</td>
      <td>16.045504</td>
      <td>52.446223</td>
      <td>42.907472</td>
      <td>19.896607</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.955306</td>
      <td>0.963079</td>
      <td>25.947015</td>
      <td>20.941798</td>
      <td>83.995931</td>
      <td>12.938675</td>
      <td>37.014578</td>
      <td>62.116842</td>
      <td>23.593983</td>
      <td>43.362200</td>
      <td>16.159971</td>
      <td>1.677523</td>
      <td>15.717207</td>
      <td>12.355918</td>
      <td>16.273294</td>
      <td>53.637069</td>
      <td>42.972417</td>
      <td>21.166656</td>
      <td>0.947513</td>
      <td>0.968764</td>
      <td>26.350501</td>
      <td>21.109971</td>
      <td>83.819531</td>
      <td>12.452336</td>
      <td>36.270021</td>
      <td>61.294809</td>
      <td>22.576992</td>
      <td>42.954574</td>
      <td>15.544373</td>
      <td>1.578030</td>
      <td>15.295650</td>
      <td>12.218123</td>
      <td>16.045504</td>
      <td>52.446223</td>
      <td>42.907472</td>
      <td>19.896607</td>
      <td>0.883833</td>
      <td>0.893020</td>
      <td>26.480624</td>
      <td>21.003982</td>
      <td>84.049437</td>
      <td>12.224644</td>
      <td>35.380198</td>
      <td>60.664482</td>
      <td>22.091433</td>
      <td>43.290957</td>
      <td>15.214655</td>
      <td>1.641667</td>
      <td>14.778802</td>
      <td>12.417256</td>
      <td>16.134238</td>
      <td>52.560315</td>
      <td>43.321985</td>
      <td>20.178428</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0</td>
      <td>0.947513</td>
      <td>0.968764</td>
      <td>26.350501</td>
      <td>21.109971</td>
      <td>83.819531</td>
      <td>12.452336</td>
      <td>36.270021</td>
      <td>61.294809</td>
      <td>22.576992</td>
      <td>42.954574</td>
      <td>15.544373</td>
      <td>1.578030</td>
      <td>15.295650</td>
      <td>12.218123</td>
      <td>16.045504</td>
      <td>52.446223</td>
      <td>42.907472</td>
      <td>19.896607</td>
      <td>0.883833</td>
      <td>0.893020</td>
      <td>26.480624</td>
      <td>21.003982</td>
      <td>84.049437</td>
      <td>12.224644</td>
      <td>35.380198</td>
      <td>60.664482</td>
      <td>22.091433</td>
      <td>43.290957</td>
      <td>15.214655</td>
      <td>1.641667</td>
      <td>14.778802</td>
      <td>12.417256</td>
      <td>16.134238</td>
      <td>52.560315</td>
      <td>43.321985</td>
      <td>20.178428</td>
      <td>0.887642</td>
      <td>0.850387</td>
      <td>26.665874</td>
      <td>20.987079</td>
      <td>84.025937</td>
      <td>12.146718</td>
      <td>35.381223</td>
      <td>60.531769</td>
      <td>21.679396</td>
      <td>43.345340</td>
      <td>15.548976</td>
      <td>1.873230</td>
      <td>15.346263</td>
      <td>12.951090</td>
      <td>16.523990</td>
      <td>52.185260</td>
      <td>43.600100</td>
      <td>18.131814</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.0</td>
      <td>0.883833</td>
      <td>0.893020</td>
      <td>26.480624</td>
      <td>21.003982</td>
      <td>84.049437</td>
      <td>12.224644</td>
      <td>35.380198</td>
      <td>60.664482</td>
      <td>22.091433</td>
      <td>43.290957</td>
      <td>15.214655</td>
      <td>1.641667</td>
      <td>14.778802</td>
      <td>12.417256</td>
      <td>16.134238</td>
      <td>52.560315</td>
      <td>43.321985</td>
      <td>20.178428</td>
      <td>0.887642</td>
      <td>0.850387</td>
      <td>26.665874</td>
      <td>20.987079</td>
      <td>84.025937</td>
      <td>12.146718</td>
      <td>35.381223</td>
      <td>60.531769</td>
      <td>21.679396</td>
      <td>43.345340</td>
      <td>15.548976</td>
      <td>1.873230</td>
      <td>15.346263</td>
      <td>12.951090</td>
      <td>16.523990</td>
      <td>52.185260</td>
      <td>43.600100</td>
      <td>18.131814</td>
      <td>0.826582</td>
      <td>0.792924</td>
      <td>26.840360</td>
      <td>21.262545</td>
      <td>84.188329</td>
      <td>12.203852</td>
      <td>35.348494</td>
      <td>60.334918</td>
      <td>21.970599</td>
      <td>43.632334</td>
      <td>16.179562</td>
      <td>2.077821</td>
      <td>15.249744</td>
      <td>13.111449</td>
      <td>17.261584</td>
      <td>52.544181</td>
      <td>42.750387</td>
      <td>15.517490</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.0</td>
      <td>0.887642</td>
      <td>0.850387</td>
      <td>26.665874</td>
      <td>20.987079</td>
      <td>84.025937</td>
      <td>12.146718</td>
      <td>35.381223</td>
      <td>60.531769</td>
      <td>21.679396</td>
      <td>43.345340</td>
      <td>15.548976</td>
      <td>1.873230</td>
      <td>15.346263</td>
      <td>12.951090</td>
      <td>16.523990</td>
      <td>52.185260</td>
      <td>43.600100</td>
      <td>18.131814</td>
      <td>0.826582</td>
      <td>0.792924</td>
      <td>26.840360</td>
      <td>21.262545</td>
      <td>84.188329</td>
      <td>12.203852</td>
      <td>35.348494</td>
      <td>60.334918</td>
      <td>21.970599</td>
      <td>43.632334</td>
      <td>16.179562</td>
      <td>2.077821</td>
      <td>15.249744</td>
      <td>13.111449</td>
      <td>17.261584</td>
      <td>52.544181</td>
      <td>42.750387</td>
      <td>15.517490</td>
      <td>0.842653</td>
      <td>0.764839</td>
      <td>27.172910</td>
      <td>21.569805</td>
      <td>84.296258</td>
      <td>11.978263</td>
      <td>36.108227</td>
      <td>61.573888</td>
      <td>22.682459</td>
      <td>44.525243</td>
      <td>16.449065</td>
      <td>2.011220</td>
      <td>15.126717</td>
      <td>13.124831</td>
      <td>17.018251</td>
      <td>52.621585</td>
      <td>42.707477</td>
      <td>15.961637</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.0</td>
      <td>0.826582</td>
      <td>0.792924</td>
      <td>26.840360</td>
      <td>21.262545</td>
      <td>84.188329</td>
      <td>12.203852</td>
      <td>35.348494</td>
      <td>60.334918</td>
      <td>21.970599</td>
      <td>43.632334</td>
      <td>16.179562</td>
      <td>2.077821</td>
      <td>15.249744</td>
      <td>13.111449</td>
      <td>17.261584</td>
      <td>52.544181</td>
      <td>42.750387</td>
      <td>15.517490</td>
      <td>0.842653</td>
      <td>0.764839</td>
      <td>27.172910</td>
      <td>21.569805</td>
      <td>84.296258</td>
      <td>11.978263</td>
      <td>36.108227</td>
      <td>61.573888</td>
      <td>22.682459</td>
      <td>44.525243</td>
      <td>16.449065</td>
      <td>2.011220</td>
      <td>15.126717</td>
      <td>13.124831</td>
      <td>17.018251</td>
      <td>52.621585</td>
      <td>42.707477</td>
      <td>15.961637</td>
      <td>0.888932</td>
      <td>0.780920</td>
      <td>26.918955</td>
      <td>21.543915</td>
      <td>83.933997</td>
      <td>11.886287</td>
      <td>35.867644</td>
      <td>62.040243</td>
      <td>23.156434</td>
      <td>44.877576</td>
      <td>16.720348</td>
      <td>1.997892</td>
      <td>15.031244</td>
      <td>12.670960</td>
      <td>16.842015</td>
      <td>52.491832</td>
      <td>43.775117</td>
      <td>13.068527</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>0.842653</td>
      <td>0.764839</td>
      <td>27.172910</td>
      <td>21.569805</td>
      <td>84.296258</td>
      <td>11.978263</td>
      <td>36.108227</td>
      <td>61.573888</td>
      <td>22.682459</td>
      <td>44.525243</td>
      <td>16.449065</td>
      <td>2.011220</td>
      <td>15.126717</td>
      <td>13.124831</td>
      <td>17.018251</td>
      <td>52.621585</td>
      <td>42.707477</td>
      <td>15.961637</td>
      <td>0.888932</td>
      <td>0.780920</td>
      <td>26.918955</td>
      <td>21.543915</td>
      <td>83.933997</td>
      <td>11.886287</td>
      <td>35.867644</td>
      <td>62.040243</td>
      <td>23.156434</td>
      <td>44.877576</td>
      <td>16.720348</td>
      <td>1.997892</td>
      <td>15.031244</td>
      <td>12.670960</td>
      <td>16.842015</td>
      <td>52.491832</td>
      <td>43.775117</td>
      <td>13.068527</td>
      <td>0.841033</td>
      <td>0.738512</td>
      <td>26.354452</td>
      <td>20.937428</td>
      <td>83.400874</td>
      <td>11.592788</td>
      <td>35.926601</td>
      <td>62.091197</td>
      <td>23.661191</td>
      <td>44.603474</td>
      <td>16.671175</td>
      <td>2.022002</td>
      <td>14.535698</td>
      <td>12.270574</td>
      <td>16.915207</td>
      <td>52.402077</td>
      <td>43.534666</td>
      <td>15.178088</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sklearn</span></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> f_regression</span><br><span class="line"></span><br><span class="line">x = data[data.columns[<span class="number">1</span>:<span class="number">94</span>]]</span><br><span class="line">y = data[data.columns[<span class="number">94</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征缩放 归一化 [0, 1]</span></span><br><span class="line">x = (x - x.<span class="built_in">min</span>()) / (x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征选择</span></span><br><span class="line">bestfeatures = SelectKBest(score_func=f_regression)   <span class="comment"># F 统计量作为评分函数</span></span><br><span class="line">fit = bestfeatures.fit(x,y)   <span class="comment"># 对数据进行拟合，计算评分</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评分写为 DataFrame</span></span><br><span class="line">dfscores = pd.DataFrame(fit.scores_)</span><br><span class="line">dfcolumns = pd.DataFrame(x.columns)</span><br><span class="line">featureScores = pd.concat([dfcolumns,dfscores],axis=<span class="number">1</span>)</span><br><span class="line">featureScores.columns = [<span class="string">&#x27;Specs&#x27;</span>,<span class="string">&#x27;Score&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看前 20 的特征</span></span><br><span class="line"><span class="built_in">print</span>(featureScores.nlargest(<span class="number">20</span>,<span class="string">&#x27;Score&#x27;</span>))  </span><br><span class="line"><span class="comment"># 取出前 17 的特征</span></span><br><span class="line">top_rows = featureScores.nlargest(<span class="number">20</span>, <span class="string">&#x27;Score&#x27;</span>).index.tolist()[:<span class="number">17</span>]</span><br><span class="line"><span class="built_in">print</span>(top_rows)</span><br></pre></td></tr></table></figure>
<pre><code>                 Specs          Score
75   tested_positive.1  148069.658278
57     tested_positive   69603.872591
42        hh_cmnty_cli    9235.492094
60      hh_cmnty_cli.1    9209.019558
78      hh_cmnty_cli.2    9097.375172
43      nohh_cmnty_cli    8395.421300
61    nohh_cmnty_cli.1    8343.255927
79    nohh_cmnty_cli.2    8208.176435
40                 cli    6388.906849
58               cli.1    6374.548000
76               cli.2    6250.008702
41                 ili    5998.922880
59               ili.1    5937.588576
77               ili.2    5796.947672
92  worried_finances.2     833.613191
74  worried_finances.1     811.916460
56    worried_finances     788.076931
87    public_transit.2     686.736539
69    public_transit.1     681.562902
51      public_transit     678.834789
[75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77, 92, 74, 56]
</code></pre>
<h3 id="导入包">导入包</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pytorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可重现性</span></span><br><span class="line">my_seed = <span class="number">65472</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">np.random.seed(my_seed)</span><br><span class="line">torch.manual_seed(my_seed)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    torch.cuda.manual_seed_all(my_seed)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_device</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 使用 GPU/CPU &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_learning_curve</span>(<span class="params">loss_record, title=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 绘制训练过程中的 loss  &#x27;&#x27;&#x27;</span></span><br><span class="line">    all_steps = <span class="built_in">len</span>(loss_record[<span class="string">&#x27;train&#x27;</span>])</span><br><span class="line">    dev_steps = <span class="built_in">len</span>(loss_record[<span class="string">&#x27;dev&#x27;</span>])</span><br><span class="line">    x_1 = <span class="built_in">range</span>(all_steps)</span><br><span class="line">    x_2 = x_1[::all_steps // dev_steps]</span><br><span class="line">    plt.figure(figsize=(<span class="number">6</span>,<span class="number">4</span>))</span><br><span class="line">    plt.plot(x_1, loss_record[<span class="string">&#x27;train&#x27;</span>], c=<span class="string">&#x27;tab:red&#x27;</span>, label=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    plt.plot(x_2, loss_record[<span class="string">&#x27;dev&#x27;</span>], c=<span class="string">&#x27;tab:cyan&#x27;</span>, label=<span class="string">&#x27;dev&#x27;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0.0</span>, <span class="number">5.0</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Training steps&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;MSE loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Learning curve of &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(title))</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_pred</span>(<span class="params">dev_set, model, device, lim=<span class="number">35.</span>, preds=<span class="literal">None</span>, targets=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 绘制 DNN 的预测情况 &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> preds <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> targets <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        preds, targets = [], []</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> dev_set:</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                pred = model(x)</span><br><span class="line">                preds.append(pred.detach().cpu())</span><br><span class="line">                targets.append(y.detach().cpu())</span><br><span class="line">        preds = torch.cat(preds, dim=<span class="number">0</span>).numpy()</span><br><span class="line">        targets = torch.cat(targets, dim=<span class="number">0</span>).numpy()</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">    plt.scatter(targets, preds, c=<span class="string">&#x27;r&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.plot([-<span class="number">0.2</span>, lim], [-<span class="number">0.2</span>, lim], c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    plt.xlim(-<span class="number">0.2</span>, lim)</span><br><span class="line">    plt.ylim(-<span class="number">0.2</span>, lim)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;ground truth value&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;predicted value&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Ground Truth v.s. Prediction&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="1-Dataset">1. Dataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">COVID19Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载和预处理 </span></span><br><span class="line"><span class="string">    (path, mode=,target_only=)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 path,</span></span><br><span class="line"><span class="params">                 mode=<span class="string">&#x27;train&#x27;</span>,</span></span><br><span class="line"><span class="params">                 target_only=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># 模式</span></span><br><span class="line">        self.mode = mode</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 读取数据</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            data = <span class="built_in">list</span>(csv.reader(fp))</span><br><span class="line">            data = np.array(data[<span class="number">1</span>:])[:, <span class="number">1</span>:].astype(<span class="built_in">float</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征工程</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> target_only:</span><br><span class="line">            features = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">93</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># TODO</span></span><br><span class="line">            features = [<span class="number">75</span>, <span class="number">57</span>, <span class="number">42</span>, <span class="number">60</span>, <span class="number">78</span>, <span class="number">43</span>, <span class="number">61</span>, <span class="number">79</span>, <span class="number">40</span>, <span class="number">58</span>, <span class="number">76</span>, <span class="number">41</span>, <span class="number">59</span>, <span class="number">77</span>, <span class="number">92</span>, <span class="number">74</span>, <span class="number">56</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 数据准备 x y</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            data = data[:, features]</span><br><span class="line">            self.data = torch.FloatTensor(data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target = data[:, -<span class="number">1</span>]</span><br><span class="line">            data = data[:, features]</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)) <span class="keyword">if</span> i%<span class="number">10</span> != <span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;dev&#x27;</span>:</span><br><span class="line">                indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)) <span class="keyword">if</span> i%<span class="number">10</span> == <span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            self.target = torch.FloatTensor(target[indices])</span><br><span class="line">            self.data = torch.FloatTensor(data[indices])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 标准化 Normalize</span></span><br><span class="line">        self.data[:, <span class="number">40</span>:] = \</span><br><span class="line">            (self.data[:, <span class="number">40</span>:] - self.data[:, <span class="number">40</span>:].mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)) \</span><br><span class="line">            / (self.data[:, <span class="number">40</span>:].std(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征维度</span></span><br><span class="line">        self.dim = self.data.shape[<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Finished reading the &#123;&#125; set of COVID19 Dataset (&#123;&#125; samples found, each dim = &#123;&#125;)&#x27;</span></span><br><span class="line">             .<span class="built_in">format</span>(mode, <span class="built_in">len</span>(self.data), self.dim))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># 获取一个样本数据</span></span><br><span class="line">        <span class="keyword">if</span> self.mode <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> self.data[index], self.target[index]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.data[index]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 长度</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure>
<h2 id="2-DataLoader">2. DataLoader</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prep_dataloader</span>(<span class="params">path, mode, batch_size, n_jobs=<span class="number">0</span>, target_only=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 读取数据集，并放入数据加载器 &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = COVID19Dataset(path, mode, target_only)</span><br><span class="line">    dataloader = DataLoader(dataset, batch_size, num_workers=n_jobs,</span><br><span class="line">                           shuffle=(mode==<span class="string">&#x27;train&#x27;</span>), pin_memory=<span class="literal">True</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> dataloader</span><br></pre></td></tr></table></figure>
<h2 id="3-Deep-Neural-Network">3. Deep Neural Network</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    一个简单的全连接 DNN </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化  input_dim 输入维度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 父类初始化</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 网络序列</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, <span class="number">16</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">16</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 损失函数</span></span><br><span class="line">        self.criterion = nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 前向传播 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x).squeeze(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_loss</span>(<span class="params">self, pred, target</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 计算损失 &#x27;&#x27;&#x27;</span></span><br><span class="line">        regularization_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            regularization_loss += torch.<span class="built_in">sum</span>(param ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> self.criterion(pred, target) + <span class="number">0.00075</span> * regularization_loss</span><br><span class="line"><span class="comment">#         return self.criterion(pred, target)</span></span><br></pre></td></tr></table></figure>
<h2 id="4-Train-Validation-Test">4. Train, Validation, Test</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dev</span>(<span class="params">dv_set, model, device</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 计算验证集上的loss &#x27;&#x27;&#x27;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> dv_set:</span><br><span class="line">        x, y = x.to(device), y.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            pred = model(x)</span><br><span class="line">            mse_loss = model.cal_loss(pred, y)</span><br><span class="line">        <span class="comment"># 本批次损失（每次是按批次取的，因此要乘以本批次的数量）</span></span><br><span class="line">        total_loss += mse_loss.detach().cpu().item() * <span class="built_in">len</span>(x)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 最后总的算平均</span></span><br><span class="line">    total_loss /= <span class="built_in">len</span>(dv_set.dataset)</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">tr_set, dv_set, model, config, device</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 训练模型 &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 定义优化器</span></span><br><span class="line">    optimizer = <span class="built_in">getattr</span>(torch.optim, config[<span class="string">&#x27;optimizer&#x27;</span>])\</span><br><span class="line">                    (model.parameters(), **config[<span class="string">&#x27;optim_hparas&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练过程</span></span><br><span class="line">    n_epochs = config[<span class="string">&#x27;n_epochs&#x27;</span>]</span><br><span class="line">    epoch = <span class="number">0</span></span><br><span class="line">    early_stop_cnt = <span class="number">0</span></span><br><span class="line">    min_loss = <span class="number">1000.0</span></span><br><span class="line">    loss_record = &#123;<span class="string">&#x27;train&#x27;</span>:[], <span class="string">&#x27;dev&#x27;</span>:[]&#125;</span><br><span class="line">    <span class="keyword">while</span> epoch &lt; n_epochs:</span><br><span class="line">        <span class="comment"># 一轮训练</span></span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> tr_set:</span><br><span class="line">            optimizer.zero_grad()              <span class="comment"># 清除参数</span></span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)                    <span class="comment"># 前向传递</span></span><br><span class="line">            loss = model.cal_loss(pred, y)     <span class="comment"># 计算损失</span></span><br><span class="line">            loss.backward()                    <span class="comment"># 反向传播</span></span><br><span class="line">            optimizer.step()                   <span class="comment"># 参数优化</span></span><br><span class="line">            loss_record[<span class="string">&#x27;train&#x27;</span>].append(loss.detach().cpu().item())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 一轮训练后进行一次验证效果</span></span><br><span class="line">        dev_loss = dev(dv_set, model, device)</span><br><span class="line">        loss_record[<span class="string">&#x27;dev&#x27;</span>].append(dev_loss)</span><br><span class="line">        <span class="keyword">if</span> dev_loss &lt; min_loss:                 <span class="comment"># 效果更好则保存模型</span></span><br><span class="line">            min_loss = dev_loss</span><br><span class="line">            torch.save(model.state_dict(), config[<span class="string">&#x27;save_path&#x27;</span>])</span><br><span class="line">            early_stop_cnt = <span class="number">0</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Saving model (epoch = &#123;:4d&#125;, loss = &#123;:4f&#125;)&#x27;</span>.<span class="built_in">format</span>(epoch, dev_loss))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            early_stop_cnt += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 轮数播报</span></span><br><span class="line">        epoch +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125; finished.&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 持续无效则提前终止</span></span><br><span class="line">        <span class="keyword">if</span> early_stop_cnt &gt; config[<span class="string">&#x27;early_stop&#x27;</span>]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 汇报</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished training after &#123;&#125; epochs, min_loss = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, min_loss))</span><br><span class="line">    <span class="keyword">return</span> min_loss, loss_record</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">tt_set, model, device</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 预测结果（测试集） &#x27;&#x27;&#x27;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    preds = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> tt_set:</span><br><span class="line">        x = x.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            pred = model(x)</span><br><span class="line">            preds.append(pred.detach().cpu())</span><br><span class="line">    preds = torch.cat(preds, dim=<span class="number">0</span>).numpy()</span><br><span class="line">    <span class="keyword">return</span> preds</span><br></pre></td></tr></table></figure>
<h2 id="5-Setup-Hyper-parameters">5. Setup Hyper-parameters</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">device = get_device()</span><br><span class="line">os.makedirs(<span class="string">&#x27;models&#x27;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">target_only = <span class="literal">True</span>                   <span class="comment"># TODO</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&#x27;n_epochs&#x27;</span>: <span class="number">10000</span>,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: <span class="string">&#x27;Adam&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;optim_hparas&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0005</span>,</span><br><span class="line"><span class="comment">#         &#x27;momentum&#x27;: 0.9</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;early_stop&#x27;</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="string">&#x27;save_path&#x27;</span>: <span class="string">&#x27;models/model.pth&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="6-Load-Data-and-Model">6. Load Data and Model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">tr_set = prep_dataloader(tr_path, <span class="string">&#x27;train&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only)</span><br><span class="line">dv_set = prep_dataloader(tr_path, <span class="string">&#x27;dev&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only)</span><br><span class="line">tt_set = prep_dataloader(tt_path, <span class="string">&#x27;test&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only)</span><br></pre></td></tr></table></figure>
<pre><code>Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 17)
Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 17)
Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 17)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">model = NeuralNet(tr_set.dataset.dim).to(device)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)</span><br></pre></td></tr></table></figure>
<pre><code>Saving model (epoch =    0, loss = 340.917373)
Saving model (epoch =    1, loss = 322.165056)
Saving model (epoch =    2, loss = 313.825131)
Saving model (epoch =    3, loss = 309.852996)
Saving model (epoch =    4, loss = 306.339627)
Saving model (epoch =    5, loss = 306.296543)
Saving model (epoch =    6, loss = 305.443566)
Saving model (epoch =    7, loss = 300.847960)
Saving model (epoch =    8, loss = 289.878357)
Saving model (epoch =    9, loss = 283.428931)
Saving model (epoch =   11, loss = 277.324653)
Saving model (epoch =   19, loss = 275.598712)
Saving model (epoch =   20, loss = 274.431580)
Saving model (epoch =   21, loss = 271.097685)
Saving model (epoch =   22, loss = 266.430409)
Saving model (epoch =   23, loss = 261.281929)
Saving model (epoch =   24, loss = 260.683929)
Saving model (epoch =   25, loss = 258.624722)
Saving model (epoch =   26, loss = 253.948218)
Saving model (epoch =   27, loss = 247.472347)
Saving model (epoch =   29, loss = 240.454434)
Saving model (epoch =   31, loss = 237.730461)
Saving model (epoch =   32, loss = 233.930249)
Saving model (epoch =   33, loss = 228.276315)
Saving model (epoch =   34, loss = 224.006245)
Saving model (epoch =   35, loss = 219.322504)
Saving model (epoch =   36, loss = 207.611922)
Saving model (epoch =   37, loss = 200.482134)
Saving model (epoch =   38, loss = 196.714348)
Saving model (epoch =   41, loss = 192.946156)
Saving model (epoch =   42, loss = 187.776669)
Saving model (epoch =   43, loss = 187.133918)
Saving model (epoch =   44, loss = 186.150606)
Saving model (epoch =   45, loss = 183.542729)
Saving model (epoch =   46, loss = 177.969274)
Saving model (epoch =   47, loss = 165.223580)
Saving model (epoch =   48, loss = 161.321226)
Saving model (epoch =   49, loss = 155.550834)
Saving model (epoch =   53, loss = 149.358119)
Saving model (epoch =   54, loss = 142.696106)
Saving model (epoch =   55, loss = 139.488191)
Saving model (epoch =   56, loss = 137.709078)
Saving model (epoch =   57, loss = 132.763100)
Saving model (epoch =   60, loss = 123.616633)
Saving model (epoch =   61, loss = 121.146074)
Saving model (epoch =   64, loss = 112.364984)
Saving model (epoch =   65, loss = 100.750797)
Saving model (epoch =   72, loss = 92.428780)
Saving model (epoch =   75, loss = 78.373004)
Saving model (epoch =   80, loss = 68.048881)
Saving model (epoch =   82, loss = 53.388715)
Saving model (epoch =   85, loss = 42.509547)
Saving model (epoch =   94, loss = 39.354231)
Saving model (epoch =   98, loss = 26.928447)
Epoch 100 finished.
Saving model (epoch =  101, loss = 22.667163)
Saving model (epoch =  106, loss = 9.036212)
Saving model (epoch =  113, loss = 7.133554)
Saving model (epoch =  141, loss = 5.964343)
Saving model (epoch =  160, loss = 5.780281)
Saving model (epoch =  184, loss = 5.398957)
Epoch 200 finished.
Saving model (epoch =  203, loss = 4.893500)
Saving model (epoch =  216, loss = 4.655919)
Saving model (epoch =  218, loss = 4.601365)
Saving model (epoch =  227, loss = 4.375972)
Saving model (epoch =  233, loss = 4.232011)
Saving model (epoch =  238, loss = 4.214206)
Saving model (epoch =  245, loss = 3.868370)
Saving model (epoch =  261, loss = 3.665027)
Saving model (epoch =  266, loss = 3.496048)
Saving model (epoch =  276, loss = 3.405258)
Saving model (epoch =  282, loss = 3.251506)
Saving model (epoch =  284, loss = 3.161817)
Epoch 300 finished.
Saving model (epoch =  301, loss = 3.101231)
Saving model (epoch =  306, loss = 2.750548)
Saving model (epoch =  307, loss = 2.730497)
Saving model (epoch =  318, loss = 2.705987)
Saving model (epoch =  321, loss = 2.625461)
Saving model (epoch =  326, loss = 2.563876)
Saving model (epoch =  342, loss = 2.365493)
Saving model (epoch =  343, loss = 2.225936)
Saving model (epoch =  348, loss = 2.199931)
Saving model (epoch =  359, loss = 2.137739)
Saving model (epoch =  360, loss = 2.051806)
Saving model (epoch =  362, loss = 1.994729)
Saving model (epoch =  364, loss = 1.951313)
Saving model (epoch =  370, loss = 1.903423)
Saving model (epoch =  372, loss = 1.817203)
Saving model (epoch =  386, loss = 1.771863)
Saving model (epoch =  394, loss = 1.617613)
Epoch 400 finished.
Saving model (epoch =  411, loss = 1.475305)
Saving model (epoch =  414, loss = 1.455347)
Saving model (epoch =  415, loss = 1.413618)
Saving model (epoch =  421, loss = 1.404032)
Saving model (epoch =  425, loss = 1.342632)
Saving model (epoch =  433, loss = 1.317732)
Saving model (epoch =  440, loss = 1.289960)
Saving model (epoch =  450, loss = 1.251974)
Saving model (epoch =  451, loss = 1.186455)
Saving model (epoch =  465, loss = 1.124176)
Saving model (epoch =  480, loss = 1.115070)
Saving model (epoch =  482, loss = 1.063177)
Saving model (epoch =  495, loss = 1.020159)
Epoch 500 finished.
Saving model (epoch =  505, loss = 0.998222)
Saving model (epoch =  525, loss = 0.996696)
Saving model (epoch =  527, loss = 0.974490)
Saving model (epoch =  528, loss = 0.946199)
Saving model (epoch =  548, loss = 0.934515)
Saving model (epoch =  549, loss = 0.930782)
Saving model (epoch =  552, loss = 0.918216)
Saving model (epoch =  562, loss = 0.888980)
Saving model (epoch =  586, loss = 0.885096)
Epoch 600 finished.
Saving model (epoch =  605, loss = 0.879943)
Saving model (epoch =  619, loss = 0.876455)
Saving model (epoch =  652, loss = 0.871618)
Saving model (epoch =  657, loss = 0.862073)
Saving model (epoch =  664, loss = 0.855746)
Epoch 700 finished.
Saving model (epoch =  736, loss = 0.848672)
Epoch 800 finished.
Saving model (epoch =  838, loss = 0.833972)
Epoch 900 finished.
Epoch 1000 finished.
Epoch 1100 finished.
Epoch 1200 finished.
Epoch 1300 finished.
Epoch 1400 finished.
Epoch 1500 finished.
Epoch 1600 finished.
Epoch 1700 finished.
Epoch 1800 finished.
Finished training after 1840 epochs, min_loss = 0.833972383428503
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制训练过程中 loss 的情况</span></span><br><span class="line">plot_learning_curve(model_loss_record, <span class="string">&#x27;deep model&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/output_26_0.png" alt="png"><br>
​</p>
<h2 id="7-Predict">7. Predict</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> model</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新实例化模型，把参数加载进来</span></span><br><span class="line">model = NeuralNet(tr_set.dataset.dim).to(device)</span><br><span class="line">ckpt = torch.load(config[<span class="string">&#x27;save_path&#x27;</span>], map_location=<span class="string">&#x27;cpu&#x27;</span>, weights_only=<span class="literal">True</span>)</span><br><span class="line">model.load_state_dict(ckpt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">plot_pred(dv_set, model, device)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/output_29_0.png" alt="png"><br>
​</p>
<h2 id="8-Save-result-to-file">8. Save result to file</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_pred</span>(<span class="params">preds, file</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 保存预测结果到csv文件 &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        writer = csv.writer(fp)</span><br><span class="line">        writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;tested_positive&#x27;</span>])</span><br><span class="line">        <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(preds):</span><br><span class="line">            writer.writerow([i, p])</span><br><span class="line"></span><br><span class="line">preds = test(tt_set, model, device)</span><br><span class="line">save_pred(preds, <span class="string">&#x27;preds.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Score">Score</h3>
<ul>
<li>Public: 0.89359</li>
<li>Private: 0.90019</li>
</ul>
<h2 id="9-Hints">*9. Hints</h2>
<h3 id="Simple-baseline">Simple baseline</h3>
<ul>
<li>Run sample code</li>
</ul>
<h3 id="Medium-baseline">Medium baseline</h3>
<ul>
<li>Feature selection: 40 states + 2 tested_positive</li>
</ul>
<h3 id="Strong-baseline">Strong baseline</h3>
<ul>
<li>Feature selection</li>
<li>DNN architecture ( layers , dimension, activation function )</li>
<li>Training ( mini-batch, optimizer, learning rate )</li>
<li>L2 regularization</li>
<li>There are some mistakes in code.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://isSeymour.github.io/butterflyblog">isSeymour</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://isseymour.github.io/butterflyblog/2024/09/08/ML2021-HW1/">https://isseymour.github.io/butterflyblog/2024/09/08/ML2021-HW1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://isSeymour.github.io/butterflyblog" target="_blank">isSeymour</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/butterflyblog/tags/ML/">ML</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/header.png" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" alt="微信支付"/></a><div class="post-qr-code-desc">微信支付</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/butterflyblog/2024/09/01/INTRO-to-DL/" title="INTRO to DL - Kaggle 官方课程"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/Kaggle/INTRO-DL/intro-to-deep-learning.svg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">INTRO to DL - Kaggle 官方课程</div></div></a></div><div class="next-post pull-right"><a href="/butterflyblog/2024/09/11/ML2021-HW2/" title="ML2021 - HW 2"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW2/header.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ML2021 - HW 2</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/butterflyblog/2024/08/29/INTRO-to-ML/" title="INTRO to ML - Kaggle 官方课程"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/Kaggle/intro-to-machine-learning.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-29</div><div class="title">INTRO to ML - Kaggle 官方课程</div></div></a></div><div><a href="/butterflyblog/2024/08/31/Intermediate-ML/" title="Intermediate ML - Kaggle 官方课程"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/Kaggle/intermediate-machine-learning.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-31</div><div class="title">Intermediate ML - Kaggle 官方课程</div></div></a></div><div><a href="/butterflyblog/2024/09/01/Data-Visualization/" title="Data Visualization - Kaggle 官方课程"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/Kaggle/Data-Visualization/data-visualization.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-01</div><div class="title">Data Visualization - Kaggle 官方课程</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">isSeymour</div><div class="author-info__description">志之所趋，无远弗届，穷山距海，不能限也。</div></div><div class="card-info-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">67</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">34</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isSeymour/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://isSeymour.github.io/profile/" target="_blank" title="学术主页"><i class="fa-regular fa-address-card" style="color: #000000;"></i></a><a class="social-icon" href="https://github.com/isSeymour/" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="https://space.bilibili.com/79699613/" target="_blank" title="B站"><i class="fa-brands fa-bilibili" style="color: #000000;"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_63205991/" target="_blank" title="CSDN"><i class="fa-solid fa-code" style="color: #000000;"></i></a><a class="social-icon" href="mailto:isSeymour@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">HW1: COVID-19 Cases Prediction (Regression)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-Prepare"><span class="toc-text">0. Prepare</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%A7%88%E6%95%B0%E6%8D%AE"><span class="toc-text">预览数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%8C%85"><span class="toc-text">导入包</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Dataset"><span class="toc-text">1. Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-DataLoader"><span class="toc-text">2. DataLoader</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Deep-Neural-Network"><span class="toc-text">3. Deep Neural Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Train-Validation-Test"><span class="toc-text">4. Train, Validation, Test</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Setup-Hyper-parameters"><span class="toc-text">5. Setup Hyper-parameters</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Load-Data-and-Model"><span class="toc-text">6. Load Data and Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Predict"><span class="toc-text">7. Predict</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-Save-result-to-file"><span class="toc-text">8. Save result to file</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Score"><span class="toc-text">Score</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Hints"><span class="toc-text">*9. Hints</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Simple-baseline"><span class="toc-text">Simple baseline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Medium-baseline"><span class="toc-text">Medium baseline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Strong-baseline"><span class="toc-text">Strong baseline</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2024/10/14/CS224W_Colab_2/" title="CS224W - Colab 2"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/GCN/shared-parameters.png" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="CS224W - Colab 2"/></a><div class="content"><a class="title" href="/butterflyblog/2024/10/14/CS224W_Colab_2/" title="CS224W - Colab 2">CS224W - Colab 2</a><time datetime="2024-10-14T14:00:00.000Z" title="发表于 2024-10-14 22:00:00">2024-10-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2024/10/14/GCN/" title="GCN 图卷积神经网络"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/GCN/DeepGraphEncoders.png" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="GCN 图卷积神经网络"/></a><div class="content"><a class="title" href="/butterflyblog/2024/10/14/GCN/" title="GCN 图卷积神经网络">GCN 图卷积神经网络</a><time datetime="2024-10-14T09:00:00.000Z" title="发表于 2024-10-14 17:00:00">2024-10-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2024/10/12/Graph-PageRank/" title="PageRank:《哈利·波特》人物节点重要度"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/PageRank/Algorithm.png" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="PageRank:《哈利·波特》人物节点重要度"/></a><div class="content"><a class="title" href="/butterflyblog/2024/10/12/Graph-PageRank/" title="PageRank:《哈利·波特》人物节点重要度">PageRank:《哈利·波特》人物节点重要度</a><time datetime="2024-10-12T14:00:00.000Z" title="发表于 2024-10-12 22:00:00">2024-10-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/ML2021/HW1/header.png')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By isSeymour</div><div class="footer_custom_text">欢迎乘坐我的生活地铁！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/butterflyblog/js/utils.js"></script><script src="/butterflyblog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23liAZxomGv7Hapw8g',
      clientSecret: 'f7cafde192c4ada8bef4b76952c422d90575cf8b',
      repo: 'gitalk',
      owner: 'isSeymour',
      admin: ['isSeymour'],
      id: '6edf2e0846ae4233e2fc9f8271759cc4',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/butterflyblog/js/search/local-search.js"></script></div></div></body></html>