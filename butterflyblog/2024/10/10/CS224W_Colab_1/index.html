<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CS224W - Colab 1 | isSeymour</title><meta name="author" content="isSeymour"><meta name="copyright" content="isSeymour"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CS224W - Colab 1 In this Colab, we will write a full pipeline for learning node embeddings. We will go through the following 3 steps. To start, we will load a classic graph in network science, the Kar">
<meta property="og:type" content="article">
<meta property="og:title" content="CS224W - Colab 1">
<meta property="og:url" content="https://isseymour.github.io/butterflyblog/2024/10/10/CS224W_Colab_1/index.html">
<meta property="og:site_name" content="isSeymour">
<meta property="og:description" content="CS224W - Colab 1 In this Colab, we will write a full pipeline for learning node embeddings. We will go through the following 3 steps. To start, we will load a classic graph in network science, the Kar">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png">
<meta property="article:published_time" content="2024-10-10T14:00:00.000Z">
<meta property="article:modified_time" content="2024-10-10T14:00:00.000Z">
<meta property="article:author" content="isSeymour">
<meta property="article:tag" content="GNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/IC1011.ico"><link rel="canonical" href="https://isseymour.github.io/butterflyblog/2024/10/10/CS224W_Colab_1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/butterflyblog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/butterflyblog/',
  algolia: undefined,
  localSearch: {"path":"/butterflyblog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CS224W - Colab 1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-10 22:00:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/butterflyblog/code/style.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">71</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">35</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/lanqiao/"><i class="fa-fw fa-solid fa-magnet"></i><span> 蓝桥杯2025</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/diary/"><i class="fa-fw fa-solid fa-hashtag"></i><span> 心路</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/major/"><i class="fa-fw fa-solid fa-map"></i><span> 专业课</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png')"><nav id="nav"><span id="blog-info"><a href="/butterflyblog/" title="isSeymour"><span class="site-name">isSeymour</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 总览</span></a></li><li><a class="site-page child" href="/butterflyblog/tags/"><i class="fa-fw fa-sharp fa-solid fa-hashtag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/butterflyblog/categories/"><i class="fa-fw fa-sharp fa-solid fa-folder"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-sharp fa-solid fa-list"></i><span> 功能</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/ctf/"><i class="fa-fw fa-solid fa-shield-halved"></i><span> CTF</span></a></li><li><a class="site-page child" href="/butterflyblog/music/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/butterflyblog/tools/"><i class="fa-fw fa-solid fa-screwdriver-wrench"></i><span> 下载</span></a></li><li><a class="site-page child" href="/butterflyblog/link/"><i class="fa-fw fa-solid fa-paper-plane"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-university"></i><span> 算法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/algorithm/hot100/"><i class="fa-fw fa-solid fa-fire"></i><span> HOT100</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/template/"><i class="fa-fw fa-solid fa-code"></i><span> Template</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/labuladong/"><i class="fa-fw fa-solid fa-coffee"></i><span> labuladong</span></a></li><li><a class="site-page child" href="/butterflyblog/algorithm/lanqiao/"><i class="fa-fw fa-solid fa-magnet"></i><span> 蓝桥杯2025</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-plane"></i><span> 旅途</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/journey/diary/"><i class="fa-fw fa-solid fa-hashtag"></i><span> 心路</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/english/"><i class="fa-fw fa-solid fa-globe"></i><span> 英语</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/major/"><i class="fa-fw fa-solid fa-map"></i><span> 专业课</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/mathAI/"><i class="fa-fw fa-solid fa-bar-chart"></i><span> 数学&amp;AI</span></a></li><li><a class="site-page child" href="/butterflyblog/journey/RecSys/"><i class="fa-fw fa-solid fa-thumbs-up"></i><span> RecSys</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-user"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/butterflyblog/about/"><i class="fa-fw fa-regular fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/butterflyblog/message/"><i class="fa-fw fa-solid fa-message"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/butterflyblog/develop/"><i class="fa-fw fa-brands fa-windows"></i><span> 开发日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CS224W - Colab 1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-10-10T14:00:00.000Z" title="发表于 2024-10-10 22:00:00">2024-10-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-10T14:00:00.000Z" title="更新于 2024-10-10 22:00:00">2024-10-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/butterflyblog/categories/CS224W/">CS224W</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CS224W - Colab 1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1><strong>CS224W - Colab 1</strong></h1>
<p>In this Colab, we will write a full pipeline for <strong>learning node embeddings</strong>.<br>
We will go through the following 3 steps.</p>
<p>To start, we will load a classic graph in network science, the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Zachary%27s_karate_club">Karate Club Network</a>. We will explore multiple graph statistics for that graph.</p>
<p>We will then work together to transform the graph structure into a PyTorch tensor, so that we can perform machine learning over the graph.</p>
<p>Finally, we will finish the first learning algorithm on graphs: a node embedding model. For simplicity, our model here is simpler than DeepWalk / node2vec algorithms taught in the lecture. But it’s still rewarding and challenging, as we will write it from scratch via PyTorch.</p>
<p>Now let’s get started! This Colab should take 1-2 hours to complete.</p>
<p><strong>Note</strong>: Make sure to <strong>restart and run all</strong> before submission, so that the intermediate variables / packages will carry over to the next cell</p>
<h1>1 Graph Basics</h1>
<p>To start, we will load a classic graph in network science, the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Zachary%27s_karate_club">Karate Club Network</a>. We will explore multiple graph statistics for that graph.</p>
<h2 id="Setup">Setup</h2>
<p>We will heavily use NetworkX in this Colab.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br></pre></td></tr></table></figure>
<h2 id="Zachary’s-karate-club-network">Zachary’s karate club network</h2>
<p>The <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Zachary%27s_karate_club">Karate Club Network</a> is a graph which describes a social network of 34 members of a karate club and documents links between members who interacted outside the club.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">G = nx.karate_club_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># G is an undirected graph</span></span><br><span class="line"><span class="built_in">type</span>(G)</span><br></pre></td></tr></table></figure>
<pre><code>networkx.classes.graph.Graph
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize the graph</span></span><br><span class="line">nx.draw(G, with_labels = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_7_0.png" alt="png"><br>
​</p>
<h2 id="Question-1-What-is-the-average-degree-of-the-karate-club-network-5-Points">Question 1: What is the average degree of the karate club network? (5 Points)</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">average_degree</span>(<span class="params">num_edges, num_nodes</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;平均度&#x27;&#x27;&#x27;</span></span><br><span class="line">    avg_degree = <span class="built_in">round</span>(<span class="number">2</span> * num_edges / num_nodes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> avg_degree</span><br><span class="line"></span><br><span class="line">num_edges = G.number_of_edges()</span><br><span class="line">num_nodes = G.number_of_nodes()</span><br><span class="line">avg_degree = average_degree(num_edges, num_nodes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average degree of karate club network is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(avg_degree))</span><br></pre></td></tr></table></figure>
<pre><code>Average degree of karate club network is 5
</code></pre>
<h2 id="Question-2-What-is-the-average-clustering-coefficient-of-the-karate-club-network-5-Points">Question 2: What is the average clustering coefficient of the karate club network? (5 Points)</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">average_clustering_coefficient</span>(<span class="params">G</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;平均聚类系数&#x27;&#x27;&#x27;</span></span><br><span class="line">    avg_cluster_coef = nx.average_clustering(G)</span><br><span class="line">    avg_cluster_coef = <span class="built_in">round</span>(avg_cluster_coef, <span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> avg_cluster_coef</span><br><span class="line"></span><br><span class="line">avg_cluster_coef = average_clustering_coefficient(G)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average clustering coefficient of karate club network is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(avg_cluster_coef))</span><br></pre></td></tr></table></figure>
<pre><code>Average clustering coefficient of karate club network is 0.57
</code></pre>
<h2 id="Question-3-What-is-the-PageRank-value-for-node-0-node-with-id-0-after-one-PageRank-iteration-5-Points">Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)</h2>
<p>Page Rank measures importance of nodes in a graph using the link structure of the web. A “vote” from an important page is worth more. Specifically, if  a page <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> with importance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">d_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> out-links, then each link gets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msub><mi>r</mi><mi>i</mi></msub><msub><mi>d</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{r_i}{d_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1566em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7115em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> votes. Thus, the importance of a Page <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>, represented as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">r_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> is the sum of the votes on its in links.</p>
<p>r_j = \sum_{i \rightarrow j} \frac{r_i}{d_i}$$, where $d_i$ is the out degree of node $i$.

The PageRank algorithm (used by Google) outputs a probability distribution which represent the likelihood of a random surfer clicking on links will arrive at any particular page. At each time step, the random surfer has two options
- With prob. $\beta$, follow a link at random
- With prob. $1- \beta$, jump to a random page

Thus, the importance of a particular page is calculated with the following PageRank equation:
$$r_j = \sum_{i \rightarrow j} \beta \frac{r_i}{d_i} + (1 - \beta) \frac{1}{N}</p>
<p>Please complete the code block by implementing the above PageRank equation for node 0.</p>
<p>Note - You can refer to more information from the slides here - <a target="_blank" rel="noopener" href="http://snap.stanford.edu/class/cs224w-2020/slides/04-pagerank.pdf">http://snap.stanford.edu/class/cs224w-2020/slides/04-pagerank.pdf</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">one_iter_pagerank</span>(<span class="params">G, beta, r0, node_id</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;一次迭代后的PageRank&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">## Note:</span></span><br><span class="line">    <span class="comment">## 1: You should not use nx.pagerank</span></span><br><span class="line">    </span><br><span class="line">    r1 = <span class="number">0</span></span><br><span class="line">    N = G.number_of_nodes()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历邻居</span></span><br><span class="line">    <span class="keyword">for</span> nbr <span class="keyword">in</span> G.neighbors(node_id):</span><br><span class="line">        d_i = G.degree(nbr)</span><br><span class="line">        r1 += beta * (r0 / d_i)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 添加随机跳转部分</span></span><br><span class="line">    r1 += (<span class="number">1</span> - beta) * (<span class="number">1</span> / N)</span><br><span class="line">    r1 = <span class="built_in">round</span>(r1, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> r1</span><br><span class="line"></span><br><span class="line">beta = <span class="number">0.8</span></span><br><span class="line">r0 = <span class="number">1</span> / G.number_of_nodes()</span><br><span class="line">node = <span class="number">0</span></span><br><span class="line">r1 = one_iter_pagerank(G, beta, r0, node)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The PageRank value for node 0 after one iteration is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(r1))</span><br></pre></td></tr></table></figure>
<pre><code>The PageRank value for node 0 after one iteration is 0.13
</code></pre>
<h2 id="Question-4-What-is-the-raw-closeness-centrality-for-the-karate-club-network-node-5-5-Points">Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)</h2>
<p>The equation for closeness centrality is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msub><mo>∑</mo><mrow><mi>u</mi><mo mathvariant="normal">≠</mo><mi>v</mi></mrow></msub><mtext>shortest path length between </mtext><mi>u</mi><mtext> and </mtext><mi>v</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">c(v) = \frac{1}{\sum_{u \neq v}\text{shortest path length between } u \text{ and } v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.5123em;vertical-align:-0.6672em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1746em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord text mtight"><span class="mord mtight">shortest path length between </span></span><span class="mord mathnormal mtight">u</span><span class="mord text mtight"><span class="mord mtight"> and </span></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6672em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">closeness_centrality</span>(<span class="params">G, node=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;中心性&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># closeness = nx.closeness_centrality(G, node)</span></span><br><span class="line">    </span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算 node 到其他节点的最短路径长度</span></span><br><span class="line">    shortest_paths = nx.shortest_path_length(G, source=node)</span><br><span class="line">    lengths = [length <span class="keyword">for</span> target, length <span class="keyword">in</span> shortest_paths.items() <span class="keyword">if</span> target != node]</span><br><span class="line">    total = <span class="built_in">sum</span>(lengths)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 若总路径长度为 0 则该节点无法到达其他节点，中心性为 0</span></span><br><span class="line">    <span class="keyword">if</span> total &gt; <span class="number">0</span>:</span><br><span class="line">        closeness = (N-<span class="number">1</span>) / total</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        closeness = <span class="number">0</span></span><br><span class="line">    closeness = <span class="built_in">round</span>(closeness, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> closeness</span><br><span class="line"></span><br><span class="line">node = <span class="number">5</span></span><br><span class="line">closeness = closeness_centrality(G, node=node)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The node 5 has closeness centrality &#123;&#125;&quot;</span>.<span class="built_in">format</span>(closeness))</span><br></pre></td></tr></table></figure>
<pre><code>The node 5 has closeness centrality 0.38
</code></pre>
<h1>2 Graph to Tensor</h1>
<p>We will then work together to transform the graph <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> into a PyTorch tensor, so that we can perform machine learning over the graph.</p>
<h2 id="Setup-2">Setup</h2>
<p>Check if PyTorch is properly installed</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>2.4.1
</code></pre>
<h2 id="PyTorch-tensor-basics">PyTorch tensor basics</h2>
<p>We can generate PyTorch tensor with all zeros, ones or random values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generate 3 x 4 tensor with all ones</span></span><br><span class="line">ones = torch.ones(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(ones)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate 3 x 4 tensor with all zeros</span></span><br><span class="line">zeros = torch.zeros(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(zeros)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate 3 x 4 tensor with random values on the interval [0, 1)</span></span><br><span class="line">random_tensor = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(random_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the shape of the tensor</span></span><br><span class="line"><span class="built_in">print</span>(ones.shape)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
tensor([[0.5627, 0.2231, 0.4255, 0.7039],
        [0.0281, 0.1933, 0.5920, 0.9510],
        [0.0953, 0.9217, 0.0193, 0.3396]])
torch.Size([3, 4])
</code></pre>
<p>PyTorch tensor contains elements for a single data type, the <code>dtype</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a 3 x 4 tensor with all 32-bit floating point zeros</span></span><br><span class="line">zeros = torch.zeros(<span class="number">3</span>, <span class="number">4</span>, dtype=torch.float32)</span><br><span class="line"><span class="built_in">print</span>(zeros.dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the tensor dtype to 64-bit integer</span></span><br><span class="line">zeros = zeros.<span class="built_in">type</span>(torch.long)</span><br><span class="line"><span class="built_in">print</span>(zeros.dtype)</span><br></pre></td></tr></table></figure>
<pre><code>torch.float32
torch.int64
</code></pre>
<h2 id="Question-5-Get-the-edge-list-of-the-karate-club-network-and-transform-it-into-torch-LongTensor-What-is-the-torch-sum-value-of-pos-edge-index-tensor-10-Points">Question 5: Get the edge list of the karate club network and transform it into <code>torch.LongTensor</code>. What is the <code>torch.sum</code> value of <code>pos_edge_index</code> tensor? (10 Points)</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">graph_to_edge_list</span>(<span class="params">G</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;获取图的所有边，列表形式&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    edge_list = <span class="built_in">list</span>(G.edges())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> edge_list</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">edge_list_to_tensor</span>(<span class="params">edge_list</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;边转为 tensor&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 读取，转置</span></span><br><span class="line">    edge_index = torch.tensor(edge_list, dtype=torch.long).t()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> edge_index</span><br><span class="line"></span><br><span class="line">pos_edge_list = graph_to_edge_list(G)</span><br><span class="line">pos_edge_index = edge_list_to_tensor(pos_edge_list)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The pos_edge_index tensor has shape &#123;&#125;&quot;</span>.<span class="built_in">format</span>(pos_edge_index.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The pos_edge_index tensor has sum value &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.<span class="built_in">sum</span>(pos_edge_index)))</span><br></pre></td></tr></table></figure>
<pre><code>The pos_edge_index tensor has shape torch.Size([2, 78])
The pos_edge_index tensor has sum value 2535
</code></pre>
<h2 id="Question-6-Please-implement-following-function-that-samples-negative-edges-Then-answer-which-edges-edge-1-to-edge-5-are-the-negative-edges-in-the-karate-club-network-10-Points">Question 6: Please implement following function that samples negative edges. Then answer which edges (edge_1 to edge_5) are the negative edges in the karate club network? (10 Points)</h2>
<p>“Negative” edges refer to the edges/links that do not exist in the graph. The term “negative” is borrowed from “negative sampling” in link prediction. It has nothing to do with the edge weights.</p>
<p>For example, given an edge (src, dst), you should check that neither (src, dst) nor (dst, src) are edges in the Graph. If these hold true, then it is a negative edge.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_negative_edges</span>(<span class="params">G, num_neg_samples</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;边的负采样&#x27;&#x27;&#x27;</span></span><br><span class="line">    neg_edge_list = []</span><br><span class="line">    nodes = <span class="built_in">list</span>(G.nodes())</span><br><span class="line">    existing_edges = <span class="built_in">set</span>(G.edges())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 开始采样负边</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(neg_edge_list) &lt; num_neg_samples:</span><br><span class="line">        u = random.choice(nodes)</span><br><span class="line">        v = random.choice(nodes)</span><br><span class="line">        <span class="comment"># 自环不被考虑</span></span><br><span class="line">        <span class="keyword">if</span> u != v <span class="keyword">and</span> (u,v) <span class="keyword">not</span> <span class="keyword">in</span> existing_edges <span class="keyword">and</span> (v,u) <span class="keyword">not</span> <span class="keyword">in</span> existing_edges:</span><br><span class="line">            neg_edge_list.append((u,v))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> neg_edge_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample 78 negative edges</span></span><br><span class="line">neg_edge_list = sample_negative_edges(G, <span class="built_in">len</span>(pos_edge_list))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform the negative edge list to tensor</span></span><br><span class="line">neg_edge_index = edge_list_to_tensor(neg_edge_list)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The neg_edge_index tensor has shape &#123;&#125;&quot;</span>.<span class="built_in">format</span>(neg_edge_index.shape))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Which of following edges can be negative ones?</span></span><br><span class="line">edge_1 = (<span class="number">7</span>, <span class="number">1</span>)</span><br><span class="line">edge_2 = (<span class="number">1</span>, <span class="number">33</span>)</span><br><span class="line">edge_3 = (<span class="number">33</span>, <span class="number">22</span>)</span><br><span class="line">edge_4 = (<span class="number">0</span>, <span class="number">4</span>)</span><br><span class="line">edge_5 = (<span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">can_be_negative</span>(<span class="params">G, edge</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;判断负边&#x27;&#x27;&#x27;</span></span><br><span class="line">    is_negative = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 判断</span></span><br><span class="line">    <span class="keyword">if</span> edge[<span class="number">0</span>] != edge[<span class="number">1</span>] <span class="keyword">and</span> edge <span class="keyword">not</span> <span class="keyword">in</span> G.edges() <span class="keyword">and</span> edge <span class="keyword">not</span> <span class="keyword">in</span> G.edges():</span><br><span class="line">        is_negative = <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> is_negative</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Edge 1 can be a negative edge: <span class="subst">&#123;can_be_negative(G, edge_1)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Edge 2 can be a negative edge: <span class="subst">&#123;can_be_negative(G, edge_2)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Edge 3 can be a negative edge: <span class="subst">&#123;can_be_negative(G, edge_3)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Edge 4 can be a negative edge: <span class="subst">&#123;can_be_negative(G, edge_4)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Edge 5 can be a negative edge: <span class="subst">&#123;can_be_negative(G, edge_5)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>The neg_edge_index tensor has shape torch.Size([2, 78])
Edge 1 can be a negative edge: False
Edge 2 can be a negative edge: True
Edge 3 can be a negative edge: False
Edge 4 can be a negative edge: False
Edge 5 can be a negative edge: True
</code></pre>
<h1>3 Node Emebedding Learning</h1>
<p>Finally, we will finish the first learning algorithm on graphs: a node embedding model.</p>
<h2 id="Setup-3">Setup</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>2.4.1
</code></pre>
<p>To write our own node embedding learning methods, we’ll heavily use the <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code>nn.Embedding</code></a> module in PyTorch. Let’s see how to use <code>nn.Embedding</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize an embedding layer</span></span><br><span class="line"><span class="comment"># Suppose we want to have embedding for 4 items (e.g., nodes)</span></span><br><span class="line"><span class="comment"># Each item is represented with 8 dimensional vector</span></span><br><span class="line"></span><br><span class="line">emb_sample = nn.Embedding(num_embeddings=<span class="number">4</span>, embedding_dim=<span class="number">8</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Sample embedding layer: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(emb_sample))</span><br></pre></td></tr></table></figure>
<pre><code>Sample embedding layer: Embedding(4, 8)
</code></pre>
<p>We can select items from the embedding matrix, by using Tensor indices</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select an embedding in emb_sample</span></span><br><span class="line"><span class="built_in">id</span> = torch.LongTensor([<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(emb_sample(<span class="built_in">id</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select multiple embeddings</span></span><br><span class="line">ids = torch.LongTensor([<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(emb_sample(ids))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the shape of the embedding weight matrix</span></span><br><span class="line">shape = emb_sample.weight.data.shape</span><br><span class="line"><span class="built_in">print</span>(shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Overwrite the weight to tensor with all ones</span></span><br><span class="line">emb_sample.weight.data = torch.ones(shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s check if the emb is indeed initilized</span></span><br><span class="line">ids = torch.LongTensor([<span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(emb_sample(ids))</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 0.0643, -0.6521,  0.1235,  0.0435,  0.7306, -0.9286, -0.2463,  0.4538]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
tensor([[ 0.0643, -0.6521,  0.1235,  0.0435,  0.7306, -0.9286, -0.2463,  0.4538],
        [ 0.0295,  3.1822,  2.7626,  0.3644,  0.8467, -0.4309, -1.1269,  0.5526]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
torch.Size([4, 8])
tensor([[1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=&lt;EmbeddingBackward0&gt;)
</code></pre>
<p>Now, it’s your time to create node embedding matrix for the graph we have!</p>
<ul>
<li>We want to have <strong>16 dimensional</strong> vector for each node in the karate club network.</li>
<li>We want to initalize the matrix under <strong>uniform distribution</strong>, in the range of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>. We suggest you using <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.rand.html"><code>torch.rand</code></a>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Please do not change / reset the random seed</span></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_node_emb</span>(<span class="params">num_node=<span class="number">34</span>, embedding_dim=<span class="number">16</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;创建节点嵌入矩阵&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 创建嵌入层</span></span><br><span class="line">    emb = nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)</span><br><span class="line">    <span class="comment"># 使用均匀分布初始化权重</span></span><br><span class="line">    nn.init.uniform_(emb.weight, -<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> emb</span><br><span class="line"></span><br><span class="line">emb = create_node_emb()</span><br><span class="line">ids = torch.LongTensor([<span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the embedding layer</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Embedding: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(emb))</span><br><span class="line"></span><br><span class="line"><span class="comment"># An example that gets the embeddings for node 0 and 3</span></span><br><span class="line"><span class="built_in">print</span>(emb(ids))</span><br></pre></td></tr></table></figure>
<pre><code>Embedding: Embedding(34, 16)
tensor([[-0.5773,  0.4670, -0.7134,  0.9294, -0.4133,  0.5903,  0.0341, -0.4398,
          0.6678, -0.7630, -0.5291,  0.1199,  0.7933, -0.4285, -0.6089, -0.6384],
        [ 0.4972,  0.3093, -0.2314,  0.9640,  0.2024, -0.2580, -0.0142,  0.9830,
          0.6717, -0.0741,  0.9804,  0.4391, -0.5324, -0.9101,  0.5811,  0.9378]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
</code></pre>
<h2 id="Visualize-the-initial-node-embeddings">Visualize the initial node embeddings</h2>
<p>One good way to understand an embedding matrix, is to visualize it in a 2D space.<br>
Here, we have implemented an embedding visualization function for you.<br>
We first do PCA to reduce the dimensionality of embeddings to a 2D space.<br>
Then we visualize each point, colored by the community it belongs to.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_emb</span>(<span class="params">emb</span>):</span><br><span class="line">    X = emb.weight.data.numpy()</span><br><span class="line">    pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">    components = pca.fit_transform(X)</span><br><span class="line">    plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">    club1_x = []</span><br><span class="line">    club1_y = []</span><br><span class="line">    club2_x = []</span><br><span class="line">    club2_y = []</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> G.nodes(data=<span class="literal">True</span>):</span><br><span class="line">        <span class="keyword">if</span> node[<span class="number">1</span>][<span class="string">&#x27;club&#x27;</span>] == <span class="string">&#x27;Mr. Hi&#x27;</span>:</span><br><span class="line">            club1_x.append(components[node[<span class="number">0</span>]][<span class="number">0</span>])</span><br><span class="line">            club1_y.append(components[node[<span class="number">0</span>]][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            club2_x.append(components[node[<span class="number">0</span>]][<span class="number">0</span>])</span><br><span class="line">            club2_y.append(components[node[<span class="number">0</span>]][<span class="number">1</span>])</span><br><span class="line">    plt.scatter(club1_x, club1_y, color=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;Mr. Hi&quot;</span>)</span><br><span class="line">    plt.scatter(club2_x, club2_y, color=<span class="string">&quot;blue&quot;</span>, label=<span class="string">&quot;Officer&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the initial random embeddding</span></span><br><span class="line">visualize_emb(emb)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_37_0.png" alt="png"><br>
​</p>
<h2 id="Question-7-Training-the-embedding-What-is-the-best-performance-you-can-get-20-Points">Question 7: Training the embedding! What is the best performance you can get? (20 Points)</h2>
<p>We want to optimize our embeddings for the task of classifying edges as positive or negative. Given an edge and the embeddings for each node, the dot product of the embeddings, followed by a sigmoid, should give us the likelihood of that edge being either positive (output of sigmoid &gt; 0.5) or negative (output of sigmoid &lt; 0.5).</p>
<p>Note that we’re using the functions you wrote in the previous questions, <em>as well as the variables initialized in previous cells</em>. If you’re running into issues, make sure your answers to questions 1-6 are correct.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">pred, label</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算准确率&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 将预测值转为 0 或 1</span></span><br><span class="line">    pred_label = (pred &gt; <span class="number">0.5</span>).<span class="built_in">float</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    correcr = (pred_label == label).<span class="built_in">float</span>().<span class="built_in">sum</span>()</span><br><span class="line">    accu = correcr / label.shape[<span class="number">0</span>]</span><br><span class="line">    accu = <span class="built_in">round</span>(accu.item(), <span class="number">4</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> accu</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">emb, loss_fn, train_label, train_edge</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;训练函数&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Train the embedding layer here. You can also change epochs and</span></span><br><span class="line">    <span class="comment"># learning rate. In general, you need to implement:</span></span><br><span class="line">    <span class="comment"># (1) Get the embeddings of the nodes in train_edge</span></span><br><span class="line">    <span class="comment"># (2) Dot product the embeddings between each node pair</span></span><br><span class="line">    <span class="comment"># (3) Feed the dot product result into sigmoid</span></span><br><span class="line">    <span class="comment"># (4) Feed the sigmoid output into the loss_fn</span></span><br><span class="line">    <span class="comment"># (5) Print both loss and accuracy of each epoch</span></span><br><span class="line">    <span class="comment"># (6) Update the embeddings using the loss and optimizer</span></span><br><span class="line">    <span class="comment"># (as a sanity check, the loss should decrease during training)</span></span><br><span class="line"></span><br><span class="line">    epochs = <span class="number">500</span></span><br><span class="line">    learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># 获取训练边中节点对的嵌入</span></span><br><span class="line">        u_emb = emb(train_edge[<span class="number">0</span>])</span><br><span class="line">        v_emb = emb(train_edge[<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算点积（节点对的相似度）再 sigmoid</span></span><br><span class="line">        dot_product = (u_emb * v_emb).<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">        pred = torch.sigmoid(dot_product)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算损失、准确率</span></span><br><span class="line">        loss = loss_fn(pred, train_label)</span><br><span class="line">        accu = accuracy(pred, train_label)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>: Loss = <span class="subst">&#123;loss.item()&#125;</span>, Accuracy = <span class="subst">&#123;accu&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 优化：梯度清零，反向传播计算梯度，更新嵌入</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> emb</span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pos_edge_index.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate the positive and negative labels</span></span><br><span class="line">pos_label = torch.ones(pos_edge_index.shape[<span class="number">1</span>], )</span><br><span class="line">neg_label = torch.zeros(neg_edge_index.shape[<span class="number">1</span>], )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Concat positive and negative labels into one tensor</span></span><br><span class="line">train_label = torch.cat([pos_label, neg_label], dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Concat positive and negative edges into one tensor</span></span><br><span class="line"><span class="comment"># Since the network is very small, we do not split the edges into val/test sets</span></span><br><span class="line">train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_edge.shape)</span><br><span class="line"></span><br><span class="line">train(emb, loss_fn, train_label, train_edge)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 78])
torch.Size([2, 156])
Epoch 0: Loss = 0.9025148153305054, Accuracy = 0.5
Epoch 50: Loss = 0.3298068046569824, Accuracy = 0.9167
Epoch 100: Loss = 0.1502346247434616, Accuracy = 1.0
Epoch 150: Loss = 0.08421747386455536, Accuracy = 1.0
Epoch 200: Loss = 0.05426323041319847, Accuracy = 1.0
Epoch 250: Loss = 0.03854725509881973, Accuracy = 1.0
Epoch 300: Loss = 0.029253864660859108, Accuracy = 1.0
Epoch 350: Loss = 0.02324979566037655, Accuracy = 1.0
Epoch 400: Loss = 0.019109662622213364, Accuracy = 1.0
Epoch 450: Loss = 0.016110926866531372, Accuracy = 1.0





Embedding(34, 16)
</code></pre>
<h2 id="Visualize-the-final-node-embeddings">Visualize the final node embeddings</h2>
<p>Visualize your final embedding here!<br>
You can visually compare the figure with the previous embedding figure.<br>
After training, you should oberserve that the two classes are more evidently separated.<br>
This is a great sanitity check for your implementation as well.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize the final learned embedding</span></span><br><span class="line">visualize_emb(emb)</span><br></pre></td></tr></table></figure>
<p>​<br>
<img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png" alt="png"><br>
​</p>
<h1>Submission</h1>
<p>When you submit your assignment, you will have to download this file as an <code>.ipynb</code> file. Please name this file <code>CS224W_Colab_1.ipynb</code>. Make sure that the files are name correctly, otherwise the autograder will not be able to find your submission files.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://isSeymour.github.io/butterflyblog">isSeymour</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://isseymour.github.io/butterflyblog/2024/10/10/CS224W_Colab_1/">https://isseymour.github.io/butterflyblog/2024/10/10/CS224W_Colab_1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://isSeymour.github.io/butterflyblog" target="_blank">isSeymour</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/butterflyblog/tags/GNN/">GNN</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY1.jpg" alt="微信支付"/></a><div class="post-qr-code-desc">微信支付</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/pay/PAY2.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/butterflyblog/2024/10/10/CS224W_Colab_0/" title="CS224W - Colab 0"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab0/output_41_0.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">CS224W - Colab 0</div></div></a></div><div class="next-post pull-right"><a href="/butterflyblog/2024/10/12/Graph-PageRank/" title="PageRank:《哈利·波特》人物节点重要度"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/PageRank/Algorithm.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">PageRank:《哈利·波特》人物节点重要度</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/butterflyblog/2024/10/10/CS224W_Colab_0/" title="CS224W - Colab 0"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab0/output_41_0.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-10</div><div class="title">CS224W - Colab 0</div></div></a></div><div><a href="/butterflyblog/2024/10/14/CS224W_Colab_2/" title="CS224W - Colab 2"><img class="cover" src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/GCN/shared-parameters.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-14</div><div class="title">CS224W - Colab 2</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/T6.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">isSeymour</div><div class="author-info__description">志之所趋，无远弗届，穷山距海，不能限也。</div></div><div class="card-info-data site-data is-center"><a href="/butterflyblog/archives/"><div class="headline">文章</div><div class="length-num">71</div></a><a href="/butterflyblog/tags/"><div class="headline">标签</div><div class="length-num">35</div></a><a href="/butterflyblog/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isSeymour/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://isSeymour.github.io/profile/" target="_blank" title="学术主页"><i class="fa-regular fa-address-card" style="color: #000000;"></i></a><a class="social-icon" href="https://github.com/isSeymour/" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="https://space.bilibili.com/79699613/" target="_blank" title="B站"><i class="fa-brands fa-bilibili" style="color: #000000;"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_63205991/" target="_blank" title="CSDN"><i class="fa-solid fa-code" style="color: #000000;"></i></a><a class="social-icon" href="mailto:isSeymour@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">CS224W - Colab 1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">1 Graph Basics</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Setup"><span class="toc-text">Setup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zachary%E2%80%99s-karate-club-network"><span class="toc-text">Zachary’s karate club network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-1-What-is-the-average-degree-of-the-karate-club-network-5-Points"><span class="toc-text">Question 1: What is the average degree of the karate club network? (5 Points)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-2-What-is-the-average-clustering-coefficient-of-the-karate-club-network-5-Points"><span class="toc-text">Question 2: What is the average clustering coefficient of the karate club network? (5 Points)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-3-What-is-the-PageRank-value-for-node-0-node-with-id-0-after-one-PageRank-iteration-5-Points"><span class="toc-text">Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-4-What-is-the-raw-closeness-centrality-for-the-karate-club-network-node-5-5-Points"><span class="toc-text">Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">2 Graph to Tensor</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Setup-2"><span class="toc-text">Setup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-tensor-basics"><span class="toc-text">PyTorch tensor basics</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-5-Get-the-edge-list-of-the-karate-club-network-and-transform-it-into-torch-LongTensor-What-is-the-torch-sum-value-of-pos-edge-index-tensor-10-Points"><span class="toc-text">Question 5: Get the edge list of the karate club network and transform it into torch.LongTensor. What is the torch.sum value of pos_edge_index tensor? (10 Points)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-6-Please-implement-following-function-that-samples-negative-edges-Then-answer-which-edges-edge-1-to-edge-5-are-the-negative-edges-in-the-karate-club-network-10-Points"><span class="toc-text">Question 6: Please implement following function that samples negative edges. Then answer which edges (edge_1 to edge_5) are the negative edges in the karate club network? (10 Points)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">3 Node Emebedding Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Setup-3"><span class="toc-text">Setup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Visualize-the-initial-node-embeddings"><span class="toc-text">Visualize the initial node embeddings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Question-7-Training-the-embedding-What-is-the-best-performance-you-can-get-20-Points"><span class="toc-text">Question 7: Training the embedding! What is the best performance you can get? (20 Points)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Visualize-the-final-node-embeddings"><span class="toc-text">Visualize the final node embeddings</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">Submission</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2025/04/26/LLM4Rec_abc_3/" title="大模型推荐系统（3）微调范式"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/3/llm4rec-abc-3-Page.webp" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="大模型推荐系统（3）微调范式"/></a><div class="content"><a class="title" href="/butterflyblog/2025/04/26/LLM4Rec_abc_3/" title="大模型推荐系统（3）微调范式">大模型推荐系统（3）微调范式</a><time datetime="2025-04-26T09:00:00.000Z" title="发表于 2025-04-26 17:00:00">2025-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2025/04/26/LLM4Rec_abc_4/" title="大模型推荐系统（4）直接推荐范式"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/4/llm4rec-abc-4-Page.png" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="大模型推荐系统（4）直接推荐范式"/></a><div class="content"><a class="title" href="/butterflyblog/2025/04/26/LLM4Rec_abc_4/" title="大模型推荐系统（4）直接推荐范式">大模型推荐系统（4）直接推荐范式</a><time datetime="2025-04-26T09:00:00.000Z" title="发表于 2025-04-26 17:00:00">2025-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/butterflyblog/2025/04/26/LLM4Rec_abc_2/" title="大模型推荐系统（2）预训练范式"><img src="https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/llm4rec_abc/2/llm4rec-abc-2-Page.png" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/Seymour0314/PicGo/blog/page_img/404.jpg'" alt="大模型推荐系统（2）预训练范式"/></a><div class="content"><a class="title" href="/butterflyblog/2025/04/26/LLM4Rec_abc_2/" title="大模型推荐系统（2）预训练范式">大模型推荐系统（2）预训练范式</a><time datetime="2025-04-26T04:00:00.000Z" title="发表于 2025-04-26 12:00:00">2025-04-26</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/isSeymour/PicGo/posts/CS224W/Colab1/output_41_0.png')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By isSeymour</div><div class="footer_custom_text">欢迎乘坐我的生活地铁！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/butterflyblog/js/utils.js"></script><script src="/butterflyblog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23liAZxomGv7Hapw8g',
      clientSecret: 'f7cafde192c4ada8bef4b76952c422d90575cf8b',
      repo: 'gitalk',
      owner: 'isSeymour',
      admin: ['isSeymour'],
      id: '98f47315b0bd1c0a7140dd3e989a3acd',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/butterflyblog/js/search/local-search.js"></script></div></div></body></html>